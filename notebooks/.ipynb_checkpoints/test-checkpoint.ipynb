{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrgSci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Keywords</th>\n",
       "      <td>[': status', 'status-quality coupling', 'netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abstract.</th>\n",
       "      <td>Abstract.\\n Previous research has demonstrated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Introduction</th>\n",
       "      <td>Introduction\\nResearch on social networks has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social Status and Network-Broadening</th>\n",
       "      <td>Social Status and Network-Broadening\\nResearch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Critical Enabler: Belief in Status-Quality Coupling</th>\n",
       "      <td>A Critical Enabler: Belief in Status-Quality C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network-Broadening Behavior and Network Size</th>\n",
       "      <td>Network-Broadening Behavior and Network Size\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research Overview</th>\n",
       "      <td>Research Overview\\nWe tested our hypotheses ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pilot Study: A Preliminary Demonstration of the Interaction Effect of Status X Coupling on Network Size in the GSS</th>\n",
       "      <td>Pilot Study: A Preliminary Demonstration of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 1: Status is Positively Associated with Network-Broadening</th>\n",
       "      <td>Study 1: Status is Positively Associated with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 2: Belief in Status-Quality Coupling Moderates the Relationship Between Status and Network-Broadening</th>\n",
       "      <td>Study 2: Belief in Status-Quality Coupling Mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 3: Testing the Indirect Effect of Status  ×  Coupling on Network Size via Network-Broadening</th>\n",
       "      <td>Study 3: Testing the Indirect Effect of Status...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 4: Testing the Causal Effect of Status and Coupling on Network-Broadening Intention</th>\n",
       "      <td>Study 4: Testing the Causal Effect of Status a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 5: Testing the Causal Effect of Status and Coupling on Network-Broadening Behavior</th>\n",
       "      <td>Study 5: Testing the Causal Effect of Status a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 6: Mechanisms Test: Perceived Self-Value and Perceived Receptivity of the Networking Target</th>\n",
       "      <td>Study 6: Mechanisms Test: Perceived Self-Value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internal Meta-Analysis</th>\n",
       "      <td>Internal Meta-Analysis\\nWe performed an intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Discussion</th>\n",
       "      <td>General Discussion\\nAcross seven studies, we e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conclusion</th>\n",
       "      <td>Conclusion\\nOur paper offers a novel explanati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endnotes</th>\n",
       "      <td>Endnotes\\n1 \\n\\n  Among network researchers, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>References</th>\n",
       "      <td>References\\nAnderson C, Brown CE (2010) The fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text\n",
       "Keywords                                            [': status', 'status-quality coupling', 'netwo...\n",
       "Abstract.                                           Abstract.\\n Previous research has demonstrated...\n",
       "Introduction                                        Introduction\\nResearch on social networks has ...\n",
       "Social Status and Network-Broadening                Social Status and Network-Broadening\\nResearch...\n",
       "A Critical Enabler: Belief in Status-Quality Co...  A Critical Enabler: Belief in Status-Quality C...\n",
       "Network-Broadening Behavior and Network Size        Network-Broadening Behavior and Network Size\\n...\n",
       "Research Overview                                   Research Overview\\nWe tested our hypotheses ac...\n",
       "Pilot Study: A Preliminary Demonstration of the...  Pilot Study: A Preliminary Demonstration of th...\n",
       "Study 1: Status is Positively Associated with N...  Study 1: Status is Positively Associated with ...\n",
       "Study 2: Belief in Status-Quality Coupling Mode...  Study 2: Belief in Status-Quality Coupling Mod...\n",
       "Study 3: Testing the Indirect Effect of Status ...  Study 3: Testing the Indirect Effect of Status...\n",
       "Study 4: Testing the Causal Effect of Status an...  Study 4: Testing the Causal Effect of Status a...\n",
       "Study 5: Testing the Causal Effect of Status an...  Study 5: Testing the Causal Effect of Status a...\n",
       "Study 6: Mechanisms Test: Perceived Self-Value ...  Study 6: Mechanisms Test: Perceived Self-Value...\n",
       "Internal Meta-Analysis                              Internal Meta-Analysis\\nWe performed an intern...\n",
       "General Discussion                                  General Discussion\\nAcross seven studies, we e...\n",
       "Conclusion                                          Conclusion\\nOur paper offers a novel explanati...\n",
       "Endnotes                                            Endnotes\\n1 \\n\\n  Among network researchers, t...\n",
       "References                                          References\\nAnderson C, Brown CE (2010) The fu..."
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "\n",
    "\n",
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "    main_section   \n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        rect = Rect(page.rect.x0 + 40, page.rect.y0 + 60, page.rect.x1 - 40, page.rect.y1 - 40) \n",
    "        \n",
    "        dict = page.get_text(\"dict\", clip = rect)\n",
    "\n",
    "        blocks = dict[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" in block.keys():\n",
    "                spans = block['lines']\n",
    "                for span in spans:\n",
    "                    data = span['spans']\n",
    "                    for lines in data:\n",
    "                        cur_size = round(lines['size'], 1)\n",
    "\n",
    "                        # Manual Override for References\n",
    "                        if lines['text'].strip() in (\"Acknowledgements\", \"References\", \"Appendix\", \"Endnotes\"):\n",
    "                            cur = Section(lines['text'], cur_size)\n",
    "                            curr_section = main_section.children[-1].children[-1]\n",
    "                            curr_section.add_child(cur)\n",
    "                            cur.set_parent(curr_section)\n",
    "                            curr_section = cur\n",
    "\n",
    "                            prev_size = round(lines['size'], 1)\n",
    "\n",
    "                        elif cur_size > prev_size:\n",
    "                            curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                            prev_size = curr_section.size\n",
    "\n",
    "                        elif cur_size == prev_size:\n",
    "                            curr_section.extend(lines['text'])\n",
    "\n",
    "                        else:  \n",
    "                            cur = Section(lines['text'], cur_size)   \n",
    "                            curr_section.add_child(cur)\n",
    "                            cur.set_parent(curr_section)\n",
    "                            curr_section = cur\n",
    "                            prev_size = round(lines['size'], 1)\n",
    "\n",
    "    # orgsci                            \n",
    "    return main_section.children[-1].children[-1].children\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references_dirty = \" \".join(references_dirty.split())\n",
    "    references = re.sub(\"([0-9]|html|\\))\\s?\\.\", r\"\\g<0>\\n\", references_dirty)\n",
    "\n",
    "    # Make list of references\n",
    "    pattern = r\"[A-ZÆØÅæøå][ÆØÅæøåA-Za-z]+.*[A-Z]{1,3},? .*\\(\\d{4}\\).*[html|\\d|\\)]\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \" and \" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\" and \")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def convert_pdf_to_dataframes(path) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(path)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    add_new_section = False\n",
    "\n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract. \", 0)\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "\n",
    "    sections_tmp = sections.copy()\n",
    "    earliest_index = 1000\n",
    "    txt = \"\"\n",
    "    # pprint.pprint(sections[abstract_index:])\n",
    "    # Fit all text that belongs in paragraph into one \"Introduction\" paragraph\n",
    "    for idx, section in enumerate(sections_tmp):\n",
    "        if len(section.content) > 200:\n",
    "            print(section)\n",
    "            add_new_section = True\n",
    "            if min(earliest_index, idx) != earliest_index:\n",
    "                earliest_index = idx\n",
    "            sections.remove(section)\n",
    "            txt += section.content\n",
    "\n",
    "    if add_new_section:\n",
    "        new_section = Section(\"Introduction\", 20)\n",
    "        new_section.add_child(Section(txt, 15))\n",
    "        sections[earliest_index] = new_section\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "\n",
    "    return sections\n",
    "\n",
    "import fitz\n",
    "import os\n",
    "\n",
    "ORGSCI_PATH = \"../data/orgsci\"\n",
    "orgsci_pdfs = [f for f in os.listdir(ORGSCI_PATH) if f.endswith('pdf')]\n",
    "for i in range(len(orgsci_pdfs)):\n",
    "    path = os.path.join(ORGSCI_PATH, orgsci_pdfs[2])\n",
    "    sections_df, references_df = convert_pdf_to_dataframes(path)\n",
    "    abstract_text = sections_df.iloc[0].item()\n",
    "    abstract, keywords = abstract_text.split(\"Keywords\")\n",
    "    cleaned_keywords = [keyword.strip() for keyword in keywords.split(\"•\")]\n",
    "    new_row = pd.DataFrame({\"text\":str(cleaned_keywords)}, index = [\"Keywords\"])\n",
    "    sections_df = pd.concat([new_row, sections_df])\n",
    "\n",
    "sections_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annurev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if type(other) == str:\n",
    "            return self.content.strip() == other\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references_dirty = \" \".join(references_dirty.split())\n",
    "    references = re.sub(\"([0-9]|html|\\))\\s?\\.\", r\"\\g<0>\\n\", references_dirty)\n",
    "\n",
    "    # Make list of references\n",
    "    pattern = r\"[A-ZÆØÅæøå][ÆØÅæøåA-Za-z]+.*[A-Z]{1,3},? .*\\(\\d{4}\\).*[html|\\d|\\)]\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \" and \" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\" and \")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def convert_pdf_to_dataframes(path) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(path)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract\", 0)\n",
    "\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        if page.number not in (doc[-1].number, doc[-2].number):\n",
    "            rect = Rect(page.rect.x0 + 20, page.rect.y0 + 20, page.rect.x1 - 20, page.rect.y1 - 30)\n",
    "            \n",
    "            dict = page.get_text(\"dict\", clip = rect)\n",
    "            blocks = dict[\"blocks\"]\n",
    "            for block in blocks:\n",
    "                if \"lines\" in block.keys():\n",
    "                    spans = block['lines']\n",
    "                    for span in spans:\n",
    "                        data = span['spans']\n",
    "                        for lines in data:\n",
    "                            cur_size = round(lines['size'], 2)\n",
    "\n",
    "                            # Manual Override for References\n",
    "                            if lines['text'].strip() in (\"Abstract\", \"Keywords\", \"LITERATURE CITED\"):\n",
    "\n",
    "                                cur = Section(lines['text'], cur_size)\n",
    "                                curr_section = main_section.children[-1].children[-1]\n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "\n",
    "                                prev_size = round(lines['size'], 2)\n",
    "\n",
    "                            elif cur_size > prev_size:\n",
    "                                curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                                prev_size = curr_section.size\n",
    "\n",
    "                            elif cur_size == prev_size:\n",
    "                                curr_section.extend(lines['text'])\n",
    "\n",
    "                            else:  \n",
    "                                cur = Section(lines['text'], cur_size)   \n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "                                prev_size = round(lines['size'], 2)\n",
    "\n",
    "\n",
    "    final_sections = main_section.children[-1].children\n",
    "    \n",
    "    if len(final_sections) > 1:\n",
    "        return final_sections[-2].children + final_sections[-1].children\n",
    "    else:\n",
    "        return final_sections[-1].children\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    first_section = Section(\"Keywords\", 0)\n",
    "    first_index = sections.index(first_section)\n",
    "    sections = sections[first_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references = \" \".join(references_dirty.split())\n",
    "    pattern = \"[A-Z][A-Za-z, ]+[A-Z]{1,3}\\. \\d{4}\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    \n",
    "    for idx, ref in enumerate(references_clean):\n",
    "        if idx == len(references_clean) - 1:\n",
    "            # All the way to the end\n",
    "            references_clean[idx] = references[references.find(ref):]\n",
    "        else:\n",
    "            next_ref = references_clean[idx+1]\n",
    "            references_clean[idx] = references[references.find(ref):references.find(next_ref)]\n",
    "\n",
    "    return references_clean\n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_PARANTHESES_CITATION_REGEX = r\"\\([&\\w\\s., ]+\\s\\d{3,4}\\)\"\n",
    "    AND_PATTERN = \"\\S+ & \\S+ \\(\\d{3,4}\\)\"\n",
    "    ONE_PATTERN = \"[A-Z]\\S+ \\(\\d{3,4}\\)\"\n",
    "    ET_AL_PATTERN = \"[A-Z][a-z] et al. \\(\\d{3,4}\\)\"\n",
    "    IN_TEXT_CITATION_REGEX = f\"{IN_PARANTHESES_CITATION_REGEX}|{AND_PATTERN}|{ONE_PATTERN}|{ET_AL_PATTERN}\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \"&\" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\"&\")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if year in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_text = sections[sections.index(\"LITERATURE CITED\")].print_contents()\n",
    "    references_clean = text_preprocess_for_reference_matching(references_text)\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "\n",
    "            item \n",
    "\n",
    "            for group in \n",
    "\n",
    "            [\n",
    "                re.sub(r\"\\(|\\)|see also|’s\", \"\", item).split(\",\")\n",
    "                for item in in_text_citations\n",
    "            ]\n",
    "\n",
    "            for item in group\n",
    "\n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    return references_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pprint\n",
    "# from IPython.display import display\n",
    "\n",
    "# annurev_path = \"../data/annurev-orgpsych\"\n",
    "# annurev_pdfs = [f for f in os.listdir(annurev_path) if f.endswith('pdf')]\n",
    "# for i in range(len(annurev_pdfs)):\n",
    "#     sections_df, references_df = convert_pdf_to_dataframes(os.path.join(annurev_path, annurev_pdfs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_dictionary = {}\n",
    "references_text = sections[sections.index(\"LITERATURE CITED\")].print_contents()\n",
    "references_clean = text_preprocess_for_reference_matching(references_text)\n",
    "for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "    in_text_citations = get_in_text_citations(text.item())\n",
    "    cleaned_in_text_citations = [\n",
    "        \n",
    "        item \n",
    "        \n",
    "        for group in \n",
    "    \n",
    "        [\n",
    "            re.sub(r\"\\(|\\)|see also|’s\", \"\", item).split(\",\")\n",
    "            for item in in_text_citations\n",
    "        ]\n",
    "        \n",
    "        for item in group\n",
    "        \n",
    "    ]\n",
    "    # print(cleaned_in_text_citations)\n",
    "    author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "    # pprint.pprint(author_year_pairs)\n",
    "    # print(\"===\")\n",
    "    references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "    \n",
    "references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOM_HEADER_SIZE = 9.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if type(other) == str:\n",
    "            return self.content.strip() == other\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "    \n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract\", 0)\n",
    "\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    first_section = Section(\"Keywords\", 0)\n",
    "    first_index = sections.index(first_section)\n",
    "    sections = sections[first_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references = \" \".join(references_dirty.split())\n",
    "    pattern = \"[A-Z][A-Za-z, ]+[A-Z]{1,3}\\. \\d{4}\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    \n",
    "    for idx, ref in enumerate(references_clean):\n",
    "        if idx == len(references_clean) - 1:\n",
    "            # All the way to the end\n",
    "            references_clean[idx] = references[references.find(ref):]\n",
    "        else:\n",
    "            next_ref = references_clean[idx+1]\n",
    "            references_clean[idx] = references[references.find(ref):references.find(next_ref)]\n",
    "\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \"&\" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\"&\")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_doc_by_size_and_font(doc):\n",
    "    first_page_fonts = {}\n",
    "    rest_fonts = {}\n",
    "    seqs = []\n",
    "    prev_size, prev_font = 0,0\n",
    "    for page in doc:      \n",
    "        d = page.get_text(\"dict\")\n",
    "        blocks = d[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" in block.keys():\n",
    "                spans = block['lines']\n",
    "                for span in spans:\n",
    "                    data = span['spans']\n",
    "                    for lines in data:                            \n",
    "\n",
    "                        cur_size = round(lines['size'], 2)\n",
    "                        cur_font = lines['font'].split(\"+\")[0]\n",
    "\n",
    "                        key = (cur_font, cur_size)\n",
    "                        # print(lines['text'], key)\n",
    "\n",
    "                        if cur_size == prev_size and cur_font == prev_font:\n",
    "                            latest_item = rest_fonts[key][-1]\n",
    "                            \n",
    "                            if page.number == 0:\n",
    "                                first_page_fonts[key][-1] = latest_item + \" \" + lines['text']  \n",
    "                                \n",
    "                            rest_fonts[key][-1] = latest_item + \" \" + lines['text']  \n",
    "                            seqs[-1] = seqs[-1] + \" \" + lines['text']\n",
    "                            \n",
    "                        else:   \n",
    "                            if page.number == 0:\n",
    "                                first_page_fonts[key] = first_page_fonts.get(key, []) + [lines['text']]\n",
    "                            rest_fonts[key] = rest_fonts.get(key, []) + [lines['text']]\n",
    "                            seqs.append(lines['text'])\n",
    "\n",
    "                        prev_size = cur_size\n",
    "                        prev_font = cur_font\n",
    "    \n",
    "    sorted_first_page_fonts = dict(sorted(first_page_fonts.items(), key = lambda x: x[0][1], reverse = True))\n",
    "    sorted_rest_fonts = dict(sorted(rest_fonts.items(), key = lambda x: x[0][1], reverse = True))\n",
    "    return seqs, sorted_first_page_fonts, sorted_rest_fonts\n",
    "\n",
    "def get_headers(fonts):\n",
    "    \"\"\"Returns list of text (headers) that has size equal to AOM-standard headers\"\"\"\n",
    "    for key, val in fonts.items():\n",
    "        font, size = key\n",
    "        if size == AOM_HEADER_SIZE:\n",
    "            return val[1:]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_abstract(first_page_fonts):\n",
    "    first_page_fonts = dict(reversed(first_page_fonts.items()))\n",
    "    dict_items = first_page_fonts.items()\n",
    "    for idx, ((font, font_size), blocks) in enumerate(dict_items):\n",
    "        # Get item right before authors\n",
    "        if font_size == AOM_HEADER_SIZE:\n",
    "            return {\"Abstract\": list(dict_items)[idx-1][1][0]}\n",
    "            \n",
    "    return first_page_fonts\n",
    "\n",
    "    \n",
    "\n",
    "def get_text_nest(seqs, starting_text_nest, pdf_headers):\n",
    "    cur_header = \"Intro\"\n",
    "    for sequence in seqs:\n",
    "        if sequence in pdf_headers:\n",
    "            starting_text_nest[sequence] = \"\"\n",
    "            cur_header = sequence\n",
    "        else:\n",
    "            starting_text_nest[cur_header] = starting_text_nest.get(cur_header, \"\") + \" \" + sequence      \n",
    "    return starting_text_nest\n",
    "\n",
    "def get_sections(doc):\n",
    "    seqs, first_page_fonts, rest_fonts = structure_doc_by_size_and_font(doc)\n",
    "    starting_text_nest = get_abstract(first_page_fonts)\n",
    "    pdf_headers = get_headers(rest_fonts)\n",
    "    text_nest = get_text_nest(seqs, starting_text_nest, pdf_headers)\n",
    "    return text_nest\n",
    "\n",
    "def make_sections_dataframe(doc):\n",
    "    text_nest = get_sections(doc)\n",
    "    sections_df = pd.DataFrame(text_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return text_nest, sections_df\n",
    "\n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if year in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "def process_citations(citation_group:str) -> (list,str):\n",
    "    citations = citation_group.split(\";\")\n",
    "    for citation in citations:\n",
    "        try:\n",
    "            # case 1: & \n",
    "            if \"&\" in citation:\n",
    "                tokens = citation.split(\",\")\n",
    "                year = tokens[-1]\n",
    "                names = \",\".join(tokens[:-1])\n",
    "                names = names.replace(\"&\", \",\")\n",
    "                names_split = names.split(\",\")\n",
    "                return ([name.strip() for name in names_split if name.strip() not in (\"\", \"e.g.\")], year.strip())\n",
    "\n",
    "            # case 2: et al\n",
    "            if \"et al.\" in citation:\n",
    "                citation = citation.replace(\"et al.\", \"\")\n",
    "                tokens = citation.split(\",\")\n",
    "                return ([token.strip() for token in tokens[:-1] if token.strip() != \"\" ], tokens[-1].strip())\n",
    "\n",
    "            # case 3: 1 author\n",
    "            else:\n",
    "                if \"(\" in citation:\n",
    "                    author, year = citation.split()\n",
    "                    return ([author], year[1:-1])\n",
    "                else:\n",
    "                    citation_split = citation.split(\",\")\n",
    "                    return ([citation_split[-2]], citation_split[-1])\n",
    "        except:\n",
    "            return ([\"\"], \"\")\n",
    "                \n",
    "                \n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references = \" \".join(references_dirty.split())\n",
    "    pattern = \"[A-Z][a-z]+, [A-Z]*[A-Za-z,\\-’&.ˇ ]*[A-Z]{1,3}\\.\\s\\d{4}\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    \n",
    "    for idx, ref in enumerate(references_clean):\n",
    "        if idx == len(references_clean) - 1:\n",
    "            # All the way to the end\n",
    "            references_clean[idx] = references[references.find(ref):]\n",
    "        else:\n",
    "            next_ref = references_clean[idx+1]\n",
    "            references_clean[idx] = references[references.find(ref):references.find(next_ref)]\n",
    "\n",
    "    return references_clean\n",
    "\n",
    "def make_references_dataframe(text_nest, sections_df):\n",
    "    references_dictionary = {}\n",
    "    references_clean = text_preprocess_for_reference_matching(text_nest[\"REFERENCES\"])\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            citation \n",
    "            if citation[0] != \"(\"\n",
    "            else citation[1:-1]\n",
    "            for citation in in_text_citations \n",
    "\n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))        \n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_PARANTHESES_CITATION_REGEX = r\"\\([&\\w\\s.,\\-; ]+\\s\\d{3,4}\\)\"\n",
    "    AND_PATTERN = \"\\S+ & \\S+ \\(\\d{3,4}\\)\"\n",
    "    ONE_PATTERN = \"[A-Z]\\S+ \\(\\d{3,4}\\)\"\n",
    "    ET_AL_PATTERN = \"[A-Z][a-z] et al. \\(\\d{3,4}\\)\"\n",
    "    IN_TEXT_CITATION_REGEX = f\"{IN_PARANTHESES_CITATION_REGEX}|{AND_PATTERN}|{ONE_PATTERN}|{ET_AL_PATTERN}\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def convert_pdf_to_dataframes(doc):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(doc)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document('../data/aom/amr.2016.0338.pdf')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstract</th>\n",
       "      <td>Managing constellations of employee relationsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intro</th>\n",
       "      <td>Q  Academy of Management Review 2018, Vol. 43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE INTERPLAY BEWTEEN HRM AND INTRAORGANIZATIONAL NETWORKS</th>\n",
       "      <td>Current approaches to classifying HR practice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES AND SOCIAL NETWORK STOCKS AND FLOWS</th>\n",
       "      <td>Whereas in previous frameworks researchers ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network Composition – Modifying HR Practices</th>\n",
       "      <td>One critical aspect of the HR function is to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TABLE 1 Framework of HR Practices and Network Modifications</th>\n",
       "      <td>Network-Modifying Dimensions Definition Netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network Configuration – Modifying HR Practices</th>\n",
       "      <td>HR practices such as work design, training an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network Content – Modifying HR Practices</th>\n",
       "      <td>HR practices such as performance manage- ment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A RELATIONAL IDENTITY VIEW OF NETWORK-MODIFYING HR PRACTICES</th>\n",
       "      <td>Roles are fundamental building blocks of or- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE IMPACT OF NETWORK-MODIFYING HR PRACTICES ON RELATIONAL IDENTITY DISRUPTION AND JOB PERFORMANCE</th>\n",
       "      <td>Individual behavior can be understood as a fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TABLE 2 Illustrative Associations Between HR Practices and Network Characteristics</th>\n",
       "      <td>a Network-Modifying Dimension HR Practice Cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIGURE 1 The Influence of HR Practices and Network Modifications on Relational Identity Disruption and Individual Performance</th>\n",
       "      <td>P2, P4, P6 Network composition– modifying HR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network Composition – Modifying HR Practices, Identity Disruption, and Performance</th>\n",
       "      <td>Revisiting our framework of HR practices, net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network Configuration – Modifying HR Practices, Identity Disruption, and Performance</th>\n",
       "      <td>Extending our assertion that network configur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network Content – Modifying HR Practices, Identity Disruption, and Performance</th>\n",
       "      <td>Network content – modifying HR practices alte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Role Clarity As a Boundary Condition of the Relational Identity – Performance Link</th>\n",
       "      <td>Recognizing the complex ways HR-induced relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISCUSSION</th>\n",
       "      <td>In light of changes to the nature of work tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theoretical Implications</th>\n",
       "      <td>In viewing the interplay of HR and social net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theoretical Extensions</th>\n",
       "      <td>Our theory lends itself to two critical theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptions of HR practices.</th>\n",
       "      <td>Our theorizing suggests that network-modifyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multilevel phenomena.</th>\n",
       "      <td>Although we largely focused on individual re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Implications for Measurement and Analysis</th>\n",
       "      <td>Perhaps the most pronounced methodological im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Practical Implications</th>\n",
       "      <td>From a practical perspective, our framework p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONCLUSION</th>\n",
       "      <td>Altogether, our framework of network-modifyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFERENCES</th>\n",
       "      <td>Abell, P., Felin, T., &amp; Foss, N. 2008. Buildi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text\n",
       "Abstract                                            Managing constellations of employee relationsh...\n",
       "Intro                                                Q  Academy of Management Review 2018, Vol. 43...\n",
       "THE INTERPLAY BEWTEEN HRM AND INTRAORGANIZATION...   Current approaches to classifying HR practice...\n",
       "A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES A...   Whereas in previous frameworks researchers ha...\n",
       "Network Composition – Modifying HR Practices         One critical aspect of the HR function is to ...\n",
       "TABLE 1 Framework of HR Practices and Network M...   Network-Modifying Dimensions Definition Netwo...\n",
       "Network Configuration – Modifying HR Practices       HR practices such as work design, training an...\n",
       "Network Content – Modifying HR Practices             HR practices such as performance manage- ment...\n",
       "A RELATIONAL IDENTITY VIEW OF NETWORK-MODIFYING...   Roles are fundamental building blocks of or- ...\n",
       "THE IMPACT OF NETWORK-MODIFYING HR PRACTICES ON...   Individual behavior can be understood as a fu...\n",
       "TABLE 2 Illustrative Associations Between HR Pr...   a Network-Modifying Dimension HR Practice Cat...\n",
       "FIGURE 1 The Influence of HR Practices and Netw...   P2, P4, P6 Network composition– modifying HR ...\n",
       "Network Composition – Modifying HR Practices, I...   Revisiting our framework of HR practices, net...\n",
       "Network Configuration – Modifying HR Practices,...   Extending our assertion that network configur...\n",
       "Network Content – Modifying HR Practices, Ident...   Network content – modifying HR practices alte...\n",
       "Role Clarity As a Boundary Condition of the Rel...   Recognizing the complex ways HR-induced relat...\n",
       "DISCUSSION                                           In light of changes to the nature of work tha...\n",
       "Theoretical Implications                             In viewing the interplay of HR and social net...\n",
       "Theoretical Extensions                               Our theory lends itself to two critical theor...\n",
       "Perceptions of HR practices.                          Our theorizing suggests that network-modifyi...\n",
       "Multilevel phenomena.                                 Although we largely focused on individual re...\n",
       "Implications for Measurement and Analysis            Perhaps the most pronounced methodological im...\n",
       "Practical Implications                               From a practical perspective, our framework p...\n",
       "CONCLUSION                                           Altogether, our framework of network-modifyin...\n",
       "REFERENCES                                           Abell, P., Felin, T., & Foss, N. 2008. Buildi..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nyberg, A. J., Moliterno, T. P., Hale, D., &amp; L...</td>\n",
       "      <td>Intro,A FRAMEWORK OF NETWORK-MODIFYING HR PRAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Becker, B. E., &amp; Huselid, M. A. 1998. High per...</td>\n",
       "      <td>Intro,A FRAMEWORK OF NETWORK-MODIFYING HR PRAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adler, P. S., &amp; Kwon, S. 2002. Social capital:...</td>\n",
       "      <td>Intro,THE INTERPLAY BEWTEEN HRM AND INTRAORGAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jiang, J. Y., &amp; Liu, C.-W. 2015. High performa...</td>\n",
       "      <td>Intro,A FRAMEWORK OF NETWORK-MODIFYING HR PRAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Collins, C. J., &amp; Clark, K. D. 2003. Strategic...</td>\n",
       "      <td>Intro,THE INTERPLAY BEWTEEN HRM AND INTRAORGAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Uzzi, B. 1997. Social structure and competitio...</td>\n",
       "      <td>A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Wasserman, S., &amp; Faust, K. 1994. Social networ...</td>\n",
       "      <td>A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Wright, P. M., &amp; Boswell, W. R. 2002. Desegreg...</td>\n",
       "      <td>A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Wright, P. M., &amp; McMahan, G. C. 1992. Theoreti...</td>\n",
       "      <td>A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Zou, X., &amp; Ingram, P. 2013. The grand duality:...</td>\n",
       "      <td>A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reference   \n",
       "0    Nyberg, A. J., Moliterno, T. P., Hale, D., & L...  \\\n",
       "1    Becker, B. E., & Huselid, M. A. 1998. High per...   \n",
       "2    Adler, P. S., & Kwon, S. 2002. Social capital:...   \n",
       "3    Jiang, J. Y., & Liu, C.-W. 2015. High performa...   \n",
       "4    Collins, C. J., & Clark, K. D. 2003. Strategic...   \n",
       "..                                                 ...   \n",
       "193  Uzzi, B. 1997. Social structure and competitio...   \n",
       "194  Wasserman, S., & Faust, K. 1994. Social networ...   \n",
       "195  Wright, P. M., & Boswell, W. R. 2002. Desegreg...   \n",
       "196  Wright, P. M., & McMahan, G. C. 1992. Theoreti...   \n",
       "197  Zou, X., & Ingram, P. 2013. The grand duality:...   \n",
       "\n",
       "                                               section  \n",
       "0    Intro,A FRAMEWORK OF NETWORK-MODIFYING HR PRAC...  \n",
       "1    Intro,A FRAMEWORK OF NETWORK-MODIFYING HR PRAC...  \n",
       "2    Intro,THE INTERPLAY BEWTEEN HRM AND INTRAORGAN...  \n",
       "3    Intro,A FRAMEWORK OF NETWORK-MODIFYING HR PRAC...  \n",
       "4    Intro,THE INTERPLAY BEWTEEN HRM AND INTRAORGAN...  \n",
       "..                                                 ...  \n",
       "193  A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...  \n",
       "194  A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...  \n",
       "195  A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...  \n",
       "196  A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...  \n",
       "197  A FRAMEWORK OF NETWORK-MODIFYING HR PRACTICES ...  \n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import fitz\n",
    "from IPython.display import display\n",
    "\n",
    "aom_path = \"../data/aom\"\n",
    "aom_pdfs = [f for f in os.listdir(aom_path) if f.endswith('pdf')]\n",
    "\n",
    "fonts = {}\n",
    "path = os.path.join(aom_path, aom_pdfs[5])\n",
    "doc = fitz.open(path) # open a document\n",
    "print(doc)\n",
    "display(*convert_pdf_to_dataframes(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOM PROD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "AOM_HEADER_SIZE = (9.96, 10.0)\n",
    "\n",
    "\n",
    "def structure_doc_by_size_and_font(doc):\n",
    "    \"\"\"Extracts text spans, fonts, and sizes from a PDF document.\n",
    "\n",
    "    Args:\n",
    "        doc (pdfplumber.pdf.PDF): The PDF document to process.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three elements:\n",
    "            - list: A list of text spans in the document.\n",
    "            - dict: A dictionary of text spans on the first page, grouped by font size.\n",
    "            - dict: A dictionary of text spans on the remaining pages, grouped by font size.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        first_page_fonts = {}\n",
    "        rest_fonts = {}\n",
    "        seqs = []\n",
    "        prev_size, prev_font = 0, 0\n",
    "        for page in doc:\n",
    "            d = page.get_text(\"dict\")\n",
    "            blocks = d[\"blocks\"]\n",
    "            for block in blocks:\n",
    "                if \"lines\" in block.keys():\n",
    "                    spans = block[\"lines\"]\n",
    "                    for span in spans:\n",
    "                        data = span[\"spans\"]\n",
    "                        for lines in data:\n",
    "                            cur_size = round(lines[\"size\"], 2)\n",
    "                            cur_font = lines[\"font\"].split(\"+\")[0]\n",
    "\n",
    "                            key = (cur_font, cur_size)\n",
    "\n",
    "                            if cur_size == prev_size and cur_font == prev_font:\n",
    "                                latest_item = rest_fonts[key][-1]\n",
    "\n",
    "                                if page.number == 0:\n",
    "                                    first_page_fonts[key][-1] = (\n",
    "                                        latest_item + \" \" + lines[\"text\"]\n",
    "                                    )\n",
    "\n",
    "                                rest_fonts[key][-1] = latest_item + \" \" + lines[\"text\"]\n",
    "                                seqs[-1] = seqs[-1] + \" \" + lines[\"text\"]\n",
    "\n",
    "                            else:\n",
    "                                if page.number == 0:\n",
    "                                    first_page_fonts[key] = first_page_fonts.get(\n",
    "                                        key, []\n",
    "                                    ) + [lines[\"text\"]]\n",
    "                                rest_fonts[key] = rest_fonts.get(key, []) + [\n",
    "                                    lines[\"text\"]\n",
    "                                ]\n",
    "                                seqs.append(lines[\"text\"])\n",
    "\n",
    "                            prev_size = cur_size\n",
    "                            prev_font = cur_font\n",
    "\n",
    "        sorted_first_page_fonts = dict(\n",
    "            sorted(first_page_fonts.items(), key=lambda x: x[0][1], reverse=True)\n",
    "        )\n",
    "        sorted_rest_fonts = dict(\n",
    "            sorted(rest_fonts.items(), key=lambda x: x[0][1], reverse=True)\n",
    "        )\n",
    "        return seqs, sorted_first_page_fonts, sorted_rest_fonts\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'structure_doc_by_size_and_font': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_headers(fonts):\n",
    "    \"\"\"Extracts AOM-standard headers from the given fonts dictionary.\n",
    "\n",
    "    Args:\n",
    "        fonts (dict): A dictionary of text spans grouped by font size.\n",
    "\n",
    "    Returns:\n",
    "        list or None: A list of text spans with the size equal to AOM-standard headers,\n",
    "            or None if no such headers are found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for key, val in fonts.items():\n",
    "            font, size = key\n",
    "            if size in AOM_HEADER_SIZE:\n",
    "                return val[1:]  # Skipping the first item as it is often empty.\n",
    "        logger.error(\"get_headers: Headers not found!\")\n",
    "        return []\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'get_headers': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_abstract(first_page_fonts):\n",
    "    \"\"\"Extracts the abstract text from the first page fonts.\n",
    "\n",
    "    Args:\n",
    "        first_page_fonts (dict): A dictionary of text spans on the first page, grouped by font size.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the abstract text under the key 'Abstract'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        first_page_fonts = dict(reversed(first_page_fonts.items()))\n",
    "        dict_items = first_page_fonts.items()\n",
    "        for idx, ((font, font_size), blocks) in enumerate(dict_items):\n",
    "            # Get item right before authors\n",
    "            if font_size in AOM_HEADER_SIZE:\n",
    "                return {\"Abstract\": list(dict_items)[idx - 1][1][0]}\n",
    "\n",
    "        return first_page_fonts\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'get_abstract': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_text_nest(seqs, starting_text_nest, pdf_headers):\n",
    "    \"\"\"Groups the sequences of text based on matching PDF headers.\n",
    "\n",
    "    Args:\n",
    "        seqs (list): A list of text sequences.\n",
    "        starting_text_nest (dict): A dictionary containing the abstract text.\n",
    "        pdf_headers (list): A list of PDF headers.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the grouped text sequences.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cur_header = \"Intro\"\n",
    "        for sequence in seqs:\n",
    "            if sequence in pdf_headers:\n",
    "                starting_text_nest[sequence] = \"\"\n",
    "                cur_header = sequence\n",
    "            else:\n",
    "                starting_text_nest[cur_header] = (\n",
    "                    starting_text_nest.get(cur_header, \"\") + \" \" + sequence\n",
    "                )\n",
    "        return starting_text_nest\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'get_text_nest': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_sections(doc):\n",
    "    \"\"\"Extracts sections from the PDF document.\n",
    "\n",
    "    Args:\n",
    "        doc (pdfplumber.pdf.PDF): The PDF document to process.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the grouped text sequences for each section.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        seqs, first_page_fonts, rest_fonts = structure_doc_by_size_and_font(doc)\n",
    "        starting_text_nest = get_abstract(first_page_fonts)\n",
    "        pdf_headers = get_headers(rest_fonts)\n",
    "        text_nest = get_text_nest(seqs, starting_text_nest, pdf_headers)\n",
    "        return text_nest\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'get_sections': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def make_sections_dataframe(doc):\n",
    "    \"\"\"Creates a DataFrame containing sections and their corresponding text.\n",
    "\n",
    "    Args:\n",
    "        doc (pdfplumber.pdf.PDF): The PDF document to process.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two elements:\n",
    "            - dict: A dictionary containing the grouped text sequences for each section.\n",
    "            - pandas.DataFrame: A DataFrame containing sections and their corresponding text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text_nest = get_sections(doc)\n",
    "        sections_df = pd.DataFrame(text_nest, index=[\"text\"]).T\n",
    "        sections_df.name = doc.name\n",
    "        return text_nest, sections_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'make_sections_dataframe': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    \"\"\"Finds citation matches in the references text.\n",
    "\n",
    "    Args:\n",
    "        author_year_pairs (list): List of tuples containing author names and years.\n",
    "        full_references (list): List of full references extracted from the text.\n",
    "        data (dict): A dictionary to store the matched citations.\n",
    "        location (str): The section location where the citations were found.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated data dictionary with matched citations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for author_year_pair in author_year_pairs:\n",
    "            authors, year = author_year_pair\n",
    "            for reference in full_references:\n",
    "                match = True\n",
    "                if year in reference:\n",
    "                    for author in authors:\n",
    "                        if author not in reference:\n",
    "                            match = False\n",
    "                    if match:\n",
    "                        dict_value = data.get(reference, [])\n",
    "                        if dict_value == []:\n",
    "                            data[reference] = []\n",
    "                        if location not in dict_value:\n",
    "                            data[reference] = data.get(reference, []) + [location]\n",
    "                else:\n",
    "                    continue\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'find_citation_matches': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def process_citations(citation_group: str):\n",
    "    \"\"\"Processes citation groups and extracts author-year pairs.\n",
    "\n",
    "    Args:\n",
    "        citation_group (str): A group of citations as a single string.\n",
    "\n",
    "    Returns:\n",
    "        list: List of author-year pairs for the citations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = []\n",
    "        citations = citation_group.split(\";\")\n",
    "        for citation in citations:\n",
    "            try:\n",
    "                # case 1: &\n",
    "                if \"&\" in citation:\n",
    "                    tokens = citation.split(\",\")\n",
    "                    year = tokens[-1]\n",
    "                    names = \",\".join(tokens[:-1])\n",
    "                    names = names.replace(\"&\", \",\")\n",
    "                    names_split = names.split(\",\")\n",
    "                    results.append(\n",
    "                        (\n",
    "                            [\n",
    "                                name.strip()\n",
    "                                for name in names_split\n",
    "                                if name.strip() not in (\"\", \"e.g.\")\n",
    "                            ],\n",
    "                            year.strip(),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                # case 2: et al\n",
    "                if \"et al.\" in citation:\n",
    "                    citation = citation.replace(\"et al.\", \"\")\n",
    "                    tokens = citation.split(\",\")\n",
    "                    results.append(\n",
    "                        (\n",
    "                            [\n",
    "                                token.strip()\n",
    "                                for token in tokens[:-1]\n",
    "                                if token.strip() != \"\"\n",
    "                            ],\n",
    "                            tokens[-1].strip(),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                # case 3: 1 author\n",
    "                else:\n",
    "                    if \"(\" in citation:\n",
    "                        author, year = citation.split()\n",
    "                        results.append(([author], year[1:-1]))\n",
    "                    else:\n",
    "                        citation_split = citation.split(\",\")\n",
    "                        results.append(\n",
    "                            ([citation_split[-2]], citation_split[-1].strip())\n",
    "                        )\n",
    "\n",
    "            except Exception as e:\n",
    "                # If any error occurs during citation processing, add an empty entry.\n",
    "                results.append(([\"\"], \"\"))\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'process_citations': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    \"\"\"Preprocesses the references text before matching citations.\n",
    "\n",
    "    Args:\n",
    "        references_text (str): The references text to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of cleaned references extracted from the text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # START searching ONCE References tag found\n",
    "        references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "        references = \" \".join(references_dirty.split())\n",
    "        pattern = \"[A-Z][a-z]+, [A-Z]*[A-Za-z,\\-’&.ˇ ]*[A-Z]{1,3}\\.\\s\\d{4}\\.\"\n",
    "        references_clean = re.findall(pattern, references)\n",
    "\n",
    "        for idx, ref in enumerate(references_clean):\n",
    "            if idx == len(references_clean) - 1:\n",
    "                # All the way to the end\n",
    "                references_clean[idx] = references[references.find(ref) :]\n",
    "            else:\n",
    "                next_ref = references_clean[idx + 1]\n",
    "                references_clean[idx] = references[\n",
    "                    references.find(ref) : references.find(next_ref)\n",
    "                ]\n",
    "\n",
    "        return references_clean\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"Error occurred in 'text_preprocess_for_reference_matching': {str(e)}\"\n",
    "        )\n",
    "        raise\n",
    "\n",
    "\n",
    "def make_references_dataframe(text_nest, sections_df):\n",
    "    \"\"\"Creates a DataFrame containing references and their corresponding sections.\n",
    "\n",
    "    Args:\n",
    "        text_nest (dict): A dictionary containing the grouped text sequences for each section.\n",
    "        sections_df (pandas.DataFrame): DataFrame containing sections and their corresponding text.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing references and their corresponding sections.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        references_dictionary = {}\n",
    "        references_clean = text_preprocess_for_reference_matching(text_nest[\"REFERENCES\"])\n",
    "        for location, text in zip(sections_df.index, sections_df.values):\n",
    "            if location != \"REFERENCES\":\n",
    "                in_text_citations = get_in_text_citations(text.item())\n",
    "                cleaned_in_text_citations = [\n",
    "                    citation if citation[0] != \"(\" else citation[1:-1]\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "                author_year_pairs_nested = list(\n",
    "                    filter(\n",
    "                        lambda x: x != None,\n",
    "                        map(process_citations, cleaned_in_text_citations),\n",
    "                    )\n",
    "                )\n",
    "                author_year_pairs = [\n",
    "                    item for group in author_year_pairs_nested for item in group\n",
    "                ]\n",
    "                references_dictionary = find_citation_matches(\n",
    "                    author_year_pairs, references_clean, references_dictionary, location\n",
    "                )\n",
    "\n",
    "        references_df = pd.DataFrame(\n",
    "            {k: [\",\".join(v)] for k, v in references_dictionary.items()}, index=[\"section\"]\n",
    "        ).T.reset_index(names=\"reference\")\n",
    "\n",
    "        return references_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'make_references_dataframe': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    \"\"\"Extracts in-text citations from the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to search for in-text citations.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of in-text citations found in the text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        IN_PARANTHESES_CITATION_REGEX = r\"\\([&\\w\\s.,\\-; ]+\\s\\d{3,4}\\)\"\n",
    "        AND_PATTERN = \"\\S+ & \\S+ \\(\\d{3,4}\\)\"\n",
    "        ONE_PATTERN = \"[A-Z]\\S+ \\(\\d{3,4}\\)\"\n",
    "        ET_AL_PATTERN = \"[A-Z][a-z] et al. \\(\\d{3,4}\\)\"\n",
    "        IN_TEXT_CITATION_REGEX = f\"{IN_PARANTHESES_CITATION_REGEX}|{AND_PATTERN}|{ONE_PATTERN}|{ET_AL_PATTERN}\"\n",
    "        return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'get_in_text_citations': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def convert_pdf_to_dataframes(doc):\n",
    "    \"\"\"Converts a PDF document into DataFrames for sections and references.\n",
    "\n",
    "    Args:\n",
    "        doc (pdfplumber.pdf.PDF): The PDF document to process.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two elements:\n",
    "            - pandas.DataFrame: DataFrame containing sections and their corresponding text.\n",
    "            - pandas.DataFrame: DataFrame containing references and their corresponding sections.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sections, sections_df = make_sections_dataframe(doc)\n",
    "        logger.info(\"Successfully made sections dataframe!\")\n",
    "        references_df = make_references_dataframe(sections, sections_df)\n",
    "        return sections_df, references_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred in 'convert_pdf_to_dataframes': {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-26 13:43:06.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mstructure_doc_by_size_and_font\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mStarting structure_doc_by_size_and_font...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mstructure_doc_by_size_and_font\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mSuccessfully finished structure_doc_by_size_and_font...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_abstract\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mStarting get_abstract...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_abstract\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mSuccessfully finished get_abstract...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_headers\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mStarting get_headers...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_headers\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mSuccessfully finished get_headers...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_text_nest\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mStarting get_text_nest...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_text_nest\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mSuccessfully finished get_text_nest...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mstructure_doc_by_size_and_font\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mStarting structure_doc_by_size_and_font...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mstructure_doc_by_size_and_font\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mSuccessfully finished structure_doc_by_size_and_font...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_abstract\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mStarting get_abstract...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_abstract\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mSuccessfully finished get_abstract...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_headers\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mStarting get_headers...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_headers\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mSuccessfully finished get_headers...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_text_nest\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mStarting get_text_nest...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_text_nest\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mSuccessfully finished get_text_nest...\u001b[0m\n",
      "\u001b[32m2023-07-26 13:43:06.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mconvert_pdf_to_dataframes\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mSuccessfully made sections dataframe!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document('../data/aom/amj.2011.0088.pdf')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstract</th>\n",
       "      <td>Drawing on the ability-motivation-opportunity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intro</th>\n",
       "      <td>HOW DOES HUMAN RESOURCE MANAGEMENT INFLUENCE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THEORETICAL BACKGROUND AND HYPOTHESES Existing Theories and Research on Relationships between HRM and Organizational Outcomes</th>\n",
       "      <td>Understanding the relationship between HRM an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decomposing HR Systems into Three HR Dimensions</th>\n",
       "      <td>Scholars have recently argued that although e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linking HR Dimensions to Multiple Outcomes</th>\n",
       "      <td>According to the ability-motivation-opportuni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METHODS Data Collection</th>\n",
       "      <td>We tested the mediating hypotheses with the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Operationalization of Variables</th>\n",
       "      <td>Three dimensions of HR systems.  We identifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-analytic and Model-Testing Procedures</th>\n",
       "      <td>To test the mediating model through meta-ana-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESULTS Differential Effects of HR Dimensions</th>\n",
       "      <td>Table 1 summarizes the correlation results of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mediation Results</th>\n",
       "      <td>Hypotheses 5 through 7 predict that the three...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIGURE 1 Theoretical Model of Effects of HR Dimensions on Organizational Outcomes</th>\n",
       "      <td>Skill-Enhancing  HR Practices  Motivation- En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIGURE 2 Final Model of Effects of HR Dimensions on Organizational Outcomes</th>\n",
       "      <td>a Human  Capital  R 2  = .22  Employee  Motiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISCUSSION</th>\n",
       "      <td>Our aim in this meta-analytic review is to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research Implications</th>\n",
       "      <td>This research offers a number of important th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIGURE 3 Theoretical Model of Effects of HPWS on Organizational Outcomes</th>\n",
       "      <td>Skill-Enhancing  HR Practices  Motivation- En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIGURE 4 Effects of HPWS on Organizational Outcomes</th>\n",
       "      <td>a .67**  Skill-Enhancing  HR Practices  Motiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Practical Implications</th>\n",
       "      <td>Our study also offers implications for manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Limitations and Future Research</th>\n",
       "      <td>Several limitations should be noted in the cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conclusions</th>\n",
       "      <td>This meta-analysis examined and extended the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFERENCES</th>\n",
       "      <td>a Agarwala, T. 2003. Innovative human resourc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APPENDIX</th>\n",
       "      <td>(Continued) Study Skill- Enhancing HR Practic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text\n",
       "Abstract                                            Drawing on the ability-motivation-opportunity ...\n",
       "Intro                                                HOW DOES HUMAN RESOURCE MANAGEMENT INFLUENCE ...\n",
       "THEORETICAL BACKGROUND AND HYPOTHESES Existing ...   Understanding the relationship between HRM an...\n",
       "Decomposing HR Systems into Three HR Dimensions      Scholars have recently argued that although e...\n",
       "Linking HR Dimensions to Multiple Outcomes           According to the ability-motivation-opportuni...\n",
       "METHODS Data Collection                              We tested the mediating hypotheses with the h...\n",
       "Operationalization of Variables                      Three dimensions of HR systems.  We identifie...\n",
       "Meta-analytic and Model-Testing Procedures           To test the mediating model through meta-ana-...\n",
       "RESULTS Differential Effects of HR Dimensions        Table 1 summarizes the correlation results of...\n",
       "Mediation Results                                    Hypotheses 5 through 7 predict that the three...\n",
       "FIGURE 1 Theoretical Model of Effects of HR Dim...   Skill-Enhancing  HR Practices  Motivation- En...\n",
       "FIGURE 2 Final Model of Effects of HR Dimension...   a Human  Capital  R 2  = .22  Employee  Motiv...\n",
       "DISCUSSION                                           Our aim in this meta-analytic review is to co...\n",
       "Research Implications                                This research offers a number of important th...\n",
       "FIGURE 3 Theoretical Model of Effects of HPWS o...   Skill-Enhancing  HR Practices  Motivation- En...\n",
       "FIGURE 4 Effects of HPWS on Organizational Outc...   a .67**  Skill-Enhancing  HR Practices  Motiv...\n",
       "Practical Implications                               Our study also offers implications for manage...\n",
       "Limitations and Future Research                      Several limitations should be noted in the cu...\n",
       "Conclusions                                          This meta-analysis examined and extended the ...\n",
       "REFERENCES                                           a Agarwala, T. 2003. Innovative human resourc...\n",
       "APPENDIX                                             (Continued) Study Skill- Enhancing HR Practic..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reference, section]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import fitz\n",
    "from IPython.display import display\n",
    "\n",
    "aom_path = \"../data/aom\"\n",
    "aom_pdfs = [f for f in os.listdir(aom_path) if f.endswith('pdf')]\n",
    "\n",
    "fonts = {}\n",
    "path = os.path.join(aom_path, aom_pdfs[6])\n",
    "doc = fitz.open(path) # open a document\n",
    "print(doc)\n",
    "text_nest = get_sections(doc)\n",
    "display(*convert_pdf_to_dataframes(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTRACT_KEY = ('AdvPSA35F', 10.0)\n",
    "HEADERS_KEY = ('AdvP2A83', 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sections_dataframe(doc):\n",
    "    text_nest = get_sections(doc)\n",
    "    sections_df = pd.DataFrame(text_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return text_nest, sections_df\n",
    "\n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if year in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def process_citations(citation_group:str):\n",
    "    citations = citation_group.split(\";\")\n",
    "    results = []\n",
    "    for citation in citations:\n",
    "        try:\n",
    "            # case 1: & \n",
    "            if \" and \" in citation:\n",
    "                tokens = citation.split(\",\")\n",
    "                year = tokens[-1]\n",
    "                names = \",\".join(tokens[:-1])\n",
    "                names = names.replace(\" and \", \",\")\n",
    "                names_split = names.split(\",\")\n",
    "                results.append(([name.strip() for name in names_split if name.strip() not in (\"\", \"e.g.\")], year.strip()))\n",
    "\n",
    "            # case 2: et al\n",
    "            if \"et al.\" in citation:\n",
    "                citation = citation.replace(\"et al.\", \"\")\n",
    "                tokens = citation.split(\",\")\n",
    "                results.append(([token.strip() for token in tokens[:-1] if token.strip() != \"\" ], tokens[-1].strip()))\n",
    "\n",
    "            # case 3: 1 author\n",
    "            else:\n",
    "                if \"(\" in citation:\n",
    "                    author, year = citation.split()\n",
    "                    results.append(([author], year[1:-1]))\n",
    "                else:\n",
    "                    citation_split = citation.split(\",\")\n",
    "                    results.append(([citation_split[-2]], citation_split[-1]))\n",
    "        except:\n",
    "            results.append(([\"\"], \"\"))\n",
    "    \n",
    "    return results\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "def remove_prefix(citation):\n",
    "    is_parantheses = False\n",
    "    for idx, char in enumerate(citation):\n",
    "        if char == \".\" and citation[idx - 1].islower() and not is_parantheses:\n",
    "            return citation[idx+2:]\n",
    "        if char == \"(\":\n",
    "            is_parantheses = True\n",
    "        if char == \")\":\n",
    "            is_parantheses = False\n",
    "            \n",
    "    return citation\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references = \" \".join(references_dirty.split())\n",
    "    pattern = \"[A-Z][A-Za-z,\\-’.ˇ() ]+ \\d{4} \"\n",
    "    references_clean = list(map(remove_prefix, re.findall(pattern, references)))\n",
    "\n",
    "    for idx, ref in enumerate(references_clean):\n",
    "        if idx == len(references_clean) - 1:\n",
    "            # All the way to the end\n",
    "            references_clean[idx] = references[references.find(ref):]\n",
    "        else:\n",
    "            next_ref = references_clean[idx+1]\n",
    "            references_clean[idx] = references[references.find(ref):references.find(next_ref)]\n",
    "\n",
    "    return references_clean\n",
    "\n",
    "def make_references_dataframe(text_nest, sections_df):\n",
    "    references_dictionary = {}\n",
    "    references_clean = text_preprocess_for_reference_matching(text_nest[\"REFERENCES\"])\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        # print(location, \"\\n\")\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        # print(in_text_citations)\n",
    "        cleaned_in_text_citations = [\n",
    "            citation \n",
    "            if citation[0] != \"(\"\n",
    "            else citation[1:-1]\n",
    "            for citation in in_text_citations \n",
    "\n",
    "        ]\n",
    "        author_year_pairs_nested = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))  \n",
    "        author_year_pairs = [item for group in author_year_pairs_nested for item in group]\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "        # print()\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    return references_df\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_PARANTHESES_CITATION_REGEX = r\"\\([&\\w\\s.,\\-; ]+\\s\\d{3,4}\\)\"\n",
    "    AND_PATTERN = \"\\S+ and \\S+ \\(\\d{3,4}\\)\"\n",
    "    ONE_PATTERN = \"[A-Z]\\S+ \\(\\d{3,4}\\)\"\n",
    "    ET_AL_PATTERN = \"[A-Z][a-z] et al. \\(\\d{3,4}\\)\"\n",
    "    IN_TEXT_CITATION_REGEX = f\"{IN_PARANTHESES_CITATION_REGEX}|{AND_PATTERN}|{ONE_PATTERN}|{ET_AL_PATTERN}\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def convert_pdf_to_dataframes(doc):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(doc)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df \n",
    "\n",
    "def structure_doc_by_size_and_font(doc):\n",
    "    # first_page_fonts = {}\n",
    "    rest_fonts = {}\n",
    "    seqs = []\n",
    "    prev_size, prev_font = 0,0\n",
    "    for page in doc:      \n",
    "        d = page.get_text(\"dict\")\n",
    "        blocks = d[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" in block.keys():\n",
    "                spans = block['lines']\n",
    "                for span in spans:\n",
    "                    data = span['spans']\n",
    "                    for lines in data:                            \n",
    "\n",
    "                        cur_size = round(lines['size'], 2)\n",
    "                        cur_font = lines['font'].split(\"+\")[0]\n",
    "\n",
    "                        key = (cur_font, cur_size)\n",
    "                        # print(lines['text'], key)\n",
    "\n",
    "                        if cur_size == prev_size and cur_font == prev_font:\n",
    "                            latest_item = rest_fonts[key][-1]\n",
    "                            \n",
    "                            # if page.number == 0:\n",
    "                                # first_page_fonts[key][-1] = latest_item + \" \" + lines['text']  \n",
    "                                \n",
    "                            rest_fonts[key][-1] = latest_item + \" \" + lines['text']  \n",
    "                            seqs[-1] = seqs[-1] + \" \" + lines['text']\n",
    "                            \n",
    "                        else:   \n",
    "                            # if page.number == 0:\n",
    "                                # first_page_fonts[key] = first_page_fonts.get(key, []) + [lines['text']]\n",
    "                            rest_fonts[key] = rest_fonts.get(key, []) + [lines['text']]\n",
    "                            seqs.append(lines['text'])\n",
    "\n",
    "                        prev_size = cur_size\n",
    "                        prev_font = cur_font\n",
    "    \n",
    "    # sorted_first_page_fonts = dict(sorted(first_page_fonts.items(), key = lambda x: x[0][1], reverse = True))\n",
    "    sorted_rest_fonts = sorted(rest_fonts.items(), key = lambda x: x[0][1], reverse = True)\n",
    "    return seqs, sorted_rest_fonts\n",
    "\n",
    "def get_headers(fonts):\n",
    "    \"\"\"Returns list of text (headers) that has size equal to AOM-standard headers\"\"\"\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    for key, val in fonts:\n",
    "        if key == ABSTRACT_KEY:\n",
    "            first_part = val\n",
    "        if key == HEADERS_KEY:\n",
    "            second_part = val\n",
    "    return first_part[:2] + second_part + first_part[2:]\n",
    "\n",
    "def find_earliest_uppercase_index(s):\n",
    "    for i, char in enumerate(s):\n",
    "        if char.isalpha() and char.upper() == char:\n",
    "            return i\n",
    "    return len(s)\n",
    "\n",
    "def get_text_nest(seqs, starting_text_nest, pdf_headers):\n",
    "    cur_header = \"Other\"\n",
    "    for sequence in seqs[1:]:\n",
    "        if sequence in pdf_headers:\n",
    "            starting_text_nest[sequence] = \"\"\n",
    "            cur_header = sequence\n",
    "        else:\n",
    "            if cur_header.startswith(\"Keyword\"):\n",
    "                earliest_idx = find_earliest_uppercase_index(sequence)\n",
    "                keyword_part = sequence[:earliest_idx]\n",
    "                intro_part = sequence[earliest_idx:]\n",
    "                starting_text_nest[cur_header] = starting_text_nest.get(cur_header, \"\") + \" \" + keyword_part   \n",
    "                cur_header = \"Introduction\"\n",
    "                starting_text_nest[cur_header] = starting_text_nest.get(cur_header, \"\") + \" \" + intro_part   \n",
    "            else:\n",
    "                starting_text_nest[cur_header] = starting_text_nest.get(cur_header, \"\") + \" \" + sequence   \n",
    "            \n",
    "    return starting_text_nest\n",
    "\n",
    "def get_sections(doc):\n",
    "    seqs, fonts = structure_doc_by_size_and_font(doc)\n",
    "    pdf_headers = get_headers(fonts)\n",
    "    text_nest = get_text_nest(seqs, {}, pdf_headers)\n",
    "    return text_nest\n",
    "\n",
    "def make_sections_dataframe(doc):\n",
    "    text_nest = get_sections(doc)\n",
    "    sections_df = pd.DataFrame(text_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return text_nest, sections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document('../data/asq/Feldberg_2022_ASQ_The Task Bind_ Explaining Gender Differences in Managerial Tasks and Performance.pdf')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bailyn, L. 1987 ‘‘Experiencing technical work:...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singh, R., N. A. Fouad, M. E. Fitzpatrick, J. ...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dresden, B. E., A. Y. Dresden, R. D. Ridge, an...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eagly, A. H., M. G. Makhijani, and B. G. Klons...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rudman, L. A., and P. Glick 2001 ‘‘Prescriptiv...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Wingfield, A. H., and R. S. Alston 2012 ‘‘The ...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Wrong, D. H. 1979 Power: Its Forms, Bases and ...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Yin, R. K. 2013 Case Study Research: Design an...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Zelek, B., and S. P. Phillips 2003 ‘‘Gender an...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Zhang, L., and D. Morand 2014 ‘‘The linkage be...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reference   \n",
       "0    Bailyn, L. 1987 ‘‘Experiencing technical work:...  \\\n",
       "1    Singh, R., N. A. Fouad, M. E. Fitzpatrick, J. ...   \n",
       "2    Dresden, B. E., A. Y. Dresden, R. D. Ridge, an...   \n",
       "3    Eagly, A. H., M. G. Makhijani, and B. G. Klons...   \n",
       "4    Rudman, L. A., and P. Glick 2001 ‘‘Prescriptiv...   \n",
       "..                                                 ...   \n",
       "118  Wingfield, A. H., and R. S. Alston 2012 ‘‘The ...   \n",
       "119  Wrong, D. H. 1979 Power: Its Forms, Bases and ...   \n",
       "120  Yin, R. K. 2013 Case Study Research: Design an...   \n",
       "121  Zelek, B., and S. P. Phillips 2003 ‘‘Gender an...   \n",
       "122  Zhang, L., and D. Morand 2014 ‘‘The linkage be...   \n",
       "\n",
       "                                               section  \n",
       "0    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "1    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "2    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "3    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "4    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "..                                                 ...  \n",
       "118  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "119  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "120  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "121  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "122  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "aom_path = \"../data/asq\"\n",
    "aom_pdfs = [f for f in os.listdir(aom_path) if f.endswith('pdf')]\n",
    "\n",
    "fonts = {}\n",
    "path = os.path.join(aom_path, aom_pdfs[1])\n",
    "doc = fitz.open(path) # open a document\n",
    "print(doc)\n",
    "\n",
    "convert_pdf_to_dataframes(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other \n",
      "\n",
      "[]\n",
      "\n",
      "Abstract \n",
      "\n",
      "[]\n",
      "\n",
      "Keywords: \n",
      "\n",
      "[]\n",
      "\n",
      "Introduction \n",
      "\n",
      "['(Bailyn, 1987; Robinson and McIlwee, 1991; Kanter, 2008; Kuehn, 2012)', '(Singh et al., 2013; Dresden et al., 2018)', '(Berger, Cohen, and Zelditch, 1972; Bailyn, 1987; Reskin, 1993; Fletcher, 1999; Ridgeway, 2001; Cech, 2013)', '(Eagly, Makhijani, and Klonsky, 1992; Heilman, 2001; Ridgeway, 2001; Rudman and Glick, 2001; Eagly and Karau, 2002; Heilman and Eagly, 2008; Rudman et al., 2012)', '(Ellemers et al., 2004; Sheppard and Aquino, 2013)', '(Halpern, 1992; Nancarrow and Borthwick, 2005; Ashcraft, 2007)', '(Freeland and Hoey, 2018)', '(Reskin, 1993)', '(Shaw et al., 2018)', '(Freeland and Hoey, 2018)', '(Lively, 2001)', '(Truelove and Kellogg, 2016)', '(DiBenigno and Kellogg, 2014)', '(McMurray, 2011)']\n",
      "\n",
      "CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATIONS \n",
      "\n",
      "['(Reskin, 1993; Acker, 1998; Ashcraft, 2013)', '(Treiman and Hartmann, 1981; Reskin and Roos, 1990)', '(Ridgeway and Berger, 1986; Berger, Ridgeway, and Zelditch, 2002)', '(Bailyn, 1987; Robinson and McIlwee, 1991; Fletcher, 1999; Cardador, 2017; Cheryan and Markus, 2020)', '(Berger, Ridgeway, and Zelditch, 2002; Ridgeway, 2014)', '(Ridgeway, 2001)', '(Kanter, 2008)', '(Bennett, Davidson, and Galeand, 1999; Powell, Bagilhole, and Dainty, 2009)', '(Cheryan and Markus, 2020)', '(Kanter, 2008)', '(Eisenhart and Finkel, 1998; Jorgenson, 2002; Faulkner, 2007)', '(Cole and Singer, 1991)', 'Heilman’s (1983)', 'Rudman and colleagues’ (2012)', 'Eagly and Karau’s (2002)', '(Heilman, 1983; Heilman, 2001; Gaucher, Friesen, and Kay, 2011)', '(Glick, Zion, and Nelson, 1988; Dodge, Gilroy, and Fenzel, 1995; Eagly and Karau, 2002)', '(Rudman and Kilianski, 2000)', '(Heilman, 2001; Rudman et al., 2012)', '(e.g., Derks et al., 2011; Duguid, 2011; Duguid, Loyd, and Tolbert, 2012)', '(Ely, 1994)', 'Sheppard and Aquino (2017)', '(see also Gibson and Lawrence, 2010; Duguid, Loyd, and Tolbert, 2012)', '(Parks-Stamm, Heilman, and Hearns, 2008; Sheppard and Aquino, 2013)', 'Eagly and Karau’s (2002)', 'Garcia-Retamero and Lo´pez-Zafra’s (2006)', '(Rudman and Glick, 2001)', '(Heilman and Okimoto, 2007)', '(Heilman et al., 2004)']\n",
      "\n",
      "SHARED DEMOGRAPHY IN CROSS-OCCUPATIONAL COLLABORATION \n",
      "\n",
      "['(Ashcraft, 2007)', '(Weber, 1978)', '(see also DiBenigno, 2020)', '(Weber, 1978; Abbott, 1988)', '(Wrong, 1979; Huising, 2015)', 'DiBenigno and Kellogg (2014)', 'DiBenigno and Kellogg’s (2014)', '(i.e., uncorrelated with occupational status; DiBenigno and Kellogg, 2014)']\n",
      "\n",
      "METHOD Research Context \n",
      "\n",
      "['(Sinclair, 1988)', '(Sweet and Norman, 1995)', '(Dingwall and McIntosh, 1978; Wallace and Abbott, 1990)', '(Kalisch and Kalisch, 1977; Wallace and Abbott, 1990)', '(Sweet and Norman, 1995)', '(e.g., Schneider, 2012; House and Havens, 2017)', '(Gittell, Godfrey, and Thistlethwaite, 2013)', '(Lancaster et al., 2015; Szafran et al., 2018)', '(Center for Health Ethics, 2020)', '(Eisenhardt, 1989; Dossett et al., 2020)', '(de Costa et al., 2018; Haskins, 2019)', '(Gjerberg and Kjølsrød, 2001)', '(National Council of State Boards of Nursing, 2020)', '(Cheryan and Markus, 2020)']\n",
      "\n",
      "Data Collection \n",
      "\n",
      "['(Robinson, 2014)', '(Lewis et al., 2012)', '(Eisenhardt, 1989)', '(Marshall and Rossman, 1989)', '(Strauss and Corbin, 1998)', '(Lincoln and Guba, 1985)', '(Spradley, 1979)']\n",
      "\n",
      "Data Analysis \n",
      "\n",
      "['(Strauss and Corbin, 1998)', '(Locke, 2001)', '(Locke, 2001)', '(Strauss and Corbin, 1998)']\n",
      "\n",
      "FINDINGS \n",
      "\n",
      "[]\n",
      "\n",
      "Nonsymmetrical Gendered Expectations for Status Equivalence \n",
      "\n",
      "[]\n",
      "\n",
      "Gendered expectations for authoritativeness. \n",
      "\n",
      "[]\n",
      "\n",
      "Gendered shows of respect. \n",
      "\n",
      "['(Zelek and Phillips, 2003)']\n",
      "\n",
      "Risks of Inter-Occupational Alienation \n",
      "\n",
      "[]\n",
      "\n",
      "Undermining organizational reputation. \n",
      "\n",
      "[]\n",
      "\n",
      "Undermining work. \n",
      "\n",
      "[]\n",
      "\n",
      "Status-Leveling Behaviors \n",
      "\n",
      "['(Cassell, 1997)']\n",
      "\n",
      "Relaxing task boundaries. \n",
      "\n",
      "['(Hughes, 1958; Huising, 2015)']\n",
      "\n",
      "Relaxing personal boundaries. \n",
      "\n",
      "[]\n",
      "\n",
      "Explaining the Effect of Status-Leveling Behaviors \n",
      "\n",
      "['(Pfeffer, 1995)', '(Pfeffer, 1995)', '(Hornstein, 2003)', 'Whitener and colleagues (1998)', '(Zhang and Morand, 2014)']\n",
      "\n",
      "Implications of Performing Status-Leveling Behaviors \n",
      "\n",
      "[]\n",
      "\n",
      "Positive implications: Increased professional effectiveness. \n",
      "\n",
      "[]\n",
      "\n",
      "Negative implications: Increased work demands. \n",
      "\n",
      "['(e.g., Grandey, 2000)', '(Jena, Olenski, and Blumenthal, 2016)']\n",
      "\n",
      "DISCUSSION \n",
      "\n",
      "[]\n",
      "\n",
      "Challenges to Women in Male-Dominated Occupations \n",
      "\n",
      "['(Cochran et al., 2013)', '(Cheryan and Markus, 2020)', '(i.e., feminine defaults; Cheryan and Markus, 2020)', '(Cheryan and Markus, 2020)', '(Heilman, 2001; Rudman and Glick, 2001)', '(Schwartz et al., 1992; Huising, 2015)']\n",
      "\n",
      "Cross-Occupational Collaboration \n",
      "\n",
      "['(Reskin, 1993; Ridgeway, 2001)', '(McPherson, Smith-Loven, and Cook, 2001)', 'DiBenigno and Kellogg (2014)', '(e.g., Crenshaw 1991; Parent, DeBlaere, and Moradi, 2013)', '(e.g., Weber, 1978; Abbott, 1988)', '(Abbott, 1988)', '(as suggested by prior research, e.g., Robinson and Mcllwee, 1991; Salles et al., 2019)', '(Richman, vanDellen, and Wood, 2011)', '(AAMC, 2020)', '(American Bar Association, 2020)']\n",
      "\n",
      "Practical Implications \n",
      "\n",
      "['(Gerull et al., 2019)', '(Ashburn-Nardo, 2018)', '(Sheppard and Aquino, 2013)', '(Tsugawa et al., 2017; Wallis et al., 2017)']\n",
      "\n",
      "Limitations and Future Directions \n",
      "\n",
      "['(Wharton and Baron, 1991)', '(Heilman, 2012)', '(Eagly and Johannesen-Schmidt, 2001)', '(Floge and Merrill, 1986)', '(Yin, 2013)', '(Pratt and Bonaccio, 2016)', '(e.g., Wingfield and Alston, 2012)']\n",
      "\n",
      "Conclusion \n",
      "\n",
      "[]\n",
      "\n",
      "Acknowledgments \n",
      "\n",
      "[]\n",
      "\n",
      "ORCID iDs \n",
      "\n",
      "[]\n",
      "\n",
      "Supplemental Material \n",
      "\n",
      "[]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bailyn, L. 1987 ‘‘Experiencing technical work:...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singh, R., N. A. Fouad, M. E. Fitzpatrick, J. ...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dresden, B. E., A. Y. Dresden, R. D. Ridge, an...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eagly, A. H., M. G. Makhijani, and B. G. Klons...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rudman, L. A., and P. Glick 2001 ‘‘Prescriptiv...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Wingfield, A. H., and R. S. Alston 2012 ‘‘The ...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Wrong, D. H. 1979 Power: Its Forms, Bases and ...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Yin, R. K. 2013 Case Study Research: Design an...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Zelek, B., and S. P. Phillips 2003 ‘‘Gender an...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Zhang, L., and D. Morand 2014 ‘‘The linkage be...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reference   \n",
       "0    Bailyn, L. 1987 ‘‘Experiencing technical work:...  \\\n",
       "1    Singh, R., N. A. Fouad, M. E. Fitzpatrick, J. ...   \n",
       "2    Dresden, B. E., A. Y. Dresden, R. D. Ridge, an...   \n",
       "3    Eagly, A. H., M. G. Makhijani, and B. G. Klons...   \n",
       "4    Rudman, L. A., and P. Glick 2001 ‘‘Prescriptiv...   \n",
       "..                                                 ...   \n",
       "118  Wingfield, A. H., and R. S. Alston 2012 ‘‘The ...   \n",
       "119  Wrong, D. H. 1979 Power: Its Forms, Bases and ...   \n",
       "120  Yin, R. K. 2013 Case Study Research: Design an...   \n",
       "121  Zelek, B., and S. P. Phillips 2003 ‘‘Gender an...   \n",
       "122  Zhang, L., and D. Morand 2014 ‘‘The linkage be...   \n",
       "\n",
       "                                               section  \n",
       "0    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "1    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "2    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "3    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "4    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "..                                                 ...  \n",
       "118  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "119  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "120  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "121  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "122  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_dictionary = {}\n",
    "references_clean = text_preprocess_for_reference_matching(text_nest[\"REFERENCES\"])\n",
    "for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "    print(location, \"\\n\")\n",
    "    in_text_citations = get_in_text_citations(text.item())\n",
    "    print(in_text_citations)\n",
    "    cleaned_in_text_citations = [\n",
    "        citation \n",
    "        if citation[0] != \"(\"\n",
    "        else citation[1:-1]\n",
    "        for citation in in_text_citations \n",
    "\n",
    "    ]\n",
    "    author_year_pairs_nested = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))  \n",
    "    author_year_pairs = [item for group in author_year_pairs_nested for item in group]\n",
    "    references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "    print()\n",
    "\n",
    "references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "references_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_references_dataframe(text_nest, sections_df):\n",
    "    references_dictionary = {}\n",
    "    references_clean = text_preprocess_for_reference_matching(text_nest[\"REFERENCES\"])\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            citation \n",
    "            if citation[0] != \"(\"\n",
    "            else citation[1:-1]\n",
    "            for citation in in_text_citations \n",
    "\n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))        \n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reference, section]\n",
       "Index: []"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_references_dataframe(sections, sections_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
