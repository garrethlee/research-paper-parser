{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrgSci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Keywords</th>\n",
       "      <td>[': status', 'status-quality coupling', 'netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abstract.</th>\n",
       "      <td>Abstract.\\n Previous research has demonstrated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Introduction</th>\n",
       "      <td>Introduction\\nResearch on social networks has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social Status and Network-Broadening</th>\n",
       "      <td>Social Status and Network-Broadening\\nResearch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Critical Enabler: Belief in Status-Quality Coupling</th>\n",
       "      <td>A Critical Enabler: Belief in Status-Quality C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network-Broadening Behavior and Network Size</th>\n",
       "      <td>Network-Broadening Behavior and Network Size\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research Overview</th>\n",
       "      <td>Research Overview\\nWe tested our hypotheses ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pilot Study: A Preliminary Demonstration of the Interaction Effect of Status X Coupling on Network Size in the GSS</th>\n",
       "      <td>Pilot Study: A Preliminary Demonstration of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 1: Status is Positively Associated with Network-Broadening</th>\n",
       "      <td>Study 1: Status is Positively Associated with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 2: Belief in Status-Quality Coupling Moderates the Relationship Between Status and Network-Broadening</th>\n",
       "      <td>Study 2: Belief in Status-Quality Coupling Mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 3: Testing the Indirect Effect of Status  ×  Coupling on Network Size via Network-Broadening</th>\n",
       "      <td>Study 3: Testing the Indirect Effect of Status...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 4: Testing the Causal Effect of Status and Coupling on Network-Broadening Intention</th>\n",
       "      <td>Study 4: Testing the Causal Effect of Status a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 5: Testing the Causal Effect of Status and Coupling on Network-Broadening Behavior</th>\n",
       "      <td>Study 5: Testing the Causal Effect of Status a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study 6: Mechanisms Test: Perceived Self-Value and Perceived Receptivity of the Networking Target</th>\n",
       "      <td>Study 6: Mechanisms Test: Perceived Self-Value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internal Meta-Analysis</th>\n",
       "      <td>Internal Meta-Analysis\\nWe performed an intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Discussion</th>\n",
       "      <td>General Discussion\\nAcross seven studies, we e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conclusion</th>\n",
       "      <td>Conclusion\\nOur paper offers a novel explanati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endnotes</th>\n",
       "      <td>Endnotes\\n1 \\n\\n  Among network researchers, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>References</th>\n",
       "      <td>References\\nAnderson C, Brown CE (2010) The fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text\n",
       "Keywords                                            [': status', 'status-quality coupling', 'netwo...\n",
       "Abstract.                                           Abstract.\\n Previous research has demonstrated...\n",
       "Introduction                                        Introduction\\nResearch on social networks has ...\n",
       "Social Status and Network-Broadening                Social Status and Network-Broadening\\nResearch...\n",
       "A Critical Enabler: Belief in Status-Quality Co...  A Critical Enabler: Belief in Status-Quality C...\n",
       "Network-Broadening Behavior and Network Size        Network-Broadening Behavior and Network Size\\n...\n",
       "Research Overview                                   Research Overview\\nWe tested our hypotheses ac...\n",
       "Pilot Study: A Preliminary Demonstration of the...  Pilot Study: A Preliminary Demonstration of th...\n",
       "Study 1: Status is Positively Associated with N...  Study 1: Status is Positively Associated with ...\n",
       "Study 2: Belief in Status-Quality Coupling Mode...  Study 2: Belief in Status-Quality Coupling Mod...\n",
       "Study 3: Testing the Indirect Effect of Status ...  Study 3: Testing the Indirect Effect of Status...\n",
       "Study 4: Testing the Causal Effect of Status an...  Study 4: Testing the Causal Effect of Status a...\n",
       "Study 5: Testing the Causal Effect of Status an...  Study 5: Testing the Causal Effect of Status a...\n",
       "Study 6: Mechanisms Test: Perceived Self-Value ...  Study 6: Mechanisms Test: Perceived Self-Value...\n",
       "Internal Meta-Analysis                              Internal Meta-Analysis\\nWe performed an intern...\n",
       "General Discussion                                  General Discussion\\nAcross seven studies, we e...\n",
       "Conclusion                                          Conclusion\\nOur paper offers a novel explanati...\n",
       "Endnotes                                            Endnotes\\n1 \\n\\n  Among network researchers, t...\n",
       "References                                          References\\nAnderson C, Brown CE (2010) The fu..."
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "\n",
    "\n",
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "    main_section   \n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        rect = Rect(page.rect.x0 + 40, page.rect.y0 + 60, page.rect.x1 - 40, page.rect.y1 - 40) \n",
    "        \n",
    "        dict = page.get_text(\"dict\", clip = rect)\n",
    "\n",
    "        blocks = dict[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" in block.keys():\n",
    "                spans = block['lines']\n",
    "                for span in spans:\n",
    "                    data = span['spans']\n",
    "                    for lines in data:\n",
    "                        cur_size = round(lines['size'], 1)\n",
    "\n",
    "                        # Manual Override for References\n",
    "                        if lines['text'].strip() in (\"Acknowledgements\", \"References\", \"Appendix\", \"Endnotes\"):\n",
    "                            cur = Section(lines['text'], cur_size)\n",
    "                            curr_section = main_section.children[-1].children[-1]\n",
    "                            curr_section.add_child(cur)\n",
    "                            cur.set_parent(curr_section)\n",
    "                            curr_section = cur\n",
    "\n",
    "                            prev_size = round(lines['size'], 1)\n",
    "\n",
    "                        elif cur_size > prev_size:\n",
    "                            curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                            prev_size = curr_section.size\n",
    "\n",
    "                        elif cur_size == prev_size:\n",
    "                            curr_section.extend(lines['text'])\n",
    "\n",
    "                        else:  \n",
    "                            cur = Section(lines['text'], cur_size)   \n",
    "                            curr_section.add_child(cur)\n",
    "                            cur.set_parent(curr_section)\n",
    "                            curr_section = cur\n",
    "                            prev_size = round(lines['size'], 1)\n",
    "\n",
    "    # orgsci                            \n",
    "    return main_section.children[-1].children[-1].children\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references_dirty = \" \".join(references_dirty.split())\n",
    "    references = re.sub(\"([0-9]|html|\\))\\s?\\.\", r\"\\g<0>\\n\", references_dirty)\n",
    "\n",
    "    # Make list of references\n",
    "    pattern = r\"[A-ZÆØÅæøå][ÆØÅæøåA-Za-z]+.*[A-Z]{1,3},? .*\\(\\d{4}\\).*[html|\\d|\\)]\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \" and \" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\" and \")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def convert_pdf_to_dataframes(path) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(path)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    add_new_section = False\n",
    "\n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract. \", 0)\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "\n",
    "    sections_tmp = sections.copy()\n",
    "    earliest_index = 1000\n",
    "    txt = \"\"\n",
    "    # pprint.pprint(sections[abstract_index:])\n",
    "    # Fit all text that belongs in paragraph into one \"Introduction\" paragraph\n",
    "    for idx, section in enumerate(sections_tmp):\n",
    "        if len(section.content) > 200:\n",
    "            print(section)\n",
    "            add_new_section = True\n",
    "            if min(earliest_index, idx) != earliest_index:\n",
    "                earliest_index = idx\n",
    "            sections.remove(section)\n",
    "            txt += section.content\n",
    "\n",
    "    if add_new_section:\n",
    "        new_section = Section(\"Introduction\", 20)\n",
    "        new_section.add_child(Section(txt, 15))\n",
    "        sections[earliest_index] = new_section\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "\n",
    "    return sections\n",
    "\n",
    "import fitz\n",
    "import os\n",
    "\n",
    "ORGSCI_PATH = \"../data/orgsci\"\n",
    "orgsci_pdfs = [f for f in os.listdir(ORGSCI_PATH) if f.endswith('pdf')]\n",
    "for i in range(len(orgsci_pdfs)):\n",
    "    path = os.path.join(ORGSCI_PATH, orgsci_pdfs[2])\n",
    "    sections_df, references_df = convert_pdf_to_dataframes(path)\n",
    "    abstract_text = sections_df.iloc[0].item()\n",
    "    abstract, keywords = abstract_text.split(\"Keywords\")\n",
    "    cleaned_keywords = [keyword.strip() for keyword in keywords.split(\"•\")]\n",
    "    new_row = pd.DataFrame({\"text\":str(cleaned_keywords)}, index = [\"Keywords\"])\n",
    "    sections_df = pd.concat([new_row, sections_df])\n",
    "\n",
    "sections_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annurev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if type(other) == str:\n",
    "            return self.content.strip() == other\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references_dirty = \" \".join(references_dirty.split())\n",
    "    references = re.sub(\"([0-9]|html|\\))\\s?\\.\", r\"\\g<0>\\n\", references_dirty)\n",
    "\n",
    "    # Make list of references\n",
    "    pattern = r\"[A-ZÆØÅæøå][ÆØÅæøåA-Za-z]+.*[A-Z]{1,3},? .*\\(\\d{4}\\).*[html|\\d|\\)]\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \" and \" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\" and \")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def convert_pdf_to_dataframes(path) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(path)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract\", 0)\n",
    "\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        if page.number not in (doc[-1].number, doc[-2].number):\n",
    "            rect = Rect(page.rect.x0 + 20, page.rect.y0 + 20, page.rect.x1 - 20, page.rect.y1 - 30)\n",
    "            \n",
    "            dict = page.get_text(\"dict\", clip = rect)\n",
    "            blocks = dict[\"blocks\"]\n",
    "            for block in blocks:\n",
    "                if \"lines\" in block.keys():\n",
    "                    spans = block['lines']\n",
    "                    for span in spans:\n",
    "                        data = span['spans']\n",
    "                        for lines in data:\n",
    "                            cur_size = round(lines['size'], 2)\n",
    "\n",
    "                            # Manual Override for References\n",
    "                            if lines['text'].strip() in (\"Abstract\", \"Keywords\", \"LITERATURE CITED\"):\n",
    "\n",
    "                                cur = Section(lines['text'], cur_size)\n",
    "                                curr_section = main_section.children[-1].children[-1]\n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "\n",
    "                                prev_size = round(lines['size'], 2)\n",
    "\n",
    "                            elif cur_size > prev_size:\n",
    "                                curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                                prev_size = curr_section.size\n",
    "\n",
    "                            elif cur_size == prev_size:\n",
    "                                curr_section.extend(lines['text'])\n",
    "\n",
    "                            else:  \n",
    "                                cur = Section(lines['text'], cur_size)   \n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "                                prev_size = round(lines['size'], 2)\n",
    "\n",
    "\n",
    "    final_sections = main_section.children[-1].children\n",
    "    \n",
    "    if len(final_sections) > 1:\n",
    "        return final_sections[-2].children + final_sections[-1].children\n",
    "    else:\n",
    "        return final_sections[-1].children\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    first_section = Section(\"Keywords\", 0)\n",
    "    first_index = sections.index(first_section)\n",
    "    sections = sections[first_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references = \" \".join(references_dirty.split())\n",
    "    pattern = \"[A-Z][A-Za-z, ]+[A-Z]{1,3}\\. \\d{4}\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    \n",
    "    for idx, ref in enumerate(references_clean):\n",
    "        if idx == len(references_clean) - 1:\n",
    "            # All the way to the end\n",
    "            references_clean[idx] = references[references.find(ref):]\n",
    "        else:\n",
    "            next_ref = references_clean[idx+1]\n",
    "            references_clean[idx] = references[references.find(ref):references.find(next_ref)]\n",
    "\n",
    "    return references_clean\n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_PARANTHESES_CITATION_REGEX = r\"\\([&\\w\\s., ]+\\s\\d{3,4}\\)\"\n",
    "    AND_PATTERN = \"\\S+ & \\S+ \\(\\d{3,4}\\)\"\n",
    "    ONE_PATTERN = \"[A-Z]\\S+ \\(\\d{3,4}\\)\"\n",
    "    ET_AL_PATTERN = \"[A-Z][a-z] et al. \\(\\d{3,4}\\)\"\n",
    "    IN_TEXT_CITATION_REGEX = f\"{IN_PARANTHESES_CITATION_REGEX}|{AND_PATTERN}|{ONE_PATTERN}|{ET_AL_PATTERN}\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \"&\" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\"&\")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if year in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_text = sections[sections.index(\"LITERATURE CITED\")].print_contents()\n",
    "    references_clean = text_preprocess_for_reference_matching(references_text)\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "\n",
    "            item \n",
    "\n",
    "            for group in \n",
    "\n",
    "            [\n",
    "                re.sub(r\"\\(|\\)|see also|’s\", \"\", item).split(\",\")\n",
    "                for item in in_text_citations\n",
    "            ]\n",
    "\n",
    "            for item in group\n",
    "\n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    return references_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pprint\n",
    "# from IPython.display import display\n",
    "\n",
    "# annurev_path = \"../data/annurev-orgpsych\"\n",
    "# annurev_pdfs = [f for f in os.listdir(annurev_path) if f.endswith('pdf')]\n",
    "# for i in range(len(annurev_pdfs)):\n",
    "#     sections_df, references_df = convert_pdf_to_dataframes(os.path.join(annurev_path, annurev_pdfs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_dictionary = {}\n",
    "references_text = sections[sections.index(\"LITERATURE CITED\")].print_contents()\n",
    "references_clean = text_preprocess_for_reference_matching(references_text)\n",
    "for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "    in_text_citations = get_in_text_citations(text.item())\n",
    "    cleaned_in_text_citations = [\n",
    "        \n",
    "        item \n",
    "        \n",
    "        for group in \n",
    "    \n",
    "        [\n",
    "            re.sub(r\"\\(|\\)|see also|’s\", \"\", item).split(\",\")\n",
    "            for item in in_text_citations\n",
    "        ]\n",
    "        \n",
    "        for item in group\n",
    "        \n",
    "    ]\n",
    "    # print(cleaned_in_text_citations)\n",
    "    author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "    # pprint.pprint(author_year_pairs)\n",
    "    # print(\"===\")\n",
    "    references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "    \n",
    "references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOM_HEADER_SIZE = 9.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if type(other) == str:\n",
    "            return self.content.strip() == other\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "    \n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract\", 0)\n",
    "\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    first_section = Section(\"Keywords\", 0)\n",
    "    first_index = sections.index(first_section)\n",
    "    sections = sections[first_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references = \" \".join(references_dirty.split())\n",
    "    pattern = \"[A-Z][A-Za-z, ]+[A-Z]{1,3}\\. \\d{4}\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    \n",
    "    for idx, ref in enumerate(references_clean):\n",
    "        if idx == len(references_clean) - 1:\n",
    "            # All the way to the end\n",
    "            references_clean[idx] = references[references.find(ref):]\n",
    "        else:\n",
    "            next_ref = references_clean[idx+1]\n",
    "            references_clean[idx] = references[references.find(ref):references.find(next_ref)]\n",
    "\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \"&\" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\"&\")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_doc_by_size_and_font(doc):\n",
    "    first_page_fonts = {}\n",
    "    rest_fonts = {}\n",
    "    seqs = []\n",
    "    prev_size, prev_font = 0,0\n",
    "    for page in doc:      \n",
    "        d = page.get_text(\"dict\")\n",
    "        blocks = d[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" in block.keys():\n",
    "                spans = block['lines']\n",
    "                for span in spans:\n",
    "                    data = span['spans']\n",
    "                    for lines in data:                            \n",
    "\n",
    "                        cur_size = round(lines['size'], 2)\n",
    "                        cur_font = lines['font'].split(\"+\")[0]\n",
    "\n",
    "                        key = (cur_font, cur_size)\n",
    "                        # print(lines['text'], key)\n",
    "\n",
    "                        if cur_size == prev_size and cur_font == prev_font:\n",
    "                            latest_item = rest_fonts[key][-1]\n",
    "                            \n",
    "                            if page.number == 0:\n",
    "                                first_page_fonts[key][-1] = latest_item + \" \" + lines['text']  \n",
    "                                \n",
    "                            rest_fonts[key][-1] = latest_item + \" \" + lines['text']  \n",
    "                            seqs[-1] = seqs[-1] + \" \" + lines['text']\n",
    "                            \n",
    "                        else:   \n",
    "                            if page.number == 0:\n",
    "                                first_page_fonts[key] = first_page_fonts.get(key, []) + [lines['text']]\n",
    "                            rest_fonts[key] = rest_fonts.get(key, []) + [lines['text']]\n",
    "                            seqs.append(lines['text'])\n",
    "\n",
    "                        prev_size = cur_size\n",
    "                        prev_font = cur_font\n",
    "    \n",
    "    sorted_first_page_fonts = dict(sorted(first_page_fonts.items(), key = lambda x: x[0][1], reverse = True))\n",
    "    sorted_rest_fonts = dict(sorted(rest_fonts.items(), key = lambda x: x[0][1], reverse = True))\n",
    "    return seqs, sorted_first_page_fonts, sorted_rest_fonts\n",
    "\n",
    "def get_headers(fonts):\n",
    "    \"\"\"Returns list of text (headers) that has size equal to AOM-standard headers\"\"\"\n",
    "    for key, val in fonts.items():\n",
    "        font, size = key\n",
    "        if size == AOM_HEADER_SIZE:\n",
    "            return val[1:]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_abstract(first_page_fonts):\n",
    "    first_page_fonts = dict(reversed(first_page_fonts.items()))\n",
    "    dict_items = first_page_fonts.items()\n",
    "    for idx, ((font, font_size), blocks) in enumerate(dict_items):\n",
    "        # Get item right before authors\n",
    "        if font_size == AOM_HEADER_SIZE:\n",
    "            return {\"Abstract\": list(dict_items)[idx-1][1][0]}\n",
    "            \n",
    "    return first_page_fonts\n",
    "\n",
    "    \n",
    "\n",
    "def get_text_nest(seqs, starting_text_nest, pdf_headers):\n",
    "    cur_header = \"Intro\"\n",
    "    for sequence in seqs:\n",
    "        if sequence in pdf_headers:\n",
    "            starting_text_nest[sequence] = \"\"\n",
    "            cur_header = sequence\n",
    "        else:\n",
    "            starting_text_nest[cur_header] = starting_text_nest.get(cur_header, \"\") + \" \" + sequence      \n",
    "    return starting_text_nest\n",
    "\n",
    "def get_sections(doc):\n",
    "    seqs, first_page_fonts, rest_fonts = structure_doc_by_size_and_font(doc)\n",
    "    starting_text_nest = get_abstract(first_page_fonts)\n",
    "    pdf_headers = get_headers(rest_fonts)\n",
    "    text_nest = get_text_nest(seqs, starting_text_nest, pdf_headers)\n",
    "    return text_nest\n",
    "\n",
    "def make_sections_dataframe(doc):\n",
    "    text_nest = get_sections(doc)\n",
    "    sections_df = pd.DataFrame(text_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return text_nest, sections_df\n",
    "\n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if year in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "def process_citations(citation_group:str) -> (list,str):\n",
    "    citations = citation_group.split(\";\")\n",
    "    for citation in citations:\n",
    "        try:\n",
    "            # case 1: & \n",
    "            if \"&\" in citation:\n",
    "                tokens = citation.split(\",\")\n",
    "                year = tokens[-1]\n",
    "                names = \",\".join(tokens[:-1])\n",
    "                names = names.replace(\"&\", \",\")\n",
    "                names_split = names.split(\",\")\n",
    "                return ([name.strip() for name in names_split if name.strip() not in (\"\", \"e.g.\")], year.strip())\n",
    "\n",
    "            # case 2: et al\n",
    "            if \"et al.\" in citation:\n",
    "                citation = citation.replace(\"et al.\", \"\")\n",
    "                tokens = citation.split(\",\")\n",
    "                return ([token.strip() for token in tokens[:-1] if token.strip() != \"\" ], tokens[-1].strip())\n",
    "\n",
    "            # case 3: 1 author\n",
    "            else:\n",
    "                if \"(\" in citation:\n",
    "                    author, year = citation.split()\n",
    "                    return ([author], year[1:-1])\n",
    "                else:\n",
    "                    citation_split = citation.split(\",\")\n",
    "                    return ([citation_split[-2]], citation_split[-1])\n",
    "        except:\n",
    "            return ([\"\"], \"\")\n",
    "                \n",
    "                \n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references = \" \".join(references_dirty.split())\n",
    "    pattern = \"[A-Z][a-z]+, [A-Z]*[A-Za-z,\\-’&.ˇ ]*[A-Z]{1,3}\\.\\s\\d{4}\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    \n",
    "    for idx, ref in enumerate(references_clean):\n",
    "        if idx == len(references_clean) - 1:\n",
    "            # All the way to the end\n",
    "            references_clean[idx] = references[references.find(ref):]\n",
    "        else:\n",
    "            next_ref = references_clean[idx+1]\n",
    "            references_clean[idx] = references[references.find(ref):references.find(next_ref)]\n",
    "\n",
    "    return references_clean\n",
    "\n",
    "def make_references_dataframe(text_nest, sections_df):\n",
    "    references_dictionary = {}\n",
    "    references_clean = text_preprocess_for_reference_matching(text_nest[\"REFERENCES\"])\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            citation \n",
    "            if citation[0] != \"(\"\n",
    "            else citation[1:-1]\n",
    "            for citation in in_text_citations \n",
    "\n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))        \n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_PARANTHESES_CITATION_REGEX = r\"\\([&\\w\\s.,\\-; ]+\\s\\d{3,4}\\)\"\n",
    "    AND_PATTERN = \"\\S+ & \\S+ \\(\\d{3,4}\\)\"\n",
    "    ONE_PATTERN = \"[A-Z]\\S+ \\(\\d{3,4}\\)\"\n",
    "    ET_AL_PATTERN = \"[A-Z][a-z] et al. \\(\\d{3,4}\\)\"\n",
    "    IN_TEXT_CITATION_REGEX = f\"{IN_PARANTHESES_CITATION_REGEX}|{AND_PATTERN}|{ONE_PATTERN}|{ET_AL_PATTERN}\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def convert_pdf_to_dataframes(doc):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(doc)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document('../data/aom/Ray_2023_AOMReview_Emergence Theory the role of social capital.pdf')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstract</th>\n",
       "      <td>The value of human capital resources (HCR) is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intro</th>\n",
       "      <td>HUMAN CAPITAL RESOURCES EMERGENCE THEORY: THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THEORETICAL BACKGROUND Human Capital Resources</th>\n",
       "      <td>HCR emanates from human capital (Becker, 1964...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emergence</th>\n",
       "      <td>Emergence is predicated on the idea that a wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emergence-Enabling States</th>\n",
       "      <td>Currently, literature relies on explaining HC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social Processes in HCR Emergence</th>\n",
       "      <td>Social interactions are a critical definition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCR EMERGENCE THEORY</th>\n",
       "      <td>Our aim is to explain precisely how the struc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central Assumptions</th>\n",
       "      <td>We build HCR emergence theory using three sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIGURE 1 Overview of HCR Emergence Theory</th>\n",
       "      <td>Individual Employee 3 Individual KSAOs Indivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emergence Mechanisms</th>\n",
       "      <td>Social interactions are a central feature of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Structural Social Capital</th>\n",
       "      <td>“ Structural social capital ”  is the configu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relational Social Capital</th>\n",
       "      <td>“ Relational social capital, ”  the value of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cognitive Social Capital</th>\n",
       "      <td>“ Cognitive social capital ”  refers to share...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Structural and Relational Social Capital</th>\n",
       "      <td>As described, relational social capital parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cognitive and Relational Social Capital</th>\n",
       "      <td>Low cognitive social capital.  The interactio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cognitive and Structural Social Capital</th>\n",
       "      <td>High social capital density can increase the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inputs and Outputs of the HCR Emergence Process</th>\n",
       "      <td>To fully capture the dynamic aspects of HCR e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISCUSSION</th>\n",
       "      <td>Although the importance of HCR is well estab-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theoretical Implications</th>\n",
       "      <td>HCR emergence theory makes three central theo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Limitations and Future Research</th>\n",
       "      <td>One barrier to testing our theory is that mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONCLUSION</th>\n",
       "      <td>We incorporate social capital research into t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFERENCES</th>\n",
       "      <td>Ablowitz, R. 1939. The theory of emergence.  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              text\n",
       "Abstract                                         The value of human capital resources (HCR) is ...\n",
       "Intro                                             HUMAN CAPITAL RESOURCES EMERGENCE THEORY: THE...\n",
       "THEORETICAL BACKGROUND Human Capital Resources    HCR emanates from human capital (Becker, 1964...\n",
       "Emergence                                         Emergence is predicated on the idea that a wh...\n",
       "Emergence-Enabling States                         Currently, literature relies on explaining HC...\n",
       "Social Processes in HCR Emergence                 Social interactions are a critical definition...\n",
       "HCR EMERGENCE THEORY                              Our aim is to explain precisely how the struc...\n",
       "Central Assumptions                               We build HCR emergence theory using three sim...\n",
       "FIGURE 1 Overview of HCR Emergence Theory         Individual Employee 3 Individual KSAOs Indivi...\n",
       "Emergence Mechanisms                              Social interactions are a central feature of ...\n",
       "Structural Social Capital                         “ Structural social capital ”  is the configu...\n",
       "Relational Social Capital                         “ Relational social capital, ”  the value of ...\n",
       "Cognitive Social Capital                          “ Cognitive social capital ”  refers to share...\n",
       "Structural and Relational Social Capital          As described, relational social capital parti...\n",
       "Cognitive and Relational Social Capital           Low cognitive social capital.  The interactio...\n",
       "Cognitive and Structural Social Capital           High social capital density can increase the ...\n",
       "Inputs and Outputs of the HCR Emergence Process   To fully capture the dynamic aspects of HCR e...\n",
       "DISCUSSION                                        Although the importance of HCR is well estab-...\n",
       "Theoretical Implications                          HCR emergence theory makes three central theo...\n",
       "Limitations and Future Research                   One barrier to testing our theory is that mea...\n",
       "CONCLUSION                                        We incorporate social capital research into t...\n",
       "REFERENCES                                        Ablowitz, R. 1939. The theory of emergence.  ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Call, M. L., Nyberg, A. J., Ployhart, R. E., &amp;...</td>\n",
       "      <td>Intro,Inputs and Outputs of the HCR Emergence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ployhart, R. E., &amp; Moliterno, T. P. 2011. Emer...</td>\n",
       "      <td>Intro,Emergence-Enabling States,Central Assump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brymer, R. A., &amp; Hitt, M. A. 2019. Agonistic r...</td>\n",
       "      <td>Intro,Emergence,DISCUSSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cannella, A. A., Jr., &amp; Sy, V. A. 2019. Human ...</td>\n",
       "      <td>Intro,THEORETICAL BACKGROUND Human Capital Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eckardt, R., &amp; Jiang, K. 2019. Human capital r...</td>\n",
       "      <td>Intro,THEORETICAL BACKGROUND Human Capital Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Gerhart, B., &amp; Feng, J. 2021. The resource-bas...</td>\n",
       "      <td>Limitations and Future Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Oldroyd, J. B., &amp; Morris, S. S. 2012. Catching...</td>\n",
       "      <td>Limitations and Future Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Kehoe, R. R., Lepak, D. P., &amp; Bentley, F. S. 2...</td>\n",
       "      <td>Limitations and Future Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Kang, S. C., Oldroyd, J. B., Morris, S. S., &amp; ...</td>\n",
       "      <td>Limitations and Future Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Morris, S., Alvarez, S. A., &amp; Barney, J. 2021....</td>\n",
       "      <td>Limitations and Future Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reference   \n",
       "0    Call, M. L., Nyberg, A. J., Ployhart, R. E., &...  \\\n",
       "1    Ployhart, R. E., & Moliterno, T. P. 2011. Emer...   \n",
       "2    Brymer, R. A., & Hitt, M. A. 2019. Agonistic r...   \n",
       "3    Cannella, A. A., Jr., & Sy, V. A. 2019. Human ...   \n",
       "4    Eckardt, R., & Jiang, K. 2019. Human capital r...   \n",
       "..                                                 ...   \n",
       "117  Gerhart, B., & Feng, J. 2021. The resource-bas...   \n",
       "118  Oldroyd, J. B., & Morris, S. S. 2012. Catching...   \n",
       "119  Kehoe, R. R., Lepak, D. P., & Bentley, F. S. 2...   \n",
       "120  Kang, S. C., Oldroyd, J. B., Morris, S. S., & ...   \n",
       "121  Morris, S., Alvarez, S. A., & Barney, J. 2021....   \n",
       "\n",
       "                                               section  \n",
       "0    Intro,Inputs and Outputs of the HCR Emergence ...  \n",
       "1    Intro,Emergence-Enabling States,Central Assump...  \n",
       "2                           Intro,Emergence,DISCUSSION  \n",
       "3    Intro,THEORETICAL BACKGROUND Human Capital Res...  \n",
       "4    Intro,THEORETICAL BACKGROUND Human Capital Res...  \n",
       "..                                                 ...  \n",
       "117                    Limitations and Future Research  \n",
       "118                    Limitations and Future Research  \n",
       "119                    Limitations and Future Research  \n",
       "120                    Limitations and Future Research  \n",
       "121                    Limitations and Future Research  \n",
       "\n",
       "[122 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import fitz\n",
    "from IPython.display import display\n",
    "\n",
    "aom_path = \"../data/aom\"\n",
    "aom_pdfs = [f for f in os.listdir(aom_path) if f.endswith('pdf')]\n",
    "\n",
    "fonts = {}\n",
    "path = os.path.join(aom_path, aom_pdfs[5])\n",
    "doc = fitz.open(path) # open a document\n",
    "print(doc)\n",
    "display(*convert_pdf_to_dataframes(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sections_dataframe(doc):\n",
    "    text_nest = get_sections(doc)\n",
    "    sections_df = pd.DataFrame(text_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return text_nest, sections_df\n",
    "\n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if year in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "def process_citations(citation_group:str) -> (list,str):\n",
    "    citations = citation_group.split(\";\")\n",
    "    for citation in citations:\n",
    "        print(citation)\n",
    "        try:\n",
    "            # case 1: & \n",
    "            if \" and \" in citation:\n",
    "                tokens = citation.split(\",\")\n",
    "                year = tokens[-1]\n",
    "                names = \",\".join(tokens[:-1])\n",
    "                names = names.replace(\" and \", \",\")\n",
    "                names_split = names.split(\",\")\n",
    "                print(names_split)\n",
    "                return ([name.strip() for name in names_split if name.strip() not in (\"\", \"e.g.\")], year.strip())\n",
    "\n",
    "            # case 2: et al\n",
    "            if \"et al.\" in citation:\n",
    "                citation = citation.replace(\"et al.\", \"\")\n",
    "                tokens = citation.split(\",\")\n",
    "                return ([token.strip() for token in tokens[:-1] if token.strip() != \"\" ], tokens[-1].strip())\n",
    "\n",
    "            # case 3: 1 author\n",
    "            else:\n",
    "                if \"(\" in citation:\n",
    "                    author, year = citation.split()\n",
    "                    return ([author], year[1:-1])\n",
    "                else:\n",
    "                    citation_split = citation.split(\",\")\n",
    "                    return ([citation_split[-2]], citation_split[-1])\n",
    "        except:\n",
    "            return ([\"\"], \"\")\n",
    "                \n",
    "                \n",
    "\n",
    "def remove_prefix(citation):\n",
    "    is_parantheses = False\n",
    "    for idx, char in enumerate(citation):\n",
    "        if char == \".\" and citation[idx - 1].islower() and not is_parantheses:\n",
    "            return citation[idx+2:]\n",
    "        if char == \"(\":\n",
    "            is_parantheses = True\n",
    "        if char == \")\":\n",
    "            is_parantheses = False\n",
    "            \n",
    "    return citation\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references = \" \".join(references_dirty.split())\n",
    "    pattern = \"[A-Z][A-Za-z,\\-’.ˇ() ]+ \\d{4} \"\n",
    "    references_clean = list(map(remove_prefix, re.findall(pattern, references)))\n",
    "\n",
    "    for idx, ref in enumerate(references_clean):\n",
    "        if idx == len(references_clean) - 1:\n",
    "            # All the way to the end\n",
    "            references_clean[idx] = references[references.find(ref):]\n",
    "        else:\n",
    "            next_ref = references_clean[idx+1]\n",
    "            references_clean[idx] = references[references.find(ref):references.find(next_ref)]\n",
    "\n",
    "    return references_clean\n",
    "\n",
    "def make_references_dataframe(text_nest, sections_df):\n",
    "    references_dictionary = {}\n",
    "    references_clean = text_preprocess_for_reference_matching(text_nest[\"REFERENCES\"])\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        # print(location, \"\\n\")\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        # print(in_text_citations)\n",
    "        cleaned_in_text_citations = [\n",
    "            citation \n",
    "            if citation[0] != \"(\"\n",
    "            else citation[1:-1]\n",
    "            for citation in in_text_citations \n",
    "\n",
    "        ]\n",
    "        author_year_pairs_nested = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))  \n",
    "        author_year_pairs = [item for group in author_year_pairs_nested for item in group]\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "        # print()\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    references_df\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_PARANTHESES_CITATION_REGEX = r\"\\([&\\w\\s.,\\-; ]+\\s\\d{3,4}\\)\"\n",
    "    AND_PATTERN = \"\\S+ and \\S+ \\(\\d{3,4}\\)\"\n",
    "    ONE_PATTERN = \"[A-Z]\\S+ \\(\\d{3,4}\\)\"\n",
    "    ET_AL_PATTERN = \"[A-Z][a-z] et al. \\(\\d{3,4}\\)\"\n",
    "    IN_TEXT_CITATION_REGEX = f\"{IN_PARANTHESES_CITATION_REGEX}|{AND_PATTERN}|{ONE_PATTERN}|{ET_AL_PATTERN}\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def convert_pdf_to_dataframes(doc):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(doc)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTRACT_KEY = ('AdvPSA35F', 10.0)\n",
    "HEADERS_KEY = ('AdvP2A83', 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_doc_by_size_and_font(doc):\n",
    "    # first_page_fonts = {}\n",
    "    rest_fonts = {}\n",
    "    seqs = []\n",
    "    prev_size, prev_font = 0,0\n",
    "    for page in doc:      \n",
    "        d = page.get_text(\"dict\")\n",
    "        blocks = d[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" in block.keys():\n",
    "                spans = block['lines']\n",
    "                for span in spans:\n",
    "                    data = span['spans']\n",
    "                    for lines in data:                            \n",
    "\n",
    "                        cur_size = round(lines['size'], 2)\n",
    "                        cur_font = lines['font'].split(\"+\")[0]\n",
    "\n",
    "                        key = (cur_font, cur_size)\n",
    "                        # print(lines['text'], key)\n",
    "\n",
    "                        if cur_size == prev_size and cur_font == prev_font:\n",
    "                            latest_item = rest_fonts[key][-1]\n",
    "                            \n",
    "                            # if page.number == 0:\n",
    "                                # first_page_fonts[key][-1] = latest_item + \" \" + lines['text']  \n",
    "                                \n",
    "                            rest_fonts[key][-1] = latest_item + \" \" + lines['text']  \n",
    "                            seqs[-1] = seqs[-1] + \" \" + lines['text']\n",
    "                            \n",
    "                        else:   \n",
    "                            # if page.number == 0:\n",
    "                                # first_page_fonts[key] = first_page_fonts.get(key, []) + [lines['text']]\n",
    "                            rest_fonts[key] = rest_fonts.get(key, []) + [lines['text']]\n",
    "                            seqs.append(lines['text'])\n",
    "\n",
    "                        prev_size = cur_size\n",
    "                        prev_font = cur_font\n",
    "    \n",
    "    # sorted_first_page_fonts = dict(sorted(first_page_fonts.items(), key = lambda x: x[0][1], reverse = True))\n",
    "    sorted_rest_fonts = sorted(rest_fonts.items(), key = lambda x: x[0][1], reverse = True)\n",
    "    return seqs, sorted_rest_fonts\n",
    "\n",
    "def get_headers(fonts):\n",
    "    \"\"\"Returns list of text (headers) that has size equal to AOM-standard headers\"\"\"\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    for key, val in fonts:\n",
    "        if key == ABSTRACT_KEY:\n",
    "            first_part = val\n",
    "        if key == HEADERS_KEY:\n",
    "            second_part = val\n",
    "    return first_part[:2] + second_part + first_part[2:]\n",
    "\n",
    "def find_earliest_uppercase_index(s):\n",
    "    for i, char in enumerate(s):\n",
    "        if char.isalpha() and char.upper() == char:\n",
    "            return i\n",
    "    return len(s)\n",
    "\n",
    "def get_text_nest(seqs, starting_text_nest, pdf_headers):\n",
    "    cur_header = \"Other\"\n",
    "    for sequence in seqs[1:]:\n",
    "        if sequence in pdf_headers:\n",
    "            starting_text_nest[sequence] = \"\"\n",
    "            cur_header = sequence\n",
    "        else:\n",
    "            if cur_header.startswith(\"Keyword\"):\n",
    "                earliest_idx = find_earliest_uppercase_index(sequence)\n",
    "                keyword_part = sequence[:earliest_idx]\n",
    "                intro_part = sequence[earliest_idx:]\n",
    "                starting_text_nest[cur_header] = starting_text_nest.get(cur_header, \"\") + \" \" + keyword_part   \n",
    "                cur_header = \"Introduction\"\n",
    "                starting_text_nest[cur_header] = starting_text_nest.get(cur_header, \"\") + \" \" + intro_part   \n",
    "            else:\n",
    "                starting_text_nest[cur_header] = starting_text_nest.get(cur_header, \"\") + \" \" + sequence   \n",
    "            \n",
    "    return starting_text_nest\n",
    "\n",
    "def get_sections(doc):\n",
    "    seqs, fonts = structure_doc_by_size_and_font(doc)\n",
    "    pdf_headers = get_headers(fonts)\n",
    "    text_nest = get_text_nest(seqs, {}, pdf_headers)\n",
    "    return text_nest\n",
    "\n",
    "def make_sections_dataframe(doc):\n",
    "    text_nest = get_sections(doc)\n",
    "    sections_df = pd.DataFrame(text_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return text_nest, sections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document('../data/asq/Feldberg_2022_ASQ_The Task Bind_ Explaining Gender Differences in Managerial Tasks and Performance.pdf')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "aom_path = \"../data/asq\"\n",
    "aom_pdfs = [f for f in os.listdir(aom_path) if f.endswith('pdf')]\n",
    "\n",
    "fonts = {}\n",
    "path = os.path.join(aom_path, aom_pdfs[1])\n",
    "doc = fitz.open(path) # open a document\n",
    "print(doc)\n",
    "\n",
    "text_nest, sections_df = make_sections_dataframe(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_citations(citation_group:str) -> (list,str):\n",
    "    citations = citation_group.split(\";\")\n",
    "    results = []\n",
    "    for citation in citations:\n",
    "        try:\n",
    "            # case 1: & \n",
    "            if \" and \" in citation:\n",
    "                tokens = citation.split(\",\")\n",
    "                year = tokens[-1]\n",
    "                names = \",\".join(tokens[:-1])\n",
    "                names = names.replace(\" and \", \",\")\n",
    "                names_split = names.split(\",\")\n",
    "                results.append(([name.strip() for name in names_split if name.strip() not in (\"\", \"e.g.\")], year.strip()))\n",
    "\n",
    "            # case 2: et al\n",
    "            if \"et al.\" in citation:\n",
    "                citation = citation.replace(\"et al.\", \"\")\n",
    "                tokens = citation.split(\",\")\n",
    "                results.append(([token.strip() for token in tokens[:-1] if token.strip() != \"\" ], tokens[-1].strip()))\n",
    "\n",
    "            # case 3: 1 author\n",
    "            else:\n",
    "                if \"(\" in citation:\n",
    "                    author, year = citation.split()\n",
    "                    results.append(([author], year[1:-1]))\n",
    "                else:\n",
    "                    citation_split = citation.split(\",\")\n",
    "                    results.append(([citation_split[-2]], citation_split[-1]))\n",
    "        except:\n",
    "            results.append(([\"\"], \"\"))\n",
    "    \n",
    "    return results\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other \n",
      "\n",
      "[]\n",
      "\n",
      "Abstract \n",
      "\n",
      "[]\n",
      "\n",
      "Keywords: \n",
      "\n",
      "[]\n",
      "\n",
      "Introduction \n",
      "\n",
      "['(Bailyn, 1987; Robinson and McIlwee, 1991; Kanter, 2008; Kuehn, 2012)', '(Singh et al., 2013; Dresden et al., 2018)', '(Berger, Cohen, and Zelditch, 1972; Bailyn, 1987; Reskin, 1993; Fletcher, 1999; Ridgeway, 2001; Cech, 2013)', '(Eagly, Makhijani, and Klonsky, 1992; Heilman, 2001; Ridgeway, 2001; Rudman and Glick, 2001; Eagly and Karau, 2002; Heilman and Eagly, 2008; Rudman et al., 2012)', '(Ellemers et al., 2004; Sheppard and Aquino, 2013)', '(Halpern, 1992; Nancarrow and Borthwick, 2005; Ashcraft, 2007)', '(Freeland and Hoey, 2018)', '(Reskin, 1993)', '(Shaw et al., 2018)', '(Freeland and Hoey, 2018)', '(Lively, 2001)', '(Truelove and Kellogg, 2016)', '(DiBenigno and Kellogg, 2014)', '(McMurray, 2011)']\n",
      "\n",
      "CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATIONS \n",
      "\n",
      "['(Reskin, 1993; Acker, 1998; Ashcraft, 2013)', '(Treiman and Hartmann, 1981; Reskin and Roos, 1990)', '(Ridgeway and Berger, 1986; Berger, Ridgeway, and Zelditch, 2002)', '(Bailyn, 1987; Robinson and McIlwee, 1991; Fletcher, 1999; Cardador, 2017; Cheryan and Markus, 2020)', '(Berger, Ridgeway, and Zelditch, 2002; Ridgeway, 2014)', '(Ridgeway, 2001)', '(Kanter, 2008)', '(Bennett, Davidson, and Galeand, 1999; Powell, Bagilhole, and Dainty, 2009)', '(Cheryan and Markus, 2020)', '(Kanter, 2008)', '(Eisenhart and Finkel, 1998; Jorgenson, 2002; Faulkner, 2007)', '(Cole and Singer, 1991)', 'Heilman’s (1983)', 'Rudman and colleagues’ (2012)', 'Eagly and Karau’s (2002)', '(Heilman, 1983; Heilman, 2001; Gaucher, Friesen, and Kay, 2011)', '(Glick, Zion, and Nelson, 1988; Dodge, Gilroy, and Fenzel, 1995; Eagly and Karau, 2002)', '(Rudman and Kilianski, 2000)', '(Heilman, 2001; Rudman et al., 2012)', '(e.g., Derks et al., 2011; Duguid, 2011; Duguid, Loyd, and Tolbert, 2012)', '(Ely, 1994)', 'Sheppard and Aquino (2017)', '(see also Gibson and Lawrence, 2010; Duguid, Loyd, and Tolbert, 2012)', '(Parks-Stamm, Heilman, and Hearns, 2008; Sheppard and Aquino, 2013)', 'Eagly and Karau’s (2002)', 'Garcia-Retamero and Lo´pez-Zafra’s (2006)', '(Rudman and Glick, 2001)', '(Heilman and Okimoto, 2007)', '(Heilman et al., 2004)']\n",
      "\n",
      "SHARED DEMOGRAPHY IN CROSS-OCCUPATIONAL COLLABORATION \n",
      "\n",
      "['(Ashcraft, 2007)', '(Weber, 1978)', '(see also DiBenigno, 2020)', '(Weber, 1978; Abbott, 1988)', '(Wrong, 1979; Huising, 2015)', 'DiBenigno and Kellogg (2014)', 'DiBenigno and Kellogg’s (2014)', '(i.e., uncorrelated with occupational status; DiBenigno and Kellogg, 2014)']\n",
      "\n",
      "METHOD Research Context \n",
      "\n",
      "['(Sinclair, 1988)', '(Sweet and Norman, 1995)', '(Dingwall and McIntosh, 1978; Wallace and Abbott, 1990)', '(Kalisch and Kalisch, 1977; Wallace and Abbott, 1990)', '(Sweet and Norman, 1995)', '(e.g., Schneider, 2012; House and Havens, 2017)', '(Gittell, Godfrey, and Thistlethwaite, 2013)', '(Lancaster et al., 2015; Szafran et al., 2018)', '(Center for Health Ethics, 2020)', '(Eisenhardt, 1989; Dossett et al., 2020)', '(de Costa et al., 2018; Haskins, 2019)', '(Gjerberg and Kjølsrød, 2001)', '(National Council of State Boards of Nursing, 2020)', '(Cheryan and Markus, 2020)']\n",
      "\n",
      "Data Collection \n",
      "\n",
      "['(Robinson, 2014)', '(Lewis et al., 2012)', '(Eisenhardt, 1989)', '(Marshall and Rossman, 1989)', '(Strauss and Corbin, 1998)', '(Lincoln and Guba, 1985)', '(Spradley, 1979)']\n",
      "\n",
      "Data Analysis \n",
      "\n",
      "['(Strauss and Corbin, 1998)', '(Locke, 2001)', '(Locke, 2001)', '(Strauss and Corbin, 1998)']\n",
      "\n",
      "FINDINGS \n",
      "\n",
      "[]\n",
      "\n",
      "Nonsymmetrical Gendered Expectations for Status Equivalence \n",
      "\n",
      "[]\n",
      "\n",
      "Gendered expectations for authoritativeness. \n",
      "\n",
      "[]\n",
      "\n",
      "Gendered shows of respect. \n",
      "\n",
      "['(Zelek and Phillips, 2003)']\n",
      "\n",
      "Risks of Inter-Occupational Alienation \n",
      "\n",
      "[]\n",
      "\n",
      "Undermining organizational reputation. \n",
      "\n",
      "[]\n",
      "\n",
      "Undermining work. \n",
      "\n",
      "[]\n",
      "\n",
      "Status-Leveling Behaviors \n",
      "\n",
      "['(Cassell, 1997)']\n",
      "\n",
      "Relaxing task boundaries. \n",
      "\n",
      "['(Hughes, 1958; Huising, 2015)']\n",
      "\n",
      "Relaxing personal boundaries. \n",
      "\n",
      "[]\n",
      "\n",
      "Explaining the Effect of Status-Leveling Behaviors \n",
      "\n",
      "['(Pfeffer, 1995)', '(Pfeffer, 1995)', '(Hornstein, 2003)', 'Whitener and colleagues (1998)', '(Zhang and Morand, 2014)']\n",
      "\n",
      "Implications of Performing Status-Leveling Behaviors \n",
      "\n",
      "[]\n",
      "\n",
      "Positive implications: Increased professional effectiveness. \n",
      "\n",
      "[]\n",
      "\n",
      "Negative implications: Increased work demands. \n",
      "\n",
      "['(e.g., Grandey, 2000)', '(Jena, Olenski, and Blumenthal, 2016)']\n",
      "\n",
      "DISCUSSION \n",
      "\n",
      "[]\n",
      "\n",
      "Challenges to Women in Male-Dominated Occupations \n",
      "\n",
      "['(Cochran et al., 2013)', '(Cheryan and Markus, 2020)', '(i.e., feminine defaults; Cheryan and Markus, 2020)', '(Cheryan and Markus, 2020)', '(Heilman, 2001; Rudman and Glick, 2001)', '(Schwartz et al., 1992; Huising, 2015)']\n",
      "\n",
      "Cross-Occupational Collaboration \n",
      "\n",
      "['(Reskin, 1993; Ridgeway, 2001)', '(McPherson, Smith-Loven, and Cook, 2001)', 'DiBenigno and Kellogg (2014)', '(e.g., Crenshaw 1991; Parent, DeBlaere, and Moradi, 2013)', '(e.g., Weber, 1978; Abbott, 1988)', '(Abbott, 1988)', '(as suggested by prior research, e.g., Robinson and Mcllwee, 1991; Salles et al., 2019)', '(Richman, vanDellen, and Wood, 2011)', '(AAMC, 2020)', '(American Bar Association, 2020)']\n",
      "\n",
      "Practical Implications \n",
      "\n",
      "['(Gerull et al., 2019)', '(Ashburn-Nardo, 2018)', '(Sheppard and Aquino, 2013)', '(Tsugawa et al., 2017; Wallis et al., 2017)']\n",
      "\n",
      "Limitations and Future Directions \n",
      "\n",
      "['(Wharton and Baron, 1991)', '(Heilman, 2012)', '(Eagly and Johannesen-Schmidt, 2001)', '(Floge and Merrill, 1986)', '(Yin, 2013)', '(Pratt and Bonaccio, 2016)', '(e.g., Wingfield and Alston, 2012)']\n",
      "\n",
      "Conclusion \n",
      "\n",
      "[]\n",
      "\n",
      "Acknowledgments \n",
      "\n",
      "[]\n",
      "\n",
      "ORCID iDs \n",
      "\n",
      "[]\n",
      "\n",
      "Supplemental Material \n",
      "\n",
      "[]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bailyn, L. 1987 ‘‘Experiencing technical work:...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singh, R., N. A. Fouad, M. E. Fitzpatrick, J. ...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dresden, B. E., A. Y. Dresden, R. D. Ridge, an...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eagly, A. H., M. G. Makhijani, and B. G. Klons...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rudman, L. A., and P. Glick 2001 ‘‘Prescriptiv...</td>\n",
       "      <td>Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Wingfield, A. H., and R. S. Alston 2012 ‘‘The ...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Wrong, D. H. 1979 Power: Its Forms, Bases and ...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Yin, R. K. 2013 Case Study Research: Design an...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Zelek, B., and S. P. Phillips 2003 ‘‘Gender an...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Zhang, L., and D. Morand 2014 ‘‘The linkage be...</td>\n",
       "      <td>CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reference   \n",
       "0    Bailyn, L. 1987 ‘‘Experiencing technical work:...  \\\n",
       "1    Singh, R., N. A. Fouad, M. E. Fitzpatrick, J. ...   \n",
       "2    Dresden, B. E., A. Y. Dresden, R. D. Ridge, an...   \n",
       "3    Eagly, A. H., M. G. Makhijani, and B. G. Klons...   \n",
       "4    Rudman, L. A., and P. Glick 2001 ‘‘Prescriptiv...   \n",
       "..                                                 ...   \n",
       "118  Wingfield, A. H., and R. S. Alston 2012 ‘‘The ...   \n",
       "119  Wrong, D. H. 1979 Power: Its Forms, Bases and ...   \n",
       "120  Yin, R. K. 2013 Case Study Research: Design an...   \n",
       "121  Zelek, B., and S. P. Phillips 2003 ‘‘Gender an...   \n",
       "122  Zhang, L., and D. Morand 2014 ‘‘The linkage be...   \n",
       "\n",
       "                                               section  \n",
       "0    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "1    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "2    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "3    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "4    Introduction,CHALLENGES TO WOMEN IN MALE-DOMIN...  \n",
       "..                                                 ...  \n",
       "118  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "119  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "120  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "121  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "122  CHALLENGES TO WOMEN IN MALE-DOMINATED OCCUPATI...  \n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_dictionary = {}\n",
    "references_clean = text_preprocess_for_reference_matching(text_nest[\"REFERENCES\"])\n",
    "for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "    print(location, \"\\n\")\n",
    "    in_text_citations = get_in_text_citations(text.item())\n",
    "    print(in_text_citations)\n",
    "    cleaned_in_text_citations = [\n",
    "        citation \n",
    "        if citation[0] != \"(\"\n",
    "        else citation[1:-1]\n",
    "        for citation in in_text_citations \n",
    "\n",
    "    ]\n",
    "    author_year_pairs_nested = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))  \n",
    "    author_year_pairs = [item for group in author_year_pairs_nested for item in group]\n",
    "    references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "    print()\n",
    "\n",
    "references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "references_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_references_dataframe(text_nest, sections_df):\n",
    "    references_dictionary = {}\n",
    "    references_clean = text_preprocess_for_reference_matching(text_nest[\"REFERENCES\"])\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            citation \n",
    "            if citation[0] != \"(\"\n",
    "            else citation[1:-1]\n",
    "            for citation in in_text_citations \n",
    "\n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))        \n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reference, section]\n",
       "Index: []"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_references_dataframe(sections, sections_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
