{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrgSci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstract.</th>\n",
       "      <td>Abstract. \\nIn the wake of media hype about ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Introduction</th>\n",
       "      <td>Introduction\\nThe most promising uses of AI wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology as a Tool: How Technologies  Support Tasks and Work</th>\n",
       "      <td>Technology as a Tool: How Technologies  Suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology as a Medium: How  Technologies Enable Collaboration  Between Groups</th>\n",
       "      <td>Technology as a Medium: How  Technologies Enab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology as a Counterpart: How  People and Technologies Interact Within  a System of Work</th>\n",
       "      <td>Technology as a Counterpart: How  People and T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taking a Counterpart Perspective:  Methodological Challenges</th>\n",
       "      <td>Taking a Counterpart Perspective:  Methodologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Relational Approach to Ethnography  and Studying AI</th>\n",
       "      <td>A Relational Approach to Ethnography  and Stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conclusion</th>\n",
       "      <td>Conclusion\\nAlthough positive narratives about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endnotes</th>\n",
       "      <td>Endnotes\\n1 \\n\\n  Machine learning algorithms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>References</th>\n",
       "      <td>References\\nAjunwa I, Greene D (2019) Platform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text\n",
       "Abstract.                                           Abstract. \\nIn the wake of media hype about ar...\n",
       "Introduction                                        Introduction\\nThe most promising uses of AI wi...\n",
       "Technology as a Tool: How Technologies  Support...  Technology as a Tool: How Technologies  Suppor...\n",
       "Technology as a Medium: How  Technologies Enabl...  Technology as a Medium: How  Technologies Enab...\n",
       "Technology as a Counterpart: How  People and Te...  Technology as a Counterpart: How  People and T...\n",
       "Taking a Counterpart Perspective:  Methodologic...  Taking a Counterpart Perspective:  Methodologi...\n",
       "A Relational Approach to Ethnography  and Study...  A Relational Approach to Ethnography  and Stud...\n",
       "Conclusion                                          Conclusion\\nAlthough positive narratives about...\n",
       "Endnotes                                            Endnotes\\n1 \\n\\n  Machine learning algorithms ...\n",
       "References                                          References\\nAjunwa I, Greene D (2019) Platform..."
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "    \n",
    "import pprint\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "    main_section   \n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        rect = Rect(page.rect.x0 + 40, page.rect.y0 + 60, page.rect.x1 - 40, page.rect.y1 - 40) \n",
    "        \n",
    "        dict = page.get_text(\"dict\", clip = rect)\n",
    "\n",
    "        blocks = dict[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" in block.keys():\n",
    "                spans = block['lines']\n",
    "                for span in spans:\n",
    "                    data = span['spans']\n",
    "                    for lines in data:\n",
    "                        cur_size = round(lines['size'], 1)\n",
    "\n",
    "                        # Manual Override for References\n",
    "                        if lines['text'].strip() in (\"Acknowledgements\", \"References\", \"Appendix\", \"Endnotes\"):\n",
    "                            cur = Section(lines['text'], cur_size)\n",
    "                            curr_section = main_section.children[-1].children[-1]\n",
    "                            curr_section.add_child(cur)\n",
    "                            cur.set_parent(curr_section)\n",
    "                            curr_section = cur\n",
    "\n",
    "                            prev_size = round(lines['size'], 1)\n",
    "\n",
    "                        elif cur_size > prev_size:\n",
    "                            curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                            prev_size = curr_section.size\n",
    "\n",
    "                        elif cur_size == prev_size:\n",
    "                            curr_section.extend(lines['text'])\n",
    "\n",
    "                        else:  \n",
    "                            cur = Section(lines['text'], cur_size)   \n",
    "                            curr_section.add_child(cur)\n",
    "                            cur.set_parent(curr_section)\n",
    "                            curr_section = cur\n",
    "                            prev_size = round(lines['size'], 1)\n",
    "\n",
    "    # orgsci                            \n",
    "    return main_section.children[-1].children[-1].children\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references_dirty = \" \".join(references_dirty.split())\n",
    "    references = re.sub(\"([0-9]|html|\\))\\s?\\.\", r\"\\g<0>\\n\", references_dirty)\n",
    "\n",
    "    # Make list of references\n",
    "    pattern = r\"[A-ZÆØÅæøå][ÆØÅæøåA-Za-z]+.*[A-Z]{1,3},? .*\\(\\d{4}\\).*[html|\\d|\\)]\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \" and \" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\" and \")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def convert_pdf_to_dataframes(path) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(path)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    add_new_section = False\n",
    "    \n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract. \", 0)\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "    \n",
    "    sections_tmp = sections.copy()\n",
    "    earliest_index = 1000\n",
    "    txt = \"\"\n",
    "    \n",
    "    # Fit all text that belongs in paragraph into one \"Introduction\" paragraph\n",
    "    for idx, section in enumerate(sections_tmp):\n",
    "        if len(section.content) > 100:\n",
    "            add_new_section = True\n",
    "            if min(earliest_index, idx) != earliest_index:\n",
    "                earliest_index = idx\n",
    "            sections.remove(section)\n",
    "            txt += section.content\n",
    "            \n",
    "    \n",
    "    if add_new_section:\n",
    "        new_section = Section(\"Introduction\", 20)\n",
    "        new_section.add_child(Section(txt, 15))\n",
    "        sections[earliest_index] = new_section\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "import fitz\n",
    "import os\n",
    "\n",
    "ORGSCI_PATH = \"data/orgsci\"\n",
    "orgsci_pdfs = [f for f in os.listdir(ORGSCI_PATH) if f.endswith('pdf')]\n",
    "path = os.path.join(ORGSCI_PATH, orgsci_pdfs[0])\n",
    "\n",
    "sections_df, references_df = convert_pdf_to_dataframes(path)\n",
    "sections_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annurev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "    \n",
    "import pprint\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "    main_section   \n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        if page.number not in (doc[-1].number, doc[-2].number):\n",
    "            if page.number == 0:\n",
    "                rect = Rect(page.rect.x0 + 20, page.rect.y0 + 250, page.rect.x1 - 20, page.rect.y1 - 20) \n",
    "            else:\n",
    "                rect = Rect(page.rect.x0 + 20, page.rect.y0 + 20, page.rect.x1 - 20, page.rect.y1 - 20) \n",
    "            \n",
    "            dict = page.get_text(\"dict\", clip = rect)\n",
    "\n",
    "            blocks = dict[\"blocks\"]\n",
    "            for block in blocks:\n",
    "                if \"lines\" in block.keys():\n",
    "                    spans = block['lines']\n",
    "                    for span in spans:\n",
    "                        data = span['spans']\n",
    "                        for lines in data:\n",
    "                            cur_size = round(lines['size'], 1)\n",
    "\n",
    "                            # Manual Override for References\n",
    "                            if lines['text'].strip() in (\"Acknowledgements\", \"References\", \"Appendix\", \"Endnotes\"):\n",
    "                                cur = Section(lines['text'], cur_size)\n",
    "                                curr_section = main_section.children[-1].children[-1]\n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "\n",
    "                                prev_size = round(lines['size'], 1)\n",
    "\n",
    "                            elif cur_size > prev_size:\n",
    "                                curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                                prev_size = curr_section.size\n",
    "\n",
    "                            elif cur_size == prev_size:\n",
    "                                curr_section.extend(lines['text'])\n",
    "\n",
    "                            else:  \n",
    "                                cur = Section(lines['text'], cur_size)   \n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "                                prev_size = round(lines['size'], 1)\n",
    "\n",
    "    # orgsci                            \n",
    "    return main_section\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract\", 0)\n",
    "\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references_dirty = \" \".join(references_dirty.split())\n",
    "    references = re.sub(\"([0-9]|html|\\))\\s?\\.\", r\"\\g<0>\\n\", references_dirty)\n",
    "\n",
    "    # Make list of references\n",
    "    pattern = r\"[A-ZÆØÅæøå][ÆØÅæøåA-Za-z]+.*[A-Z]{1,3},? .*\\(\\d{4}\\).*[html|\\d|\\)]\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \" and \" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\" and \")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def convert_pdf_to_dataframes(path) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(path)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        if page.number not in (doc[-1].number, doc[-2].number):\n",
    "            rect = Rect(page.rect.x0 + 20, page.rect.y0 + 20, page.rect.x1 - 20, page.rect.y1 - 30)\n",
    "            \n",
    "            dict = page.get_text(\"dict\", clip = rect)\n",
    "            blocks = dict[\"blocks\"]\n",
    "            for block in blocks:\n",
    "                if \"lines\" in block.keys():\n",
    "                    spans = block['lines']\n",
    "                    for span in spans:\n",
    "                        data = span['spans']\n",
    "                        for lines in data:\n",
    "                            cur_size = round(lines['size'], 2)\n",
    "\n",
    "                            # Manual Override for References\n",
    "                            if lines['text'].strip() in (\"Abstract\", \"Keywords\", \"LITERATURE CITED\"):\n",
    "                                cur = Section(lines['text'], cur_size)\n",
    "                                curr_section = main_section.children[-1].children[-1]\n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "\n",
    "                                prev_size = round(lines['size'], 2)\n",
    "\n",
    "                            elif cur_size > prev_size:\n",
    "                                curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                                prev_size = curr_section.size\n",
    "\n",
    "                            elif cur_size == prev_size:\n",
    "                                curr_section.extend(lines['text'])\n",
    "\n",
    "                            else:  \n",
    "                                cur = Section(lines['text'], cur_size)   \n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "                                prev_size = round(lines['size'], 2)\n",
    "\n",
    "    # orgsci                            \n",
    "    return main_section.children[-1].children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[John P. Hausknecht, Further]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document('data/annurev-orgpsych/Hausknecht_2017_Annurev-Orgpsych_Collective Turnover.pdf')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[INTRODUCTION,\n",
       " DEFINITIONS AND CONSTRUCT ISSUES,\n",
       " THEORETICAL ADVANCEMENTS,\n",
       " CHOOSING A COLLECTIVE TURNOVER MEASURE,\n",
       " Context-Emergent Turnover Theory,\n",
       " Turnover Capacity,\n",
       " RECENT EMPIRICAL CONTRIBUTIONS,\n",
       " Meta-Analyses,\n",
       " Original Articles,\n",
       " FUTURE RESEARCH NEEDS,\n",
       " FIFTEEN PROMISING RESEARCH QUESTIONS FOR FUTURE COLLECTIVE TURNOVER RESEARCH,\n",
       " Expand the Study of Context (Research Questions 7, 8, 12, 13, and 15),\n",
       " Move Beyond the United States (Research Questions 2, 6, 11, 13, and 15),\n",
       " Examine Events and Interventions (Research Questions 4, 5, 9, and 11),\n",
       " Measure Process (Research Questions 3, 6, and 14),\n",
       " Expand, Validate, and Reﬁne Measures (Research Questions 1, 2, 5, and 10),\n",
       " CONCLUSION,\n",
       " DISCLOSURE STATEMENT,\n",
       " LITERATURE CITED]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annurev_path = \"data/annurev-orgpsych\"\n",
    "annurev_pdfs = [f for f in os.listdir(annurev_path) if f.endswith('pdf')]\n",
    "doc = fitz.open(os.path.join(annurev_path, annurev_pdfs[1])) # open a document\n",
    "print(doc)\n",
    "sections = get_sections(doc)\n",
    "# sections = preprocess_sections(sections)\n",
    "sections[1].children\n",
    "# content_nest = {}\n",
    "\n",
    "# for section in sections:\n",
    "#     content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "# sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "# sections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
