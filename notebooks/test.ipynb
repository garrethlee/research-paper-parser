{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrgSci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstract.</th>\n",
       "      <td>Abstract. \\nIn the wake of media hype about ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Introduction</th>\n",
       "      <td>Introduction\\nThe most promising uses of AI wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology as a Tool: How Technologies  Support Tasks and Work</th>\n",
       "      <td>Technology as a Tool: How Technologies  Suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology as a Medium: How  Technologies Enable Collaboration  Between Groups</th>\n",
       "      <td>Technology as a Medium: How  Technologies Enab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology as a Counterpart: How  People and Technologies Interact Within  a System of Work</th>\n",
       "      <td>Technology as a Counterpart: How  People and T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taking a Counterpart Perspective:  Methodological Challenges</th>\n",
       "      <td>Taking a Counterpart Perspective:  Methodologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Relational Approach to Ethnography  and Studying AI</th>\n",
       "      <td>A Relational Approach to Ethnography  and Stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conclusion</th>\n",
       "      <td>Conclusion\\nAlthough positive narratives about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endnotes</th>\n",
       "      <td>Endnotes\\n1 \\n\\n  Machine learning algorithms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>References</th>\n",
       "      <td>References\\nAjunwa I, Greene D (2019) Platform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text\n",
       "Abstract.                                           Abstract. \\nIn the wake of media hype about ar...\n",
       "Introduction                                        Introduction\\nThe most promising uses of AI wi...\n",
       "Technology as a Tool: How Technologies  Support...  Technology as a Tool: How Technologies  Suppor...\n",
       "Technology as a Medium: How  Technologies Enabl...  Technology as a Medium: How  Technologies Enab...\n",
       "Technology as a Counterpart: How  People and Te...  Technology as a Counterpart: How  People and T...\n",
       "Taking a Counterpart Perspective:  Methodologic...  Taking a Counterpart Perspective:  Methodologi...\n",
       "A Relational Approach to Ethnography  and Study...  A Relational Approach to Ethnography  and Stud...\n",
       "Conclusion                                          Conclusion\\nAlthough positive narratives about...\n",
       "Endnotes                                            Endnotes\\n1 \\n\\n  Machine learning algorithms ...\n",
       "References                                          References\\nAjunwa I, Greene D (2019) Platform..."
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "    \n",
    "import pprint\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "    main_section   \n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        rect = Rect(page.rect.x0 + 40, page.rect.y0 + 60, page.rect.x1 - 40, page.rect.y1 - 40) \n",
    "        \n",
    "        dict = page.get_text(\"dict\", clip = rect)\n",
    "\n",
    "        blocks = dict[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" in block.keys():\n",
    "                spans = block['lines']\n",
    "                for span in spans:\n",
    "                    data = span['spans']\n",
    "                    for lines in data:\n",
    "                        cur_size = round(lines['size'], 1)\n",
    "\n",
    "                        # Manual Override for References\n",
    "                        if lines['text'].strip() in (\"Acknowledgements\", \"References\", \"Appendix\", \"Endnotes\"):\n",
    "                            cur = Section(lines['text'], cur_size)\n",
    "                            curr_section = main_section.children[-1].children[-1]\n",
    "                            curr_section.add_child(cur)\n",
    "                            cur.set_parent(curr_section)\n",
    "                            curr_section = cur\n",
    "\n",
    "                            prev_size = round(lines['size'], 1)\n",
    "\n",
    "                        elif cur_size > prev_size:\n",
    "                            curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                            prev_size = curr_section.size\n",
    "\n",
    "                        elif cur_size == prev_size:\n",
    "                            curr_section.extend(lines['text'])\n",
    "\n",
    "                        else:  \n",
    "                            cur = Section(lines['text'], cur_size)   \n",
    "                            curr_section.add_child(cur)\n",
    "                            cur.set_parent(curr_section)\n",
    "                            curr_section = cur\n",
    "                            prev_size = round(lines['size'], 1)\n",
    "\n",
    "    # orgsci                            \n",
    "    return main_section.children[-1].children[-1].children\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references_dirty = \" \".join(references_dirty.split())\n",
    "    references = re.sub(\"([0-9]|html|\\))\\s?\\.\", r\"\\g<0>\\n\", references_dirty)\n",
    "\n",
    "    # Make list of references\n",
    "    pattern = r\"[A-ZÆØÅæøå][ÆØÅæøåA-Za-z]+.*[A-Z]{1,3},? .*\\(\\d{4}\\).*[html|\\d|\\)]\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \" and \" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\" and \")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def convert_pdf_to_dataframes(path) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(path)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    add_new_section = False\n",
    "    \n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract. \", 0)\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "    \n",
    "    sections_tmp = sections.copy()\n",
    "    earliest_index = 1000\n",
    "    txt = \"\"\n",
    "    \n",
    "    # Fit all text that belongs in paragraph into one \"Introduction\" paragraph\n",
    "    for idx, section in enumerate(sections_tmp):\n",
    "        if len(section.content) > 100:\n",
    "            add_new_section = True\n",
    "            if min(earliest_index, idx) != earliest_index:\n",
    "                earliest_index = idx\n",
    "            sections.remove(section)\n",
    "            txt += section.content\n",
    "            \n",
    "    \n",
    "    if add_new_section:\n",
    "        new_section = Section(\"Introduction\", 20)\n",
    "        new_section.add_child(Section(txt, 15))\n",
    "        sections[earliest_index] = new_section\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "import fitz\n",
    "import os\n",
    "\n",
    "ORGSCI_PATH = \"data/orgsci\"\n",
    "orgsci_pdfs = [f for f in os.listdir(ORGSCI_PATH) if f.endswith('pdf')]\n",
    "path = os.path.join(ORGSCI_PATH, orgsci_pdfs[0])\n",
    "\n",
    "sections_df, references_df = convert_pdf_to_dataframes(path)\n",
    "sections_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annurev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section:\n",
    "    def __init__(self, content, size):\n",
    "        self.children = []\n",
    "        self.size = size\n",
    "        self.parent = None\n",
    "        self.content = content\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.content.strip() == other.content.strip()\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def add_child(self, new_child):\n",
    "        self.children.append(new_child)\n",
    "        \n",
    "    def has_child(self):\n",
    "        return len(self.children) != 0\n",
    "    \n",
    "    def set_parent(self, new_parent):\n",
    "        self.parent = new_parent\n",
    "    \n",
    "    def extend(self, content):\n",
    "        self.content += f\" {content}\"\n",
    "    \n",
    "    def backtrack_add(self, content, size):\n",
    "        curr = self\n",
    "        \n",
    "        while curr.size <= size:\n",
    "            curr = curr.parent\n",
    "        \n",
    "        parent = curr\n",
    "        cs = Section(content, size)\n",
    "        parent.add_child(cs)\n",
    "        cs.set_parent(parent)\n",
    "                \n",
    "        return cs\n",
    "    def print_contents(self):\n",
    "        if len(self.children) == 0:\n",
    "            return self.content\n",
    "        \n",
    "        return self.content + \"\\n\" + \" \\n\\n \".join([child.print_contents() for child in self.children])\n",
    "    \n",
    "import pprint\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "    main_section   \n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        if page.number not in (doc[-1].number, doc[-2].number):\n",
    "            if page.number == 0:\n",
    "                rect = Rect(page.rect.x0 + 20, page.rect.y0 + 250, page.rect.x1 - 20, page.rect.y1 - 20) \n",
    "            else:\n",
    "                rect = Rect(page.rect.x0 + 20, page.rect.y0 + 20, page.rect.x1 - 20, page.rect.y1 - 20) \n",
    "            \n",
    "            dict = page.get_text(\"dict\", clip = rect)\n",
    "\n",
    "            blocks = dict[\"blocks\"]\n",
    "            for block in blocks:\n",
    "                if \"lines\" in block.keys():\n",
    "                    spans = block['lines']\n",
    "                    for span in spans:\n",
    "                        data = span['spans']\n",
    "                        for lines in data:\n",
    "                            cur_size = round(lines['size'], 1)\n",
    "\n",
    "                            # Manual Override for References\n",
    "                            if lines['text'].strip() in (\"Acknowledgements\", \"References\", \"Appendix\", \"Endnotes\"):\n",
    "                                cur = Section(lines['text'], cur_size)\n",
    "                                curr_section = main_section.children[-1].children[-1]\n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "\n",
    "                                prev_size = round(lines['size'], 1)\n",
    "\n",
    "                            elif cur_size > prev_size:\n",
    "                                curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                                prev_size = curr_section.size\n",
    "\n",
    "                            elif cur_size == prev_size:\n",
    "                                curr_section.extend(lines['text'])\n",
    "\n",
    "                            else:  \n",
    "                                cur = Section(lines['text'], cur_size)   \n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "                                prev_size = round(lines['size'], 1)\n",
    "\n",
    "    # orgsci                            \n",
    "    return main_section\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract\", 0)\n",
    "\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    abstract_text = sections.pop(abstract_index + 1)\n",
    "    sections[abstract_index].add_child(abstract_text)\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def make_sections_dataframe(path):\n",
    "    doc = fitz.open(path) # open a document\n",
    "    \n",
    "    # Get sections\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df.name = doc.name\n",
    "    return sections, sections_df\n",
    "\n",
    "def make_references_dataframe(sections, sections_df):\n",
    "    references_dictionary = {}\n",
    "    \n",
    "    references_clean = text_preprocess_for_reference_matching(sections[-1].print_contents())\n",
    "\n",
    "    for location, text in zip(sections_df.index[:-1], sections_df.values[:-1]):\n",
    "        in_text_citations = get_in_text_citations(text.item())\n",
    "        cleaned_in_text_citations = [\n",
    "            item \n",
    "            for group in \n",
    "                [  \n",
    "                    [c.strip()                             # Remove whitespace\n",
    "                     for c in citation[1:-1].split(',')    # Remove '(' and ')'\n",
    "                     if any(char.isdigit() for char in c)] # Remove any that doesn't have digits (year)\n",
    "\n",
    "                    for citation in in_text_citations\n",
    "                ]\n",
    "            for item in group \n",
    "        ]\n",
    "        author_year_pairs = list(filter(lambda x: x != None, map(process_citations, cleaned_in_text_citations)))\n",
    "        references_dictionary = find_citation_matches(author_year_pairs, references_clean, references_dictionary, location)\n",
    "\n",
    "    references_df = pd.DataFrame({k:[\",\".join(v)] for k,v in references_dictionary.items()}, index = [\"section\"]).T.reset_index(names = \"reference\")\n",
    "    \n",
    "    return references_df\n",
    "\n",
    "def text_preprocess_for_reference_matching(references_text):\n",
    "    # START searching ONCE References tag found\n",
    "    references_dirty = re.sub(\"\\n\", \" \", references_text)\n",
    "    references_dirty = \" \".join(references_dirty.split())\n",
    "    references = re.sub(\"([0-9]|html|\\))\\s?\\.\", r\"\\g<0>\\n\", references_dirty)\n",
    "\n",
    "    # Make list of references\n",
    "    pattern = r\"[A-ZÆØÅæøå][ÆØÅæøåA-Za-z]+.*[A-Z]{1,3},? .*\\(\\d{4}\\).*[html|\\d|\\)]\\.\"\n",
    "    references_clean = re.findall(pattern, references)\n",
    "    return references_clean\n",
    "    \n",
    "\n",
    "def get_in_text_citations(text):\n",
    "    IN_TEXT_CITATION_REGEX = r\"\\([\\w\\s.,]+\\s\\d{3,4}\\s?\\)\"\n",
    "    return re.findall(IN_TEXT_CITATION_REGEX, text)\n",
    "\n",
    "def process_citations(citation:str) -> (list,str):\n",
    "    # case 1: 2 authors\n",
    "    if \" and \" in citation:\n",
    "        tokens = citation.split()\n",
    "        year = tokens[-1]\n",
    "        names = \" \".join(tokens[:-1])\n",
    "        names_split = names.split(\" and \")\n",
    "        return ((names_split[0].strip(), names_split[1].strip()), year.strip())\n",
    "\n",
    "    # case 2: et al\n",
    "    if \"et al.\" in citation:\n",
    "        tokens = citation.split(\"et al.\")\n",
    "        return ([tokens[0].strip()], tokens[1].strip())\n",
    "    \n",
    "    # case 3: 1 author\n",
    "    else:\n",
    "        split = citation.split()\n",
    "        if len(split) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            tokens = citation.split()\n",
    "            year = tokens[-1]\n",
    "            author = \" \".join(tokens[:-1])\n",
    "            return ([author.strip()], year.strip())\n",
    "        \n",
    "        \n",
    "def find_citation_matches(author_year_pairs, full_references, data, location):\n",
    "    for author_year_pair in author_year_pairs:\n",
    "        authors, year = author_year_pair\n",
    "        for reference in full_references:\n",
    "            match = True\n",
    "            if f\"({year})\" in reference:\n",
    "                for author in authors:\n",
    "                    if author not in reference:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    dict_value = data.get(reference, [])\n",
    "                    if dict_value == []:\n",
    "                        data[reference] = []\n",
    "                    if location not in dict_value:\n",
    "                        data[reference] = data.get(reference, []) + [location]\n",
    "            else:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def convert_pdf_to_dataframes(path) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Returns (sections_df, references_df)\"\"\"\n",
    "    sections, sections_df = make_sections_dataframe(path)\n",
    "    references_df = make_references_dataframe(sections, sections_df)\n",
    "    return sections_df, references_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections(doc):\n",
    "\n",
    "    main_section = Section(\"\", 100)\n",
    "\n",
    "    prev_size = 100\n",
    "    curr_section = main_section\n",
    "    nest = {}\n",
    "\n",
    "    for page in doc:\n",
    "        if page.number not in (doc[-1].number, doc[-2].number):\n",
    "            rect = Rect(page.rect.x0 + 20, page.rect.y0 + 20, page.rect.x1 - 20, page.rect.y1 - 30)\n",
    "            \n",
    "            dict = page.get_text(\"dict\", clip = rect)\n",
    "            blocks = dict[\"blocks\"]\n",
    "            for block in blocks:\n",
    "                if \"lines\" in block.keys():\n",
    "                    spans = block['lines']\n",
    "                    for span in spans:\n",
    "                        data = span['spans']\n",
    "                        for lines in data:\n",
    "                            cur_size = round(lines['size'], 2)\n",
    "\n",
    "                            # Manual Override for References\n",
    "                            if lines['text'].strip() in (\"Abstract\", \"Keywords\", \"LITERATURE CITED\"):\n",
    "                                cur = Section(lines['text'], cur_size)\n",
    "                                curr_section = main_section.children[-1].children[-1]\n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "\n",
    "                                prev_size = round(lines['size'], 2)\n",
    "\n",
    "                            elif cur_size > prev_size:\n",
    "                                curr_section = curr_section.backtrack_add(lines['text'], cur_size)\n",
    "                                prev_size = curr_section.size\n",
    "\n",
    "                            elif cur_size == prev_size:\n",
    "                                curr_section.extend(lines['text'])\n",
    "\n",
    "                            else:  \n",
    "                                cur = Section(lines['text'], cur_size)   \n",
    "                                curr_section.add_child(cur)\n",
    "                                cur.set_parent(curr_section)\n",
    "                                curr_section = cur\n",
    "                                prev_size = round(lines['size'], 2)\n",
    "\n",
    "    final_sections = main_section.children[-1].children\n",
    "    \n",
    "    if len(final_sections) > 1:\n",
    "        return final_sections[-2].children + final_sections[-1].children\n",
    "    else:\n",
    "        return final_sections[-1].children\n",
    "\n",
    "def preprocess_sections(sections):\n",
    "    # Preprocess sections\n",
    "    abstract_section = Section(\"Abstract\", 0)\n",
    "\n",
    "    abstract_index = sections.index(abstract_section)\n",
    "    # abstract_text = sections.pop(abstract_index + 1)\n",
    "    # sections[abstract_index].add_child(abstract_text)\n",
    "\n",
    "    sections = sections[abstract_index:]\n",
    "    \n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n",
      "                                                                                                 text\n",
      "Abstract                                            Abstract\\nThis article provides an overview of...\n",
      "INTRODUCTION                                        INTRODUCTION\\nAs ﬁrms seek to compete using al...\n",
      "HISTORY OF STRATEGIC HUMAN RESOURCE MANAGEMENT:...  HISTORY OF STRATEGIC HUMAN RESOURCE MANAGEMENT...\n",
      "The Era of Conceptual Models                        The Era of Conceptual Models\\nFollowing these ...\n",
      "The Era of Empirical Examination                    The Era of Empirical Examination\\nHowever, for...\n",
      "The Era of Empirical Critiques                      The Era of Empirical Critiques\\nAs the volume ...\n",
      "WHERE WE ARE TODAY                                  WHERE WE ARE TODAY\\nSHRM research has grown bo...\n",
      "Theoretical Foundations                             Theoretical Foundations\\nWright & McMahan (199...\n",
      "Strategic Human Resource Management and Firm Pe...  Strategic Human Resource Management and Firm P...\n",
      "Multilevel Issues                                   Multilevel Issues\\nAlthough the ﬁeld of SHRM b...\n",
      "Fit and Flexibility                                 Fit and Flexibility\\nAnother area within the ﬁ...\n",
      "INTERNATIONAL STRATEGIC HUMAN RESOURCE MANAGEMENT   INTERNATIONAL STRATEGIC HUMAN RESOURCE MANAGEM...\n",
      "WHERE WE ARE GOING                                  WHERE WE ARE GOING\\nHaving described the histo...\n",
      "Increasing Rigor                                    Increasing Rigor\\nAs the “Era of Empirical Cri...\n",
      "Increasing Multilevel                               Increasing Multilevel\\nAs discussed previously...\n",
      "Increasing Global                                   Increasing Global\\nWhetten (2008) identiﬁed tw...\n",
      "Increasing Human Capital                            Increasing Human Capital\\nAs previously discus...\n",
      "Increasing Integration with Strategy Researchers    Increasing Integration with Strategy Researche...\n",
      "Increasing Integration with Practice                Increasing Integration with Practice\\nInterest...\n",
      "CONCLUSION                                          CONCLUSION\\nThe ﬁeld of SHRM has moved beyond ...\n",
      "DISCLOSURE STATEMENT                                DISCLOSURE STATEMENT\\nThe authors are not awar...\n",
      "LITERATURE CITED                                    LITERATURE CITED\\nAguinis H, Boyd BK, Pierce C...\n",
      "RELATED RESOURCES                                   RELATED RESOURCES\\nKetkar S, Sett PK. 2010. En...\n",
      "====\n",
      "                                                                                                 text\n",
      "Abstract                                            Abstract\\nThis review builds from the last maj...\n",
      "INTRODUCTION                                        INTRODUCTION\\nCollective turnover represents “...\n",
      "DEFINITIONS AND CONSTRUCT ISSUES                    DEFINITIONS AND CONSTRUCT ISSUES\\nAuthors have...\n",
      "THEORETICAL ADVANCEMENTS                            THEORETICAL ADVANCEMENTS\\nA key research objec...\n",
      "CHOOSING A COLLECTIVE TURNOVER MEASURE              CHOOSING A COLLECTIVE TURNOVER MEASURE\\nThe tr...\n",
      "Context-Emergent Turnover Theory                    Context-Emergent Turnover Theory\\nBeginning wi...\n",
      "Turnover Capacity                                   Turnover Capacity\\nHausknecht & Holwerda’s (20...\n",
      "RECENT EMPIRICAL CONTRIBUTIONS                      RECENT EMPIRICAL CONTRIBUTIONS\\nShortly after ...\n",
      "Meta-Analyses                                       Meta-Analyses\\nTwo of the four meta-analytic s...\n",
      "Original Articles                                   Original Articles\\nAlongside the meta-analyses...\n",
      "FUTURE RESEARCH NEEDS                               FUTURE RESEARCH NEEDS\\nThe collective turnover...\n",
      "FIFTEEN PROMISING RESEARCH QUESTIONS FOR FUTURE...  FIFTEEN PROMISING RESEARCH QUESTIONS FOR FUTUR...\n",
      "Expand the Study of Context (Research Questions...  Expand the Study of Context (Research Question...\n",
      "Move Beyond the United States (Research Questio...  Move Beyond the United States (Research Questi...\n",
      "Examine Events and Interventions (Research Ques...  Examine Events and Interventions (Research Que...\n",
      "Measure Process (Research Questions 3, 6, and 14)   Measure Process (Research Questions 3, 6, and ...\n",
      "Expand, Validate, and Reﬁne Measures (Research ...  Expand, Validate, and Reﬁne Measures (Research...\n",
      "CONCLUSION                                          CONCLUSION\\nDespite enduring interest at the i...\n",
      "DISCLOSURE STATEMENT                                DISCLOSURE STATEMENT\\nThe author is not aware ...\n",
      "LITERATURE CITED                                    LITERATURE CITED\\nBartunek JM, Huang Z, Walsh ...\n",
      "====\n",
      "                                                                                                 text\n",
      "Abstract                                            Abstract\\nThis article reviews the history of ...\n",
      "INTRODUCTION                                        INTRODUCTION\\nNo other talent management syste...\n",
      "PERFORMANCE EVALUATION                              PERFORMANCE EVALUATION\\nThe early history of P...\n",
      "Performance Evaluation Challenges                   Performance Evaluation Challenges\\nUnderlying ...\n",
      "Summary and Next Steps for Performance Evaluati...  Summary and Next Steps for Performance Evaluat...\n",
      "SUMMARY: PERFORMANCE EVALUATION                     SUMMARY: PERFORMANCE EVALUATION\\nBelow is a su...\n",
      "PERFORMANCE MANAGEMENT                              PERFORMANCE MANAGEMENT\\nWith ﬂatter, leaner or...\n",
      "New Approaches to Performance Management            New Approaches to Performance Management\\nThe ...\n",
      "Streamlining the Formal Performance Management ...  Streamlining the Formal Performance Management...\n",
      "DESIGNING PERFORMANCE MANAGEMENT PROCESSES TO D...  DESIGNING PERFORMANCE MANAGEMENT PROCESSES TO ...\n",
      "Driving More Effective Performance Management B...  Driving More Effective Performance Management ...\n",
      "KEY PERFORMANCE MANAGEMENT BEHAVIORS FOR MANAGERS   KEY PERFORMANCE MANAGEMENT BEHAVIORS FOR MANAG...\n",
      "KEY PERFORMANCE MANAGEMENT BEHAVIORS FOR EMPLOYEES  KEY PERFORMANCE MANAGEMENT BEHAVIORS FOR EMPLO...\n",
      "Successful Implementation of Performance Manage...  Successful Implementation of Performance Manag...\n",
      "Summary and Next Steps for Performance Manageme...  Summary and Next Steps for Performance Managem...\n",
      "SUMMARY: PERFORMANCE MANAGEMENT                     SUMMARY: PERFORMANCE MANAGEMENT\\nBelow is a su...\n",
      "DISCLOSURE STATEMENT                                DISCLOSURE STATEMENT\\nThe authors are not awar...\n",
      "LITERATURE CITED                                    LITERATURE CITED\\nAdler S, Campion M, Colquitt...\n",
      "====\n",
      "                                                                                                 text\n",
      "Abstract                                            Abstract\\nFor decades, the accepted view in or...\n",
      "INTRODUCTION                                        INTRODUCTION\\nBy the early 1970s, the broad co...\n",
      "THE FORESHADOWING OF ORGANIZATIONAL CITIZENSHIP...  THE FORESHADOWING OF ORGANIZATIONAL CITIZENSHI...\n",
      "ORGANIZATIONAL CITIZENSHIP BEHAVIOR: 1983–2005      ORGANIZATIONAL CITIZENSHIP BEHAVIOR: 1983–2005...\n",
      "ORGANIZATIONAL CITIZENSHIP BEHAVIOR: 2005–2016 ...  ORGANIZATIONAL CITIZENSHIP BEHAVIOR: 2005–2016...\n",
      "Focused Research on Speciﬁc Forms of Organizati...  Focused Research on Speciﬁc Forms of Organizat...\n",
      "Organizational Citizenship Behavior and Organiz...  Organizational Citizenship Behavior and Organi...\n",
      "Job Satisfaction Versus Personality                 Job Satisfaction Versus Personality\\nAs noted ...\n",
      "The Justice Motif                                   The Justice Motif\\nOnce the idea of job satisf...\n",
      "What is the “Downside” of Organizational Citize...  What is the “Downside” of Organizational Citiz...\n",
      "The “Good Citizen” as Identity                      The “Good Citizen” as Identity\\nFor the most p...\n",
      "What Directions Will Organizational Citizenship...  What Directions Will Organizational Citizenshi...\n",
      "Alternative Conceptual Frameworks                   Alternative Conceptual Frameworks\\nThus far, t...\n",
      "Methodology                                         Methodology\\nWe might do well to encourage mor...\n",
      "DISCLOSURE STATEMENT                                DISCLOSURE STATEMENT\\nThe author is not aware ...\n",
      "LITERATURE CITED                                    LITERATURE CITED\\nAguinis H. 2013. The too-muc...\n",
      "====\n",
      "                                                                             text\n",
      "Abstract                        Abstract\\nThis review of social network analys...\n",
      "INTRODUCTION                    INTRODUCTION\\nIt has been almost 100 years sin...\n",
      "SOCIAL NETWORK FOUNDATIONS      SOCIAL NETWORK FOUNDATIONS\\nA social network i...\n",
      "OLD NEW DIRECTIONS              OLD NEW DIRECTIONS\\nI would be remiss if I did...\n",
      "STRUCTURAL HOLES AND BROKERAGE  STRUCTURAL HOLES AND BROKERAGE\\nStructural hol...\n",
      "Beyond the Triad                Beyond the Triad\\nAlthough almost all the stru...\n",
      "Alters as Brokers               Alters as Brokers\\nPerhaps more importantly, m...\n",
      "NATURE OF TIES                  NATURE OF TIES\\nI have thus far focused on str...\n",
      "Strength of Ties                Strength of Ties\\nI begin with strength of tie...\n",
      "Negative Ties                   Negative Ties\\nAlthough strength of tie resear...\n",
      "Multiplex Ties                  Multiplex Ties\\nAlthough typically acknowledge...\n",
      "Dormant Ties                    Dormant Ties\\nDormant ties refer to past conne...\n",
      "Redundant Ties                  Redundant Ties\\nIn an effort to highlight the ...\n",
      "CONCLUSIONS                     CONCLUSIONS\\nWhat’s next in social network ana...\n",
      "SUMMARY POINTS                  SUMMARY POINTS\\n1. Adding affect, behavior, an...\n",
      "FUTURE ISSUES                   FUTURE ISSUES\\n1. Do the relative networks, an...\n",
      "DISCLOSURE STATEMENT            DISCLOSURE STATEMENT\\nThe author is not aware ...\n",
      "ACKNOWLEDGMENTS                 ACKNOWLEDGMENTS\\nThanks to Steve Borgatti, Dan...\n",
      "LITERATURE CITED                LITERATURE CITED\\nAral S, Van Alstyne M. 2011....\n",
      "====\n",
      "                                                                                           text\n",
      "Abstract                                      Abstract\\nSocial networks involve ties (and th...\n",
      "INTRODUCTION                                  INTRODUCTION\\nSocial network research in organ...\n",
      "TWO APPROACHES TO INTEGRATION                 TWO APPROACHES TO INTEGRATION\\nEmerging from t...\n",
      "Structure Dominates                           Structure Dominates\\nMuch social network resea...\n",
      "Bringing People Back In                       Bringing People Back In\\nSocial networks invol...\n",
      "DEBATES                                       DEBATES\\nGiven its diverse origins, social net...\n",
      "Strength of Ties                              Strength of Ties\\nTie strength was brought to ...\n",
      "Open versus Closed Networks                   Open versus Closed Networks\\nJust as researche...\n",
      "LEVELS OF ANALYSIS                            LEVELS OF ANALYSIS\\nSocial network theory and ...\n",
      "Individual Level                              Individual Level\\nThis concerns the social net...\n",
      "Dyad Level                                    Dyad Level\\nA distinguishing feature of networ...\n",
      "Triad Level                                   Triad Level\\nTriads are fundamental to researc...\n",
      "Network Level                                 Network Level\\nNetwork-level analysis of organ...\n",
      "Analytical Procedures for Levels of Analysis  Analytical Procedures for Levels of Analysis\\n...\n",
      "FUTURE RESEARCH Personality and Structure     FUTURE RESEARCH Personality and Structure\\nAs ...\n",
      "Network Change                                Network Change\\nDespite numerous calls to inve...\n",
      "Detecting Structural Opportunities            Detecting Structural Opportunities\\nTo benefit...\n",
      "Cross-Cultural Differences                    Cross-Cultural Differences\\nMost social networ...\n",
      "PRACTICAL IMPLICATIONS                        PRACTICAL IMPLICATIONS\\nPeople’s integration i...\n",
      "CONCLUSION                                    CONCLUSION\\nResearch on social networks thrive...\n",
      "SUMMARY POINTS                                SUMMARY POINTS\\n1. Social network research has...\n",
      "FUTURE ISSUES                                 FUTURE ISSUES\\n1. An unresolved question relat...\n",
      "DISCLOSURE STATEMENT                          DISCLOSURE STATEMENT\\nThe authors are not awar...\n",
      "LITERATURE CITED                              LITERATURE CITED\\nBaer M. 2010. The strength-o...\n",
      "RELATED RESOURCES                             RELATED RESOURCES\\nBorgatti SP, Everett MG, Fr...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "annurev_path = \"../data/annurev-orgpsych\"\n",
    "annurev_pdfs = [f for f in os.listdir(annurev_path) if f.endswith('pdf')]\n",
    "for i in range(len(annurev_pdfs)):\n",
    "    doc = fitz.open(os.path.join(annurev_path, annurev_pdfs[i])) # open a document\n",
    "    sections = get_sections(doc)\n",
    "    sections = preprocess_sections(sections)\n",
    "    print(\"====\")\n",
    "    \n",
    "    content_nest = {}\n",
    "\n",
    "    for section in sections:\n",
    "        content_nest[section.content] = [section.print_contents()]\n",
    "\n",
    "    sections_df = pd.DataFrame(content_nest, index = [\"text\"]).T\n",
    "    sections_df\n",
    "    pprint.pprint(sections_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
