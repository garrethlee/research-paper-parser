,text
Keywords,"[': learning algorithms', 'arti ﬁ cial intelligence', 'algorithmic brokers', 'knowledge brokerage', 'knowledge sharing', 'knowledge translation']"
Abstract.,"Abstract.  This paper presents research on how knowledge brokers attempt to translate opa- que algorithmic predictions. The research is based on a 31-month ethnographic study of the implementation of a learning algorithm by the Dutch police to predict the occurrence of crime incidents and offers one of the  ﬁ rst empirical accounts of algorithmic brokers. We studied a group of intelligence of ﬁ cers, who were tasked with brokering between a machine learning community and a user community by translating the outcomes of the learning algorithm to police management. We found that, as knowledge brokers, they performed different transla- tion practices over time and enacted increasingly in ﬂ uential brokerage roles, namely, those of messenger, interpreter, and curator. Triggered by an impassable knowledge boundary yielded by the black-boxed machine learning, the brokers eventually acted like  “ kings in the land of the blind ”  and substituted the algorithmic predictions with their own judgments. By emphasizing the dynamic and in ﬂ uential nature of algorithmic brokerage work, we contrib- ute to the literature on knowledge brokerage and translation in the age of learning algorithms. History:     This paper has been accepted for the Special Issue on Emerging Technologies and Organizing.    Keywords : learning algorithms   •     arti ﬁ cial intelligence   •     algorithmic brokers   •     knowledge brokerage   •     knowledge sharing   •    knowledge translation"
Introduction,"Introduction From healthcare to recruitment, litigation, and law en- forcement, learning algorithms are increasingly preva- lent in everyday work (e.g., Brayne  2020 , Rezazade Mehrizi et al.  2020 , Zhang et al.  2020 , Lebovitz et al. 2021 , Van den Broek et al.  2021 ). By combining large data sets with advanced computational and statistical methods to make connections between data points — a process that is called  “ machine learning ”  (Burrell 2016 , Brynjolfsson and McAfee 2017 , Davenport 2018 ) — learning algorithms generate algorithmic pre- dictions (Faraj et al.  2018 ). Learning algorithms de- serve speci ﬁ c scholarly attention, as we cannot rely on the existing understanding of “ intelligent tech- nologies ”  in organizations (Von Krogh  2018 , Bailey and Barley  2020 , Huysman  2020 , Pachidi et al.  2021 ). Earlier  “ rule-based ”  technologies, such as expert sys- tems, re ﬂ ected the expert knowledge that was coded into them (Forsythe  1993 ), and developers could ex- plain their outputs. In contrast, through machine learning, the input data and the knowledge of devel- opers are autonomously transformed into algorithmic predictions. The downside of machine learning is that it is dif ﬁ cult for humans to discern how and which connections between data points are made, which makes it challenging to understand how algorithmic predictions are generated. This problem is often referred to as the  “ opaque nature ”  (Burrell  2016 , Christin  2020 ) or  “ black box problem ”  (Pasquale  2015 , Anthony  2021 ) of learning algorithms. The opaque nature of learning algorithms makes trusting and using algorithmic predictions in practice problematic (Bader and Kaiser  2019 , Lebovitz et al. 2019 , Glikson and Woolley  2020 ). As a potential solu- tion, recent studies posit that  “ algorithmic brokers ” (Kellogg et al.  2020 ) could emerge to facilitate the use of these systems by translating predictions to users (Henke et al.  2018 , Gal et al.  2020 , Sachs  2020 ). The work of algorithmic brokers should therefore resem- ble what is referred to in organizational theory as “ knowledge brokers ”  (e.g., Carlile  2004 , Pawlowski and Robey  2004 , Meyer  2010 ) — actors who enact translation practices to solve knowledge boundaries between communities (Brown and Duguid  1998 ). These knowledge boundaries are de ﬁ ned by the practices that are easily shared by actors within com- munities and equally dif ﬁ cult to share by actors from different communities. For algorithmic brokers, this means solving a knowledge boundary between a machine learning community and a user community. ISSN 1047-7039 (print), ISSN 1526-5455 (online) http://pubsonline.informs.org/journal/orsc    A machine learning community can be de ﬁ ned by the shared practices of developing algorithmic predic- tions; a user community represents actors who share domain knowledge and intend to use algorithmic pre- dictions. Previous studies argue that for brokers to translate between communities requires a thorough understanding of the practices of both communities (Brown and Duguid  1998 , Sturdy and Wright  2011 , Røvik  2016 ). However, in the case of learning algo- rithms, algorithmic predictions are generated by com- bining inputs (i.e., data and developers ’  knowledge) with machine learning (Von Krogh  2018 ). Because of the black-boxed nature of learning algorithms, these aspects of the machine learning community remain hidden, even for developers (e.g., Faraj et al.  2018 ), which leads to a puzzle that goes beyond the current understanding of knowledge brokerage: How do brokers translate algorithmic predictions when they cannot understand how these are generated? To answer this question, we offer a 31-month ethno- graphic study of a Dutch police department that imple- mented predictive policing — that is, the use of a learn- ing algorithm to predict where and when a crime is likely to occur. By analyzing the implementation pro- cess over an extended period, we found that a group of “ intelligence of ﬁ cers ”  performed different translation practices through which they enacted increasingly in- ﬂ uential knowledge brokerage work (i.e., in the form of messenger, interpreter, and curator). Our study offers an integrative perspective on organizational theory and emerging technologies and reveals the emergence of a new phenomenon: the algorithmic broker with its dy- namic and in ﬂ uential nature. Through our process per- spective on knowledge brokerage work, we offer new insights into the literature on knowledge brokers (e.g., Brown and Duguid  1998 , Pawlowski and Robey  2004 , Meyer  2010 , Burgess and Currie  2013 ). The study shows that the translation practices that knowledge brokers enact over time afford them a unique position in which they can grow to become increasingly in ﬂ uen- tial. Moreover, this case highlights that knowledge bro- kerage work is more complex than resolving a knowl- edge boundary between communities (e.g., Dougherty 1992 , Carlile  2004 , Boari and Riboldazzi  2014 ), because, in their efforts to resolve such boundaries, brokers can generate new boundaries between themselves and the communities they are intended to connect. In addi- tion, our  ﬁ ndings contribute to translation theory (e.g., Czarniawska and Sev ´ on  2005 , Mueller and Whittle 2011 , Nielsen et al.  2014 , Røvik  2016 ). Whereas current translation theories mainly focus on how knowledge is translated to speci ﬁ c  ﬁ elds and organizations, we show the importance of unpacking how knowledge is trans- lated from its original source and provide insights into what happens to translation in the case of opaque ma- chine learning."
Research on Knowledge Brokers,"Research on Knowledge Brokers Sharing knowledge between actors coming from di- verse professional or organizational settings is consid- ered a key organizational competence and the topic has occupied many organizational scholars (e.g., Non- aka  1994 , Von Hippel  1994 , Østerlund and Carlile 2005 , Pachidi et al.  2021 , Safadi et al.  2021 ). Initially, knowledge was mainly considered as an object that had to be made explicit before it could be transmitted (e.g., Nelson and Winter  1982 , Teece  1998 ). However, organizational scholars started to counter this per- spective by arguing that knowledge is embedded in practices (e.g., Cook and Brown  1999 , Brown and Du- guid  2001 , Tsoukas  2003 ), which means that knowl- edge is shared through sharing practices. The practice-based perspective on knowledge has gained traction ever since and has triggered many interesting research avenues, such as how practice-based knowl- edge can be distributed, managed, and supported by technology (Orlikowski  2002 , Levina and Vaast  2005 , Faraj et al.  2016 ). Taking a practice-based perspective on knowledge helps us to see that knowledge sharing is a complex process, since the tacit elements of knowledge that are “ rooted in action, procedures, routines, commitment, ideals, values, and emotions ”  (Nonaka and von Krogh 2009 , p. 636) can lead to interpretative differences between actors residing in different communities (Lave  1988 , Brown and Duguid  1998 , Orlikowski 2002 , Carlile  2004 ). For example, Barley ( 1986 ) has shown how interpretative differences can emerge and grow when the implementation of a CT scanner re- quires knowledge sharing between technology devel- opers and technology users. In such situations, a so-called  “ semantic boundary ”  (Carlile  2004 ) hinders knowledge sharing as the communities ’  practice- based knowledge 1      continues to reproduce this bound- ary. Crossing a semantic boundary therefore requires creating shared understandings (Dougherty  1992 ). Some scholars argue that diverse actors can develop a shared understanding when they participate in shared practices (Brown and Duguid  1991 , Lave and Wenger  1991 , Orr  1996 ). However, most studies argue that such shared practices are unusual and emphasize that crossing a semantic boundary requires a particu- lar group of “ knowledge brokers ” to operate in-between communities by becoming familiar with them in order to gather and disseminate information and knowledge (e.g., Hargadon and Sutton  1997 , Brown and Duguid  1998 , Carlile  2004 , Evers and Menkhoff  2004 , Burgess and Currie  2013 , Chiambaret- to et al.  2019 ). Accordingly, organizational scholars have paid attention to the role of knowledge brokers in areas such as engineering (Johri  2008 ), science (Bar- ley  1996 , Kissling-Naf  2009 ), information technology (Pawlowski and Robey  2004 ), and recently regarding emerging technologies, such as learning algorithms (Kellogg et al.  2020 ). Knowledge brokers perform a kind of  “ boundary work ”  (e.g., Soundarajan et al. 2018 , Langley et al.  2019 ), yet differ from what are known as  “ boundary spanners ”  (e.g., Ancona and Caldwell  1992 , Levina and Vaast  2005 ) in that knowl- edge brokers do not belong to or come from the com- munities they intend to connect (Gould and Fernan- dez  1989 , Fleming and Waguespack  2007 , Meyer  2010 , Haas  2015 ). The concept of knowledge brokers is derived from the  ﬁ eld of broker studies (e.g., Gould and Fernandez 1989 , Burt  1992 , Obstfeld  2005 , Stovel and Shaw  2012 , Heaphy  2013 ) and traditionally resides in the structur- al network approach (e.g., DiMaggio  1993 , Fernandez and Gould  1994 , Reagans and McEvily  2003 , Leonardi and Bailey  2017 ). Taking this perspective, brokers are considered to occupy a  “ structural hole ”  (Burt  1992 ) between disconnected actors and to bene ﬁ t from unique access to various communities and knowledge sources (DiMaggio  1993 , Fernandez and Gould  1994 ). Studies on  brokerage work  move away from the struc- tural network perspective, in which a broker ’ s role is determined by one ’ s position in a network, to take a more practice-based perspective on how brokerage roles are enacted in practice (e.g., Wenger  1999 , Fernandez-Mateo  2007 , Lingo and O ’ Mahony  2010 , Obstfeld et al.  2014 , Edacott and Leonardi  2020 ). These studies emphasize how brokerage work emerges when new tasks are created that existing communities are unwilling or unable to take on (Barley  1996 , Heimer and Stevens  1997 , O ’ Mahony and Bechky 2008 , Huising and Silbey  2011 ). For example, Kellogg ( 2014 ) examined how, in the face of organizational re- form at a hospital, brokers took on tasks that medical professionals and lawyers did not consider to be part of their occupational domain. In the case of knowledge brokerage, these new tasks are typically related to translating knowledge in order to ensure that actors across different communities can understand each other. Knowledge brokers therefore enact translation practices through which they present the knowledge of one community in such a way that it gains a shared understanding and can be put in practice (Tushman and Katz  1980 , Barley  1996 , Grady and Pratt  2000 , Paul and Whittam  2010 , Boari and Riboldazzi  2014 ). To enact such translation practices, knowledge brokers depend on their interactions with the communities with the aim to (1)  decontextualize knowledge in order to  translate knowledge from  one community into more abstract representations (e.g., words or texts) and to (2)  contextualize  the abstract rep- resentations in order to  translate to  another community (Callon  1984 , Latour  1986 , Czarniawska and Joerges 1996 , Doorewaard and van Bijsterveld  2001 , Nielsen et al.  2014 , Røvik  2016 ). Translation thus requires a deep understanding of both communities, which makes performing translation a knowledge-intensive practice in itself. For knowledge brokers, who are not members of any of the communities they intend to connect (Gould and Fernandez  1989 , Fleming and Waguespack  2007 , Meyer  2010 , Haas  2015 ), understanding these commu- nities can thus be a challenging and extensive task (Brown and Duguid  1998 ). This becomes even more problematic with the recent emergence of  “ algorithmic brokers. ”  Below, we unpack why the unique, black- boxed nature of learning algorithms offers new chal- lenges to knowledge brokerage work."
Brokering Learning Algorithms,"Brokering Learning Algorithms Learning algorithms are calculative devices used for “ machine learning, ”  a sub ﬁ eld of the broader  ﬁ eld of “ arti ﬁ cial intelligence ”  (AI). Whereas AI technologies, on the surface, appear to mainly consist of abstract statistical equations, there is always a community of computer scientists behind it, who construct the ab- stract mathematical representations through situated, embodied, and social practices (Lave  1988 ). AI tech- nologies consist of three parts: task inputs, task pro- cesses, and task outputs (Von Krogh  2018 ). Task in- puts comprise the input data and the knowledge of the developers, for example, of constructing, cleaning, and preparing data sets and of coding the initial deci- sion logic of the learning algorithm. Task processes re- fer to machine learning, that is, making and adjusting connections between a large number of data points, which changes the decision logic as initially coded. The task outputs are the algorithmic predictions, which can be put in practice by users and are often used as new data points for the learning algorithm. Whereas the task inputs are relatively transparent (e.g., data sets can be looked into, and developers can be asked about their practices), the task processes (i.e., machine learning) present a challenging new phenom- enon, as machine learning becomes increasingly dif ﬁ - cult for humans to understand (Brynjolfsson and McAfee  2017 , Faraj et al.  2018 , Gal et al.  2020 ). This is referred to as the  “ opaque nature ”  (Burrell  2016 , Christin  2020 ) or the  “ black-box problem ”  (Pasquale 2015 , Introna  2016 , Ajunwa  2020 , Anthony  2021 ) of learning algorithms and mainly occurs because the procedures used for machine learning differ funda- mentally from  “ demands of human-scale reasoning and styles of semantic interpretation ”  (Burrell  2016 , p. 2). To illustrate this point, Burrell ( 2016 , p. 9) dis- cussed a spam  ﬁ lter:  “ Humans likely recognize and evaluate spam according to genre: the phishing scam, the Nigerian 419 email, the Viagra sales pitch. By con- trast, the  ‘ bag of words ’  approach [i.e., machine learn- ing] breaks down texts into atomistic collections of units, words whose ordering is irrelevant. ”  Thus, whereas humans use their ability to interpret and put a message into context to assess if an email is spam, a learning algorithm uses words commonly associated with spam (e.g., click, dollar, price), is trained to rank these words by weight,  ﬂ ags an email based on the ag- gregate of the weights of all words, and becomes bet- ter at doing this over time through machine learning. Understanding how algorithmic predictions are gen- erated therefore requires not only discerning the task in- puts (e.g., the data used to develop and train the model or the internal decision logic as coded by developers) but also unpacking the machine learning, that is, how the learning algorithm ’ s internal decision logic changes when the algorithm learns from data. However, the in- herent difference between machine learning and hu- man reasoning makes the opaque nature of learning algorithms a fundamental issue and keeps even devel- opers in the dark about how the internal decision logic of these systems evolves over time (Michalski et al. 2013 , Faraj et al.  2018 ). As a consequence, black-boxed machine learning is a speci ﬁ c area of concern in the ﬁ eld of computer science, which triggered these schol- ars to study  “ explainability issues ”  and how to allevi- ate them (e.g., Doran et al.  2017 , Kirsch  2017 , Lipton 2018 , Preece et al.  2018 , Miller  2019 , Mittelstadt et al. 2019 , Robbins  2019 , Barredo et al.  2020 ). They argue that the nature of learning algorithms is a double- edged sword: their key strength (i.e., learning from large data sets to arrive at predictions) is simulta- neously their main problem. The explainability issues are also gaining traction with organizational scholars, who increasingly emphasize that when users are con- fronted with algorithmic predictions that cannot be ex- plained or understood, they experience dif ﬁ culties trusting, using, and maintaining control over the role of learning algorithms in their decision-making pro- cesses (Zarsky  2016 , Bader and Kaiser  2019 , Lebovitz et al.  2019 , Christin and Brayne  2020 , Gal et al.  2020 , Glikson and Woolley  2020 , Dur ´ an and Jongsma  2021 ). To overcome the explainability issues of learning al- gorithms in organizations, organizational scholars em- phasize the need to make algorithmic predictions comprehensible and actionable to users (Bolin and Andersson Schwarz  2015 ). This requires new tasks re- lated to translating algorithmic predictions in practice (Henke et al.  2018 , Gal et al.  2020 , Kellogg et al.  2020 , Sachs  2020 , Shestakofsky and Kelkar  2020 ). As the practices of developing algorithmic predictions of the machine learning community and the domain practi- ces of the user community are not easily shared, a semantic boundary creates an opportunity for knowl- edge brokers to step in and take up translation tasks (Carlile  2004 ). By translating algorithmic predictions to users, algorithmic brokers (Kellogg et al.  2020 ) are seen as providing a potential solution to the explainability problem established in computer sci- ence (Henke et al.  2018 ). Yet, an interesting puzzle arises regarding the abili- ty to translate algorithmic predictions. As we have discussed, theories on translation taught us that to en- act translation practices requires knowledge brokers to interact with and understand the communities in- volved (e.g., Brown and Duguid  1998 , Røvik  2016 ). Such interaction is signi ﬁ cantly hindered in the case of learning algorithms. More precisely, whereas brokers can interact with developers to discover the knowledge of the machine learning community, the black-boxed machine learning prevents them from fully understanding how algorithmic predictions are generated. In translating predictions to users, algorith- mic brokers are thus confronted with a new situation in which understanding the input data and the knowl- edge of developers is not enough to comprehend how algorithmic predictions are generated. Accordingly, our aim is to analyze which practices algorithmic brokers enact when they encounter black-boxed learn- ing algorithms — in other words, when they operate “ in the land of the blind. ”"
Methods,"Methods Research Setting Our study focuses on the implementation of the so-called  “ Crime Anticipation System ”  (CAS), which was internally developed by a team of so-called  “ data scientists ”  at the Dutch police. The development of CAS was initiated by the national police management to allocate police resources (e.g., patrol of ﬁ cers, spe- cialized teams, material resources) more effectively and ef ﬁ ciently by predicting where and when a crime was most likely to occur. In contrast to, for example, the fragmented organizational structure of the U.S. police force (see e.g., Van Maanen  1973 , Brayne  2020 ), the Dutch police is nationally organized and coordi- nated, which facilitated the nationwide implementa- tion of CAS. The Dutch police started the predictive policing project in 2012 by hiring three data scientists and, between 2012 and 2017, gradually expanded the data science team to about 20 members. Maintaining CAS remained one of the responsibilities of these data scientists, although after its implementation at local police departments, most of the members of the data science team were also actively involved in other proj- ects, such as developing counterterrorism learning al- gorithms and image recognition for investigating and preventing child sexual abuse. One data scientist (Dennis 2    ) took the lead in the development of CAS and was therefore the main  “ brains ”  behind the learn- ing algorithm. All other data scientists were responsi- ble for maintaining the system and performing updates. In 2013, the data scientists  ﬁ nished the  ﬁ rst version of CAS, which predicted a week in advance where and when a crime was most likely to occur. During the test phase, the work of  “ intelligence of ﬁ cers, ”  who could help local police managers to use the crime pre- dictions, emerged. In the Findings section, we will go into detail about the emergence of these intelligence of ﬁ cers as algorithmic brokers. Here, it is important to emphasize that the implementation of CAS therefore included data scientists as developers, intelligence of- ﬁ cers as algorithmic brokers, and local police manag- ers (hereafter  “ police managers ” ) as users. The inter- action between intelligence of ﬁ cers, data scientists, and police managers in the implementation and use of CAS was in ﬂ uenced by the siloed and hierarchical organizational structure of the Dutch police. The  “ user community ”  consisted of the police managers who were intended to use the crime predictions in their op- erational decision-making practices, such as allocating police resources. They transferred data-related tasks to intelligence of ﬁ cers, and, because the nature of po- lice work is action-oriented and police managers con- sidered CAS to be extremely complex and  “ foreign, ” they did not feel the need to engage with CAS directly and trusted intelligence of ﬁ cers to do so. As one police manager responded to an intelligence of ﬁ cer,  “ You lost me at http. ” The  “ machine learning community ”  consisted of the data scientists, the data, and the CAS learning al- gorithm. To create CAS, the data scientists were in- spired by the U.S. version  “ PredPol. ”  Whereas the po- lice could have bought into the external PredPol algorithm, national management decided that the in-house data scientists could better develop a new version so that it would not require the police to share vulnerable data with external sources. Moreover, through in-house development, the police planned to hold a grip on which data and variables were includ- ed in the learning algorithm (e.g., to prevent pro ﬁ ling, they decided not to include individual-level data). The data scientists used logistic regression analysis as the technique for the CAS learning algorithm. Lo- gistic regression analysis is a very popular method in machine learning, speci ﬁ cally for binary classi ﬁ cation tasks (i.e., a problem with two class values, such as “ crime ”  and  “ no crime ” ). It is used to predict, for ex- ample, whether an email should be classi ﬁ ed as spam or not, whether a tumor is benign or malignant, or whether a loan will or will not be repaid. Because learning algorithms are trained using large amounts of data, CAS was developed with data of crimes with the highest reporting numbers, which are called “ high-impact crimes ”  (e.g., burglary, car theft, rob- bery). Such crimes are relatively easy to carry out and thus happen frequently, and they have a high impact on citizens, which means that they are often reported. The reporting of these crimes results in a large num- ber of data points, which makes them speci ﬁ cally suit- ed for developing and training learning algorithms. For the CAS algorithm to learn, the data scientists constructed a data set with historic high-impact crime data. They divided the country into squares of 125 m 2    and used three years of historical data for every square. Across the three years, they used biweekly ref- erence moments, which resulted in 76 lines of data per square. Each line of data consisted of eight technical variables and 47 predictive variables (limited by strict data regulations). The technical values included, for example, time indicators, the name of the police sta- tion, and the name of the police district. The 47 predic- tive variables consisted of 19 population-related varia- bles (e.g., number of one-parent households, total number of addresses, average house price, number of male and female inhabitants, and average age of in- habitants) and 28 crime-speci ﬁ c variables (e.g., for burglary, variables such as time since the last burglary and number of burglaries in the last two weeks). In addition, each line included whether the speci ﬁ c crime happened in the two weeks between the refer- ence moment. To predict the probabilities of future crimes, the logistic regression model of CAS was trained to learn a mapping between the 47 predictive variables and whether a crime happened or not. To transform the numerical probabilities into a visualiza- tion of the crime predictions on a map, threshold val- ues were added to determine whether and in what color predicted squares appeared on the map; the darker the color, the higher the predicted probability (see Figure  1 ). Data extraction, model building, and map generation were automated and happened on a Figure 1.  (Color online) Visualization of Predictions as Per- ceived in the User Interface    weekly basis. The model was thus able to autono- mously learn and generate predictions. This, in combi- nation with the size of the data set and the high num- ber of predictions, made the internal decision logic of predictions opaque in practice, even for the data scientists. The data scientists were located in a different build- ing, far removed from daily police operations and the intelligence of ﬁ cers. They were hired for their exper- tise in computer science and were expected to create systems that would generate new insights for police operations across the country. The data scientists were not bothered by their distance from daily police oper- ations. They considered algorithmic predictions fun- damentally different from police occupational knowl- edge and were convinced that these predictions could and should be generated away from the police. As a result, the data scientists only occasionally interacted with intelligence of ﬁ cers (via email or organized meet- ings held on average twice a year) and rarely spoke with police managers. Data Collection We performed ethnographic research with the aim of theory elaboration to make theoretical advancements (Fisher and Aguinis  2017 ). We conducted our  ﬁ eld- work with the Dutch police over 31 months, from Oc- tober 2016 to April 2019. During these three years, the ﬁ rst author observed and took part in the daily work at the intelligence department and the emergency re- sponse department. In this study, we report on our data of the intelligence department only. We followed the intelligence of ﬁ cers over these three years, with an intensive observation period in the second year of the study, in which the  ﬁ rst author joined the intelligence department approximately three days a week, observ- ing and taking part in the intelligence of ﬁ cers ’  work. All observations were conducted when CAS was al- ready in use, and details about CAS were obtained through (retrospective) interviews with data scientists and archival documents. Our interest in the role of the intelligence of ﬁ cers was triggered when, at the start of our  ﬁ eldwork, we were surprised to see that the police managers did not directly interact with CAS and that the intelligence of ﬁ cers performed this work instead. The  ﬁ rst author had unrestricted access to the intel- ligence department — which consisted of about 15 full- time employees — of a police station in a large Dutch city. She shadowed the intelligence of ﬁ cers in all their work, including their interactions with CAS, data sci- entists, police managers, and police of ﬁ cers. Her main focus was on the intelligence of ﬁ cers, but joining the various interactions also gave her thorough insights into the other groups involved. She would usually sit at the desk next to one of the intelligence of ﬁ cers and write down in detail which features they used when working with CAS, how they tried to make sense of the learning algorithm and the crime predictions, and how they reasoned and went about representing the predictions to police managers. Through her pro- longed presence at the intelligence department, she gained the trust of the intelligence of ﬁ cers to perform some of the intelligence activities herself, which gave her deep insights in the efforts involved in performing intelligence of ﬁ cers ’  work. For example, they asked her to help out with extensive database searches, and she was given access to the CAS user interface to go through crime predictions and eventually even helped new intelligence of ﬁ cers settle in by explaining how to use CAS. The  ﬁ rst author also followed other activities of the intelligence of ﬁ cers, which gave her a rich contextual understanding of the empirical site. For example, par- ticipating in brie ﬁ ngs at the start of police shifts, join- ing management meetings and meetings with data scientists, and accompanying the intelligence of ﬁ cers for lunch and occasional festivities, such as their year- ly team outing and Christmas party. Finally, the  ﬁ rst author joined one of the intelligence of ﬁ cers ap- pointed as spokesperson to regional (once a month) and national (once every six months) gatherings of in- telligence of ﬁ cers at police stations across the country. Because the intelligence of ﬁ cers all worked at different police stations, these meetings were used to re ﬂ ect and learn from each other. Initially during these meet- ings, the intelligence of ﬁ cers shared best practices and their struggles with translating algorithmic predic- tions. This further established the  ﬁ rst author ’ s obser- vations of the challenges faced by the intelligence of ﬁ - cers. Near the end of the  ﬁ eldwork, the  ﬁ rst author observed that the intelligence of ﬁ cers collectively em- phasized the need to substitute predictions, which validated her observations of how the role of intelli- gence of ﬁ cers changed over time. By actively partici- pating in all facets of the intelligence of ﬁ cers ’  work, the  ﬁ rst author became fully socialized into the intelli- gence department, by which she developed a holistic perspective of intelligence of ﬁ cers ’  work and their relationship to other stakeholders, a deep understand- ing of the work practices performed, as well as the un- derlying feelings and experiences, such as confusion, stress due to time pressure, and tiredness, and the pride and joy of being able to come up with a  ﬁ tting recommendation. In addition, the  ﬁ rst author also conducted 33 formal semistructured interviews. Voice recording was possi- ble for 25 interviews, which were transcribed verbatim. For the other eight, detailed notes were taken during the interview and expanded afterward into an elabo- rate summary. We explicitly searched for and con- tacted people who could provide rich details and reasoning into how CAS development, implementation, and deployment proceeded and why. The  ﬁ rst author interviewed actors from all groups involved to main- tain a multiactor perspective. These actors included data scientists who were closely involved with CAS for the longest time, intelligence of ﬁ cers who were at the intelligence department already before the imple- mentation of CAS, and police managers who were closely involved in the implementation of the learning algorithm. Moreover, for a deeper understanding of the police occupational world, the  ﬁ rst author inter- viewed  ﬁ ve patrol of ﬁ cers, who needed to have at least 10 years of experience to make sure they could deeply re ﬂ ect on their work. The main questions asked to data scientists were about the techniques used in CAS to get in-depth, retrospective insight into the development and reasoning behind CAS. After one of these interviews, the  ﬁ rst author sat with the data scientist to have a close look at the learning algo- rithm of CAS, which gave her a better understanding of the methods used. Intelligence of ﬁ cers and police managers were asked to describe their occupational trajectory, their daily activities, and what role CAS played in these activities to get an in-depth under- standing of the in ﬂ uence of the learning algorithm on their everyday work. In addition, police managers were asked about their views on the usefulness of CAS for allocating police resources and crime preven- tion to understand their motivation behind working with the system. At the very end of the  ﬁ eldwork (April 2019), the  ﬁ rst author conducted retrospective interviews with two intelligence of ﬁ cers, where she asked them to reconstruct how their work practices and responsibilities changed from the introduction of CAS in 2015 to their current role. Finally, during the  ﬁ eldwork, countless informal conversations took place with all groups involved. These informal conversations allowed the  ﬁ rst author to ask questions to solicit interpretations of speci ﬁ c events or decisions. For retrospective details, we also collected documentation data that were either inter- nally or externally available. These materials were very valuable, as they gave us additional information about the technical speci ﬁ cations of CAS (e.g., the complete list of variables used) and insight into, for example, the evaluations of the CAS implementation, strategic plans, reasoning and expectations about role transformations, and meeting details. We summarized each of the data sources in Table  1 . Data Analysis Throughout the data collection, we engaged in regular conversations to re ﬂ ect on observations, ask ourselves what these meant, and link them to related literature. The coding was performed by the  ﬁ rst and second au- thors, with the  ﬁ rst author taking the lead and the sec- ond author frequently checking in and adding input. We began coding by reading  ﬁ eld notes and interview transcripts, adding potential codes in the margins. This helped us to identify important themes. For ex- ample, we were struck by how the intelligence of ﬁ cers frequently referred to unexpected changes in their work and role and remarks about their growing in ﬂ u- ence on police managers. To trace how this growing in ﬂ uence came about, we performed a temporal anal- ysis of our data, broadly mapping the changes. We also noted the struggles of intelligence of ﬁ cers with understanding and interpreting algorithmic predic- tions. This triggered us to further scrutinize the nature of algorithmic predictions and how this related to the intelligence of ﬁ cers ’  brokerage work. We used open coding (parsing out the data to un- derstand the underlying dynamics) to conduct a more formalized analysis of the  ﬁ eld notes and transcripts (Strauss and Corbin  1990 ). We initially focused on specifying in detail the activities and interactions of the three groups involved. We categorized the codes by the occupational group to maintain oversight (i.e., “ data scientists, ” “ intelligence of ﬁ cers, ”  and  “ police managers ” ) and used these groups to construct a visu- al map that portrayed how certain activities triggered speci ﬁ c events (Langley  1999 ). 3      We then engaged in further rounds of axial coding, that is, unraveling more thematic relationships and contrasts through coding across concepts (Strauss and Corbin  1990 ), and noticed that the intelligence of ﬁ cers ’  efforts to under- stand both the machine learning community and the police community played a central role in how their work changed over time. We compared and contrasted the intelligence of ﬁ cers ’  interactions with the learning algorithm, the developers, and the associated algorith- mic predictions, as well as with the police community, through which  ﬁ ve key translation practices emerged: (1) extracting, (2) examining, (3) transferring, (4) do- mesticating, and (5) substituting (see Figure  2 ). Using the literature on knowledge brokerage work and translation theory helped us to better understand what these  ﬁ ve brokerage practices exempli ﬁ ed. Based on theories on translation (Røvik  2016 ), we grouped the practices  “ extracting ”  and  “ examining ” under the theoretical category  “ translating from (ma- chine learning community) ” and the practices “ transferring, ” “ domesticating, ”  and  “ substituting ” under the theoretical category  “ translating to (user community). ”  Together, these two theoretical categories formed the basis for our understanding of algorithmic brokerage work. This structure, and its associated prac- tices, also helped us to see how the algorithmic broker- age work evolved through a cumulative process, in which new types of practices built on earlier ones. In this cumulative process, we identi ﬁ ed three algorithmic brokerage roles: (1) messenger, (2) interpreter, and (3) curator. In what follows, we use these roles to explain the cumulative efforts to translate algorithmic predic- tions in practice."
Findings,"Findings After a two-year development period, in 2015, the data scientists performed a test to see whether the CAS could be nationally implemented. They deployed the learning algorithm for several months in  ﬁ ve large Dutch cities, which was closely monitored by evalua- tors from the Dutch police academy. After the test, which was considered a success, the evaluators wrote a report in which they indicated an occupational group called  “ intelligence of ﬁ cers, ”  who emerged as important actors who  “ supported police managers ”  at local police stations by  “ being able to generate CAS predictions ”  (internal document). The importance of intelligence of ﬁ cers was surprising to the evaluators, since, before the introduction of CAS, the work of in- telligence of ﬁ cers mainly involved supporting police of ﬁ cers by searching the numerous police databases when the police themselves did not have direct access to them (e.g.,  ﬁ nding crime numbers, suspect data, or information about criminal networks). Intelligence of- ﬁ cers were  “ hidden ”  in a back of ﬁ ce, the work was generally regarded as low-status, the education level Table 1.     Description of Data Sources and Their Uses Data types Amount/duration Use in analysis Primary data Observations of intelligence of ﬁ cers ’  work Between October 2016 and April 2019, 565 hours Provided rich insight into the daily practices and lived experience of intelligence work and their interactions with data scientists and police managers. Meetings with data scientists 2 (average duration: 2 hours) Provided insight into the intelligence of ﬁ cers ’  attempt at giving feedback to the data scientists and the data scientists ’ responses. Management meetings 47 (average duration: 2 hours) Provided insight into the changing dominance of intelligence work and how the managers responded. Brie ﬁ ngs 123 (average duration: 15 minutes) Provided insight into the translation of intelligence work to daily police practice. Intelligence gatherings (regional and national) 14 (average duration: 2 hours) Provided broader insight into how intelligence of ﬁ cers ’  work evolved regionally and nationally. Formal interviews Total: 33 (average duration: 1 hour) Enriched and deepened our understanding of the worlds of the communities involved. Intelligence of ﬁ cers 8 ( 6  50% of the team) Enriched our understanding of the background and development of intelligence work. Data scientists 7 Enriched our understanding of the  “ machine reasoning ”  world of the data scientists. Police managers 13 Enriched our understanding of the police occupational world, the needs for police operational decision-making, and the managers ’  trust in data and algorithms. Police of ﬁ cers 5 Enriched our understanding of the police occupational world. Secondary data Documentation Total: 431 documents Validated observation and interview  ﬁ ndings and added context and historical insights. Management documents Meeting documents Strategy documents 32 3 Provided insight into managerial decisions and helped to establish the chronology. Intelligence documents Role descriptions Intelligence outputs Educational documents 11 28 6 Provided insight into the developments in the role of the intelligence of ﬁ cers and helped to establish the chronology. Additional documents External sources Crime and activity reports 24 237 Provided insight into the backgrounds to CAS and enriched our understanding of the police occupational world.    required for the position was low — it did not require one to be knowledgeable of technology or police work — and it was considered to offer an opportunity for those who  “ wanted to join the police without wanting to work on the street ”  (intelligence of ﬁ cer Louisa). The evaluators, however, saw the potential bene ﬁ ts of tasking intelligence of ﬁ cers, who were used to working with police data, with translating algorithmic predictions to make them meaningful for police work. They ended their report with suggestions for a new work process for contextualizing algorithmic predic- tions. According to the evaluation report, the work process should include three steps: actualizing, inter- preting, and explaining. Actualizing meant adjusting predictions to local changes (e.g., when a burglar was captured). Interpreting meant adding more informa- tion to the crime predictions, such as the most-used crime methods. Explaining meant deeply analyzing why a crime is predicted (i.e.,  ﬁ nding causal explana- tions for the algorithmic predictions). The data science team agreed with the suggestion of the evaluators and gathered that intelligence of ﬁ cers could, for example, contextualize a burglary prediction by adding infor- mation about the kind of houses in the targeted area: You need to have somebody [i.e., an intelligence offi- cer] who looks at the maps and thinks about the causes of high risk and how to prevent them. How to take the cause away so that you are not fighting the symptoms but taking away the cause of the problem. (Data scientist Dennis)    The intelligence of ﬁ cers were thus expected to  ﬁ nd un- derlying causes for predictions, but the data scientists assumed that they did not need to understand how the learning algorithm generated predictions to perform their translation tasks and that access to police data- bases would be enough. As one of the data scientists ex- plained,  “ Intelligence of ﬁ cers don ’ t have to interpret model parameters or any kind of technical stuff; they just get the maps. ”  The intelligence of ﬁ cers were thus asked to ful ﬁ ll brokerage work without full insight into how algorithmic predictions were generated. Below, we analyze the efforts of a group of intelli- gence of ﬁ cers at one police station to translate crime predictions for police managers and how they thereby Figure 2.  Conceptual Scheme    enacted three consecutive roles — namely, those of messenger, translator, and curator. We discuss how these efforts were hindered by the inability to under- stand machine learning and how this eventually led the intelligence of ﬁ cers to believe that the predictions should be substituted by their own alternatives. Algorithmic Broker Acting as Messenger The main aim of intelligence of ﬁ cers ’  work was to make abstract algorithmic predictions meaningful for local police managers. The predictions were available to the intelligence of ﬁ cers by means of an interactive map, where they could select the location, the crime type, and the time frame. Because police managers never looked at the map, they asked the intelligence of ﬁ cers to generate a weekly overview of the predic- tions, which could be used as input for scheduling police resources. Generating such an overview was a laborious task for the intelligence of ﬁ cers. For example, they had to click on every time frame in a drop-down menu, 4      and since the system generated predictions for four different crime types per police station, the intelli- gence of ﬁ cers went through this cycle four times, se- lecting a time frame in the drop-down menu a total of 168 times. When a prediction appeared on the map in the form of a colored block, they translated the predic- tions into words and added it to a Word document — for example,  “ burglary, Monday, between 12:00 and 16:00, [street name]. ”  Per crime type, the  ﬁ nal list made in Word included on average one predicted time frame and one or two predicted areas a day. Through this process of extracting predictions, a comprehensive list of predictions was generated. However, because the map did not offer any insights into the causes, they had little clue about the meaning of these predictions in the context of the police. More- over, since their new tasks caused them to be  “ in search of their identity as intelligence of ﬁ cers and sometimes didn ’ t know where their work ended ”  (in- telligence of ﬁ cer Wendy), their insecurity grew to- ward the information needs of the police managers. Afraid to leave out a prediction that might turn out to be right, or add irrelevant information, the intelligence of ﬁ cers decided to stick to comprehensive reporting of all crime predictions. Better safe than sorry, the in- telligence of ﬁ cers gathered that transferring a full overview of potential crimes would be best to support police managers ’  decision making and assumed that “ all police managers probably know what ’ s behind the predictions ”  (intelligence of ﬁ cer Eva). Even though it took the intelligence of ﬁ cers quite some time and effort to construct exhaustive lists of predictions, the police managers did not receive the lists with much enthusiasm; the document was too long, and the causes were unknown. For example, po- lice manager Rudy re ﬂ ected that the long lists were dif ﬁ cult to use because they lacked a speci ﬁ c focus: “ If you keep the [algorithmic predictions] too broad, then we are quick to ignore them. I think the more concrete you are, the more feeling we have for it. ” The data scientists also acknowledged that simply list- ing crime predictions was not enough, because the “ quantitative ”  predictions needed  “ qualitative in- sights ”  (data scientist Dennis). They emphasized the need to  “ add color to ”  and  “ enrich ”  the crime predic- tions. As Dennis explained: Intelligence officers have to take the predictions and enrich them with qualitative information. For exam- ple [for burglary predictions], adding who could do it or why burglaries might occur in that area or at that time. Intelligence officers could say:  “ we have some narcotics-related issues here, so maybe it could be junkies? ”  Most of the time, junkies aren ’ t well- prepared criminals, so maybe it ’ s just very easy for them to burglarize that area. So maybe those houses have very bad hinges and locks and you can just en- ter them with a very easy trick. That ’ s the kind of context the intelligence officers should provide.    In sum, confronted with a map that did not provide any background, such as the causes of crime predic- tions, together with largely unknown requirements from the police community, intelligence of ﬁ cers ini- tially tried to determine whether the algorithmic pre- dictions would make sense to police managers if they extracted them from the system and transferred them as a list (see Table  2 ). By performing translation practi- ces in the form of  “ extracting ”  and  “ transferring, ”  the intelligence of ﬁ cers enacted a brokerage role that can best be described as a  “ messenger. ”  It soon became clear, however, that the differences between algorith- mic predictions and the knowledge of police manag- ers were larger than the intelligence of ﬁ cers initially expected. Both the police managers and the data scien- tists criticized the efforts of the intelligence of ﬁ cers and pushed them to deepen their knowledge broker- age work by not just listing but further interpreting the predictions. In other words, the intelligence of ﬁ cers had to better decontextualize the algorithmic predic- tions from the machine learning community in order to contextualize them to the police. Algorithmic Broker Acting as Interpreter To translate algorithmic predictions to the police, the intelligence of ﬁ cers realized they lacked a deep under- standing of the machine learning community and the police community and invested in learning more about both. Learning About the Machine Learning Community.    The intelligence of ﬁ cers recognized that they had to better understand the computational and statistical techniques used in CAS. As intelligence of ﬁ cer Table 2.     Overview of Intelligence Of ﬁ cers ’  Brokerage Work Characteristics of brokerage work Messengers Interpreters Curators Details Data segments Details Data segments Details Data segments Understanding of machine learning community No knowledge of machine learning and its associated techniques “ It ’ s just a map. What can we do with it? What do we have to do with it? ”  (Intelligence of ﬁ cer Sophia) “ Sometimes I have such a blackout, then I really don ’ t know what to do. ” (Intelligence of ﬁ cer Louisa) “ When we started it really took a day or two to do it really well [to list all predictions]. ” (Intelligence of ﬁ cer Wendy) Attempting to gain some knowledge of computational and statistical techniques “ I asked the data scientists, like, is there some kind of value attached to the calculation of the hot times? Does last week count more than a year ago, or two years ago? What kind of table is used for that? ” (Intelligence of ﬁ cer Tom) “ What I  ﬁ nd dif ﬁ cult is, something [a prediction] pops up and turns red. There are so many variables in CAS and there are only a few that make that prediction pop up. I would really appreciate it if I knew which variables. ” (Intelligence of ﬁ cer Maya) “ We really want to know what ’ s behind each prediction. . . . Even if it ’ s only a top three, that ’ s already something. ” (Intelligence of ﬁ cer Wendy) Experience an impassable knowledge boundary “ I [still] have to guess about the reasons why a hotspot turns red. And then  ﬁ nd a ﬁ tting recommendation. ” (Intelligence of ﬁ cer Fred) “ To be really honest, in case of nuisance, I just don ’ t trust CAS anymore. I have more trust in the data we can get out of the police databases ourselves. ” (Intelligence of ﬁ cer Joey) Understanding of user community Struggling to understand the police community “ We are still struggling to  ﬁ nd the best way to use CAS for informing police decision making. ”  (Intelligence of ﬁ cer Eva) Intelligence of ﬁ cer Nate explains the troubles he has with understanding the needs of police. He does not know how to  ﬁ gure them out. (Observation notes) The intelligence of ﬁ cers say that they are still searching for their identity and that they themselves sometimes do not know where their work ends, but also that the police sometimes expect things from them that they feel are not part of their work. (Observation notes) Becoming familiar with police requirements “ We ask direct questions to police of ﬁ cers. This neighborhood is the predicted location for burglary. What is going on there? What kind of locks are on the doors? What kind of houses are there? What kind of people live there? Are there a lot of cars, not so many cars, parking spots, good or bad street lighting? ” (Intelligence of ﬁ cer Wendy) Intelligence of ﬁ cer Louisa sends the police of ﬁ cers of a speci ﬁ c neighborhood an email to ask for more information about the predicted location. In the email, Louisa asks the police of ﬁ cers to respond before this Friday, because she plans to ﬁ nish the prediction document by then. (Observation notes) Experience a passable knowledge boundary “ [The relationship with managers] is much more like a full partner. We are on the same level. Instead of being supportive, we are actually partners. ” (Intelligence of ﬁ cer Ben) “ Before, we never had to think anything of anything. Back then it was just a question and an answer, that ’ s that. And whatever I thought about that didn ’ t matter. But now we need to think something of it. You have to give a value judgment. That ’ s probably our added value. The information itself, they [police managers] have that themselves too. So that ’ s not the point anymore, that we do that. We need to think something of it. ”    Table 2.     (Continued) Characteristics of brokerage work Messengers Interpreters Curators Details Data segments Details Data segments Details Data segments (Intelligence of ﬁ cer Wendy) “ When we ’ re at the management meeting, police managers actually always follow our recommendations. ” (Wendy) Brokerage practices Extracting and transferring crime predictions Intelligence of ﬁ cer Eva says in a management meeting that she ’ s been struggling with interpreting the predictions, which is why she decided to “ take CAS at face value ”  and present a full list of predictions to the managers. (Observation notes) Examining and domesticating crime predictions “ Often, when I try to  ﬁ nd an explanation for the predictions, I look at the police data. ”  (Intelligence of ﬁ cer Joey) “ We need to look at the data about previous crimes to trust the predictions. ” (Intelligence of ﬁ cer Michael) “ I can imagine that sometimes a prediction is mainly based on the police data and other times on demographic data. If that can be made visible for each prediction, that would really aid my work. ” (Intelligence of ﬁ cer Fred) “ If something is predicted for weeks on end, I look into whether it ’ s constantly the same suspect who ’ s active there, so that I can add a picture and a name and possibly an MO or a more speci ﬁ c timeframe to the prediction. ”  (Joey) Substituting crime predictions “ We base our recommendations on the ﬁ gures we generate ourselves. We run a report on [own explainable tool] so that you can see, like, hey I see an upward trend in pickpocketing here. Then we zoom in on that. ” (Intelligence of ﬁ cer Wendy) Intelligence of ﬁ cer Louisa explains that their new tool helps them to label and retrieve data. On Sunday, she spent a long time working on various car burglaries. She read and labeled several reports about the burglaries, which helped her see a connection and pattern between them. (Observation notes) “ We don ’ t refer to CAS anymore. ”  (Wendy) Data scientists ’ responses to translation Insist that algorithmic predictions need to be moved away from the data science world “ What we wanted [intelligence of ﬁ cers] to do in this working process is not to follow orders but be a bit more proactive and to not be afraid of putting forth their own thoughts about what ’ s happening here [in this crime prediction]. ”  (Data scientist Dennis) “ Police just want more information. They want to Explain the basics of machine learning “ During our meeting, it was asked which variables are used for the predictions. An overview of the variables can be found at: [internal link]. ” (Data scientist Matt in an email to the intelligence of ﬁ cers) “ [Name of police database] is the place where the data is collected on which the predictions are based. ”  (Matt No further interaction “ Well, we let it go now. The [intelligence of ﬁ cers at] police stations know best about crime details. ”  (Data scientist Dennis)    Table 2.     (Continued) Characteristics of brokerage work Messengers Interpreters Curators Details Data segments Details Data segments Details Data segments know, for example,  ‘ are there any people I should pay attention to when I see them? Are there certain buildings that are interesting in one way or another? ’  This kind of qualitative information is important. That helps them to focus rather than just being somewhere at a certain predicted moment. ”  (Dennis) to intelligence of ﬁ cers in an email) Police managers ’ responses to translation Insist that they need a meaningful overview of crime predictions “ Let ’ s set priorities. Look, we cannot handle everything, but let ’ s at least make a choice and set a priority for this. Like, we [police and intelligence] will in any case tackle this [crime prediction], because we now  ﬁ nd this important. ”  (Police manager Rudy) “ We [police managers] need concrete action points. ”  (Head of police department George) “ [Explanations will help] to increase the acceptance of predictions [by police managers]. ”  (Internal document) Start to act on the intelligence of ﬁ cers ’ suggestions “ I think that people who are knowledgeable about CAS [intelligence of ﬁ cers] have thought about this [the recommendation]. So, then I expect that it has added value too. And then I think, yes, we should just do this [use CAS in operational decision-making]. ”  (Police manager Harry) “ Now, police managers ask us to report it. It used to be, like,  ‘ this is CAS, there ’ s an increased chance in burglary, ’ and that was it. And then you ’ d wish that police of ﬁ cers would do a bit of driving around over there. Now we ’ re requested to report at the end of our shift, like,  ‘ yes, we ’ ve been there and we didn ’ t see anything. ’” (Police of ﬁ cer Jay) Suggestions are relevant for operational decision making “ Based on the home and car burglary predictions, we have decided to place the [specialized team] in that area for the upcoming two weeks. ”  (Email of police managers) “ Well, CAS helps to give direction to police work. You ’ re not uselessly driving around in circles. If you really do things based on information, then you ’ re useful. ”  (Police manager Harry)    Richard re ﬂ ected,  “ There are so many indicators that CAS uses to make these calculations. And then CAS turns a square red on the map. But why does it turn that square red? ”  Consequently, the  ﬁ rst step was to interact with the data scientists to  ﬁ nd out more about their practices and to see if the causes of predictions could be made transparent. They asked the data scien- tists to create a tool that would make the decision log- ic of crime predictions visible. The assumption was that such a tool would make it possible for the intelli- gence of ﬁ cers to trace how a crime prediction was cal- culated. However, the data scientists insisted that  “ the algorithm did not easily display why something was predicted ”  (data scientist Jules) and that generating the best predictions required complex techniques for pattern recognition in vast amounts of data, which made the learning algorithm opaque. As a conse- quence, the data scientists claimed that pattern recog- nition through machine learning, which combines many different variables and theories, required  “ such complex mathematical reasoning that it probably ex- tends beyond human reasoning. ” 5      Data scientist Den- nis further explained this belief as follows: If you want to have the perfect set of selection rules, it means that you have to study a lot of variances for a long time. And this is the reason why [data scien- tists] don ’ t do it in a common-sense way [using hu- man reasoning] because there are too many possible variations. You have to do it by computer [using ma- chine learning].    To help the intelligence of ﬁ cers understand the data science practices, the data scientists did explain the techniques they used for developing CAS. For exam- ple, they showed the variables that were included in the learning algorithm. Such a list of variables still, however, did not give insight into which variable was considered most important for a given prediction and for what reason, as this was determined by the learn- ing algorithm and unknown even to the data scien- tists. These explanations therefore did not satisfy the intelligence of ﬁ cers ’  need to understand how the crime predictions were generated and gradually they gave up on their quest to gain deep insights into the practices of the data scientists. Dedicated to ful ﬁ lling their tasks as brokers, they decided to leave the data scientist aside and started to examine the predictions by inspecting the input they had direct access to: the police data. As intelligence of- ﬁ cer Eva re ﬂ ected,  “ How predictions come about technically might be a guess but you can have a look at the police data of past years and  ﬁ nd quite some reasons. ”  For example, to understand why burglaries were often predicted in the morning, insight into how the time frame of crime predictions was calculated was needed, which triggered the intelligence of ﬁ cers to dig into the police database and look for time stamps in burglary reports. It appeared that, if a bur- glary occurred in a period when people were away from home, the report included a time frame (e.g., 08:00 to 18:00) instead of one time stamp (e.g., 08:30). So, they reasoned that the time the data scientists de- cided to use was the so-called  “ starting time ”  of an in- cident (in this case 08:00) instead of including the full time frame. Taking their assignment to create connections be- tween the machine learning community and the police community seriously, the intelligence of ﬁ cers unsuc- cessfully tried to share their  ﬁ ndings from the police data with the data scientists. For example, when they suggested a different method for calculating time frames, the data scientists maintained their belief in the machine learning techniques they had applied and said that this was the  “ only scienti ﬁ cally proven meth- od ”  for calculating time predictions (data scientists Dennis and Mary). In another instance, when one of the intelligence of ﬁ cers emailed the data scientists to share that CAS generated predictions for car bur- glaries in areas where cars were not permitted, data scientist Dennis continued to believe in the CAS pre- dictions and answered that  “ it really was a parking area. ” These interactions with the data scientists made the intelligence of ﬁ cers realize there was a serious bound- ary between machine learning and their human inter- pretations, which blocked a mutual understanding between them and the data scientists. According to the intelligence of ﬁ cers, the data scientists were “ trying to develop better tools ”  (intelligence of ﬁ cer Fred) but  “ did not understand what they [intelligence of ﬁ cers] wanted ”  (intelligence of ﬁ cer Bart). They grew more and more skeptical of how algorithmic predic- tions were developed. As intelligence of ﬁ cer Wendy remarked,  “ Data scientists don ’ t have a clue about po- lice work. CAS is just a tool with some kind of science behind it. Well, if you reason like that, you don ’ t get our reasoning. ”  Moreover, no matter how much effort they put into examining the data to better understand where the crime predictions came from, most of the time they  “ just could not deduce from the data why a prediction appeared ”  (intelligence of ﬁ cer Joey), which was considered to be a serious bottleneck in perform- ing their work as knowledge brokers. As intelligence of ﬁ cer Fred explained: Understanding CAS is especially important for get- ting to the final step, for putting the predictions in the context of the police. If I know that the reason be- hind a prediction is just that a lot of crimes happened there in the past, then I can suggest that the police of- ficers drive around in that area so that they can pre- vent the predicted crimes from coming true. If the prediction appears because of demographic data, indicating that there ’ s a lot of money over there or something like that, then police officers have to take another approach. Then they have to warn the resi- dents and make them prevent these crimes from hap- pening [e.g., by improving their locks].    The inability to fully comprehend the decision logic of CAS had fundamental consequences for translating predictions from the learning algorithm to the police. To better understand how this was so in ﬂ uential, we ﬁ rst turn to how the intelligence of ﬁ cers also put ef- forts into better understanding the police community. Learning About the User Community.     Initially, the in- telligence of ﬁ cers also struggled with translating the crime predictions to the police. To solve this issue, they started to interact more directly with the police to gain a better understanding of the police communi- ty. By printing a crime prediction, sitting down with police of ﬁ cers, and asking them to make sense of that prediction from their occupational perspective (see Figure  3 ), they learned that  “ more concrete ”  (police manager Rudy) or contextualized predictions includ- ed speci ﬁ c details of the area or of potential suspects. For example, the police managers told the intelligence of ﬁ cers that algorithmic predictions would start to make sense to them if the intelligence of ﬁ cers  “ dared to add suspects ”  (Rudy). To create these more contex- tualized predictions, the intelligence of ﬁ cers relied on police data; navigating the police databases and reading police reports (e.g., DNA matches, burglary reports, pictures of criminals sent to the police via community WhatsApp groups). They also learned from interacting with police managers that short and action-oriented descriptions best  ﬁ t the police commu- nity.  “ We gave the police managers a couple of op- tions and asked for their opinion, ”  intelligence of ﬁ cer Wendy re ﬂ ected,  “ and eventually they said  ‘ give us as little as possible. ’” Using their improved understanding of police work, the intelligence of ﬁ cers changed the way they handled crime predictions and started deleting, edit- ing, and interpreting them. The request for a concise document triggered the intelligence of ﬁ cers to limit the number of predictions they presented to  ﬁ ve time frames (from an average of 28) and two locations (from an average of 56) and to delete all predictions they thought did not make sense. For example, they removed burglary predictions when no burglaries happened the week before. Moreover, even though they could not comprehend the decision logic of the crime predictions, the intelligence of ﬁ cers tried to in- clude details that they could link to the predictions without knowing the exact causes, such as area char- acteristics (e.g.,  “ rehabilitation center for ex-convicts in the vicinity ” ), housing conditions (e.g.,  “ mainly stu- dent houses ”  or  “ outdated locks ” ), or even adding po- tential suspects who had been criminally active in the area before. Intelligence of ﬁ cer Ben summarized their knowledge brokerage work as follows: We add an interpretation to the algorithmic predic- tions so police managers can do something with them. In other words:  “ It is like this for these reason- s. ”  You can also give police managers advice, like:  “ I would focus on this or that person, ”  or  “ I wouldn't do anything about that type of crime because it ’ s way too unpredictable. ”    The police managers appreciated the new way of domesticating algorithmic predictions and perceived the brokerage work as more relevant and valuable. They expressed, for example, that, thanks to the intel- ligence of ﬁ cers ’  interpretations, the algorithmic pre- dictions gave more  “ direction to their decision- making work ”  (police manager Harry) and also recog- nized the increased value of intelligence of ﬁ cers ’  work for “ coordinating police work ” (police manager Rudy). Moreover, during the time that the intelligence of ﬁ cers became more knowledgeable of police work and the police managers started using the crime pre- dictions to inform their operational decisions, the po- lice managers observed an overall decline in the num- ber of high-impact crimes (e.g., burglary and car theft). The decrease in the number of burglaries was even so spectacular that the police station won a na- tional award called  “ Harm Alarm ”  for the largest bur- glary reduction (minus 47% compared with the year before). In their internal communication, the police managers attributed this achievement largely to the Figure 3.  (Color online) Police Of ﬁ cer and Intelligence Of ﬁ - cer Together Making Sense of a Prediction    learning algorithm that offered them  “ new ways of gathering and analyzing data. ” Even though the declining crime numbers could have reasons unrelated to the use of algorithmic predic- tions (e.g., criminals being less interested in doing “ laborious ”  burglaries and moving toward cybercrime instead), the police managers felt they had reasons to believe that the use of algorithmic predictions was pay- ing off. Happy with the work of the intelligence of ﬁ - cers, the police managers decided to give more weight to the brokerage work. They appointed the intelligence of ﬁ cers as key  ﬁ gures for informing their operational and strategic decisions by inviting them into their man- agement meetings. To  “ make crime predictions more central ”  (police manager Harry), they scheduled about 20 minutes at the beginning of these meetings for intel- ligence of ﬁ cers to present their advice. In sum, to translate algorithmic predictions to the po- lice, the intelligence of ﬁ cers realized that they them- selves  ﬁ rst had to better understand how these predic- tions were generated and how police work was performed. In their efforts to  ﬁ nd out more about the decision logic of crime predictions, they encountered the opaque nature of learning algorithms, which solidi- ﬁ ed a knowledge boundary between the machine learn- ing community and the intelligence of ﬁ cers. On the oth- er hand, due to the consistent interactions with the police, the access to the police data, and the police man- agers ’  increased belief in the value of crime predictions, the knowledge differences between the intelligence of ﬁ - cers and the police community was slowly fading. This allowed the intelligence of ﬁ cers to contextualize the al- gorithmic predictions in such a way that they made sense to the police managers (see Table  2 ). By perform- ing translation practices in the form of  “ examining ” and  “ domesticating, ”  the intelligence of ﬁ cers enacted a knowledge brokerage role that can best be described as an  “ interpreter. ”  However, even though their contextu- alizing efforts seemed to work for the police managers, the intelligence of ﬁ cers continued to struggle with un- derstanding the black-boxed machine learning. Algorithmic Broker Acting as Curator Now that the intelligence of ﬁ cers became used to their ascribed expertise as algorithmic brokers, they searched for ways to deal with the opaque algorithmic predictions and discussed this with their head of de- partment. He suggested that the difference between machine learning and their human interpretation was in fact so large that it could not be overcome and that they should therefore use their own expertise: Intelligence work is not only about CAS. You can in- clude your input there as well. Human intelligence is by definition smarter than algorithmic systems. (Head of intelligence department Rick)    By now, the intelligence of ﬁ cers were so knowl- edgeable of the police community that they felt con ﬁ - dent enough to leave CAS aside and focus only on helping police managers to not be disturbed by “ useless ”  issues and emphasize the  “ really important ” ones (intelligence of ﬁ cer Richard). Moreover, a side ef- fect from their efforts to deduce details about machine learning from police data were that they realized that they used many more data sources in their knowledge brokerage work than those included in CAS. Intelli- gence of ﬁ cer Joey expressed a shared sentiment:  “ To be honest, I trust CAS less than I trust the information I can gather from the police databases. ”  They also be- came increasingly vocal among each other about the centrality of their work for guiding police managers. For example, in one of their department meetings, they agreed that intelligence work should not be about  “ ﬁ guring out how systems work, but making meaningful data combinations for police managers. ” Whereas data scientists believed that the intelli- gence of ﬁ cers continued to make the crime predic- tions meaningful to the police and helped police man- agers to make their operational processes  “ smarter and better ”  (data scientist Jules), in the meantime, the intelligence of ﬁ cers substituted CAS with more ex- plainable solutions that supported their human judg- ments. For example, the intelligence of ﬁ cers requested that their local IT desk develop an archival and analy- sis tool. This tool operated on Excel and used all data sources the intelligence of ﬁ cers worked with previ- ously to make sense of algorithmic predictions. It did not include a learning algorithm but was merely there to help the intelligence of ﬁ cers store and add codes to police reports, which facilitated quick and easy infor- mation retrieval and analysis. Since the tool did not use a learning algorithm, it was possible to scrutinize the calculated patterns, which facilitated their knowl- edge brokerage work. For example, they requested that the tool include a new method for calculating crime time frames, by using and visualizing a weight- ed average of the time windows of past crimes. When the intelligence of ﬁ cers compared the times calculated by their tool with the times predicted by CAS, they considered their  “ own ”  times  “ more explainable ”  (in- telligence of ﬁ cer Louisa). Their new tool only gave the intelligence of ﬁ cers insights into past crime patterns and had no predictive capacity for an example of CAS predictions compared with outcomes of their new tool, but the transparent and explainable nature of their new tool helped them in to make substitutes that they thought would best  ﬁ t the police. As intelligence of ﬁ cer Wendy re ﬂ ected: We already see the problem and then we go and double-check it with CAS and say:  “ Oh, well, it sup- ports our judgment, we can point police managers ’ attention there. ”  The problem is already clear, it ’ s al- ready evident, so we don ’ t need CAS that much anymore.    Interestingly, whereas they pushed the learning algorithm to the background and constructed explain- able alternatives that aligned with their human judg- ments, only the intelligence of ﬁ cers themselves were aware of this shift. Driven by police management ’ s pushback to being disturbed by the complex technolo- gy and pushed by their encouragements to come up with  “ concise ”  predictions, for example, to  “ give them as little as possible ”  (police manager Rudy), the intelli- gence of ﬁ cers shielded the police managers from the process through which they generated the substitutes. “ We should keep these choices away from police management, ”  said the head of intelligence Rick dur- ing one of their department meetings,  “ they just need a clear recommendation; we shouldn ’ t bother them with what kind of tools we used for it. ” This was also reinforced by the intelligence of ﬁ cers ’ experiences during their presentations at management meetings. During these presentations, police manag- ers did not pay attention to slide handouts or explana- tions and were instead checking their phones. Yet, they plainly followed the intelligence of ﬁ cers ’  recom- mendations.  “ We give our advice, ”  intelligence of ﬁ cer Wendy re ﬂ ected,  “ and most of the time the police managers allocate police resources accordingly. ” Eventually, these occurrences during meetings made them believe that the police managers took their ad- vice seriously without the need for any references, and they decided to just offer the substitutes without the need to  “ back up their suggestions to police man- agers with numbers ”  (intelligence of ﬁ cer Aileen). Wendy explained: In the beginning, we had this whole document with a long interpretation [of the algorithmic predictions]. Now, I only present the problem and our advice. Po- lice managers just don ’ t care at all what the numbers look like.    In the end, the intelligence of ﬁ cers presented their recommendations using just one slide, which only in- cluded a direct and short piece of advice without its source, such as:  “ Due to incidents with disorderly con- duct because of alcohol/narcotics use, the intelligence department advises police management to conduct alcohol/narcotics tests on traf ﬁ c participants during the nightly hours over the weekend. Mainly at loca- tions [anonymized]. ”  Being able to substitute the crime predictions with their own alternatives that were will- ingly accepted by the police managers, the intelligence of ﬁ cers felt they had grown more equal to them: We are now considered more as a partner of police managers. Before, we would usually wait for police managers to give us a task. Now, it ’ s just: we are a department and we have something to say too. And we have good suggestions. That ’ s the difference. We changed into an intelligence department having a seat at the table. (Intelligence officer Wendy)    In sum, the intelligence of ﬁ cers eventually realized that the boundary between machine learning and their human interpretation of crime predictions was impassable. As a consequence, they pushed back the learning algorithm and substituted it with explainable alternatives that aligned with their human judgments and that they considered most suitable for the police managers (see Table  2 ). As such, by performing trans- lation practices in the form of  “ substituting, ”  the intel- ligence of ﬁ cers enacted a brokerage role that can be best described as a  “ curator, ”  in which they grew to become more in ﬂ uential and were eventually consid- ered more as a partner to the police managers."
Discussion,"Discussion Building on the  ﬁ ndings of our case, we offer a gener- al explanation of how algorithmic brokers translate predictions to users (see Figure  4 ). In particular, we observed how brokers perform translation practices that allow them to enact increasingly in ﬂ uential algo- rithmic brokerage roles. The brokerage work changes over time, because when they attempt to translate al- gorithmic predictions, knowledge differences emerge between the brokers and the communities they intend to connect. At the start of the brokerage work, brokers lack suf ﬁ cient understanding of the machine learning community and the user community and cannot do more than act as messengers. They do so by interact- ing with the learning algorithm ’ s task outputs, extract- ing and transferring predictions. This, however, leads to failed attempts of decontextualizing the algorithmic predictions from the machine learning community and of contextualizing them to the user community. To solve this, realization sets in that translation re- quires deeper insights into both communities. This means a move away from merely acting as a messen- ger to an interpreter role, aiming to examine the algo- rithmic predictions and domesticating them in the user community. Although it is possible for the brokers to reach a deeper understanding of the learn- ing algorithms ’  task inputs, that is, the developers ’ knowledge and the input data, the opaque nature of machine learning prevents them from fully under- standing how algorithmic predictions are generated. Because of this, the brokers experience an impassable knowledge boundary between them and the machine learning community, which triggers them to act as cu- rators and substitute the algorithmic predictions with their own human judgments. This study shows that bringing together the  ﬁ elds of emerging technologies and organizational theory allows for the emergence of a new phenomenon, that of algorithmic brokerage work with its dynamic and in ﬂ uential nature. More speci ﬁ cally, the current divi- de between the two academic  ﬁ elds has resulted in a scholarly understanding of knowledge brokerage in which the need to comprehend the communities to be able to translate has been taken more or less for granted (Barley  1996 , Vogel and Kaghan  2001 , Meyer 2010 ). Our study shows that the recent rise of learning algorithms with its black-boxed machine learning brings to the fore the need for uniting the two  ﬁ elds. Particularly, our case of knowledge brokerage in the age of learning algorithms highlights the complex and important practice of translating from the machine learning community for knowledge brokerage. Study- ing the translation practices of algorithmic predictions reveals that knowledge brokerage work can become increasingly in ﬂ uential, even to the extent that brokers can eventually substitute the algorithmic predictions, and gives us a better understanding of how and why this growth in in ﬂ uence happens. Below, we offer the key contributions of our study. Creating New Knowledge Boundaries Through Algorithmic Brokerage Work One of the core  ﬁ ndings of the research presented in this paper is that algorithmic brokers enact different translation practices over time and can thereby create new knowledge boundaries between them and the communities they intend to connect. This dynamic perspective on brokerage work offers new insights into the literature on knowledge brokerage and to translation theory. Previous studies argued that knowledge brokerage tasks emerge when a semantic boundary hinders two communities from sharing knowledge (Dougherty 1992 , Carlile  2004 , Boari and Riboldazzi  2014 ) and rea- soned that knowledge brokers could resolve bound- aries and align perspectives by enacting translation practices (Tushman and Katz  1980 , Barley  1996 , Wenger  1999 , Grady and Pratt  2000 , Paul and Whit- tam  2010 ). We contribute to the knowledge brokerage literature by providing a more  ﬁ ne-grained and dy- namic perspective on how knowledge brokers enact translation practices over time and in relation to opaque algorithmic predictions. Building on Røvik ( 2016 ) and based on our empirical  ﬁ ndings, we Figure 4.  Theoretical Model of Brokering Algorithmic Predictions    consider  “ extracting ”  and  “ examining ”  as practices to translate from the machine learning community, and “ transferring, ” “ domesticating, ”  and  “ substituting ”  as practices to translate to the user community, which of- fers a more re ﬁ ned insight into the complexity of bro- kerage work. For brokers to resolve a semantic boundary and to translate knowledge, prior research has emphasized the need to understand the communities involved (Brown and Duguid  1998 , Carlile  2004 , Sturdy and Wright  2011 , Gal et al.  2020 ). Our research reveals that, in the case of learning algorithms, such “ contextual bilingualism ”  (Røvik  2016 , p. 299) cannot be obtained, because gaining a deep understanding of machine learning is impossible. Through the brokers ’ translation practices, which are in ﬂ uenced by a lack of understanding of how algorithmic predictions are generated, a knowledge boundary solidi ﬁ ed between the machine learning community and the brokers. As we mentioned earlier, most research on knowledge brokerage focuses on the semantic boundary that brokers should be able to resolve (Dougherty  1992 , Carlile  2004 , Boari and Riboldazzi  2014 ). Our case shows that, in the efforts to resolve a semantic bound- ary through translation practices, knowledge bound- aries can solidify between knowledge brokers and the communities they intend to connect. This added com- plexity regarding knowledge boundaries uncovers an additional understanding of knowledge brokers; by translating knowledge, they can create their own boundaries. By unpacking the practices through which brokers translate predictions from one community to another, this study also emphasizes the dynamic and changing nature of translation, which offers a contribution to translation theory (e.g., Latour  1986 ,  2005 ; Law  2002 ; Czarniawska and Sev ´ on  2005 ; Røvik  2016 ). Moreover, whereas translation theory scholars have paid exten- sive attention to how ideas are translated to speci ﬁ c ﬁ elds and organizations (e.g., Saka  2004 , Mueller and Whittle  2011 , Nielsen et al.  2014 , Ciuk and James 2015 ), only a few studies have focused on how knowl- edge is translated from its original source (Furusten 1999 , Suddaby and Greenwood  2001 , Heusinkveld and Benders  2005 ). These studies, so far, have not ad- dressed what translation entails if knowledge bound- aries are impassable, such as in the case of learning algorithms. Finally, by uncovering the emergence of an impass- able knowledge boundary between the algorithmic brokers and the machine learning community, our study points to the importance of including technolo- gy in our understanding of knowledge sharing. Our study points out that the practices commonly under- stood to contribute to knowledge sharing (such as per- sonal interaction and shared activities) can become counterproductive in the case of black-boxed machine learning and can even lead to communities moving further apart. Becoming Influential Curators Through Algorithmic Brokerage Work Another core  ﬁ nding of this study is how, by perform- ing different translation practices, the knowledge brokers enact roles that change to become more in ﬂ u- ential over time. Especially the emergence of algorith- mic brokers as curators, acting as  “ kings in the land of the blind ”  adds to our understanding of the work of knowledge brokers as in ﬂ uential and consequential. Research on knowledge brokerage has largely re- garded the work to be that of neutral intermediaries dealing with the knowledge of others (Barley and Bechky  1994 , Barley  1996 ). However, to better under- stand the in ﬂ uential nature of algorithmic brokerage work, the analogy of art curators provides a useful lens. Around the 16th century, with the materializa- tion of  “ cabinets of curiosity, ”  art curators emerged and became responsible for taking care of works of art and valuable objects. In that time, they were leverag- ing the direct connection between artists and collec- tors. The cabinets were closed to the public and housed the private art collections of wealthy citizens. Stemming from the Latin word  cura , the art curators ’ work at that time was to take care of art objects behind closed doors and was not considered to have a recog- nizable status. Interestingly, with the rise of public museums, the curators ’  caretaking practices triggered the public to consider them as experts of art objects (Teather  1990 ). Over time, art progressed into  “ too many artists, too many movements, too many art- works in too many shows, too much discussion ” (Balzer  2014 , p. 65). The direct connection between ar- tists and collectors thus was vanishing, and knowl- edge about art became increasingly abstract and dif ﬁ - cult to understand. Given their knowledge of art sources, art curators stepped in as key  ﬁ gures in the translation of art toward the wider public and were usually blindly trusted by collectors. The story of art curators is particularly helpful, because it reveals how, through caretaking practices, the curators changed from hidden caretakers to a highly in ﬂ uential and independent occupation. The historical journey of curators helps us to understand that, in contrast to our previous understanding of knowledge brokerage work as neutral, the algorithmic brokerage work in our study becomes so in ﬂ uential that brokers can sub- stitute outputs with their own judgments. It is interesting to note that, by using the analogy of the historical trajectory of the work of art curators, this study departs from the current interest in  “ data curators ”  who are mainly considered to act as content creators, data cleaners, or data editors (e.g., Karasti et al.  2006 , Muller et al.  2009 , Carah  2014 , Kellogg et al. 2020 ). Some studies describe how data curation hap- pens  “ behind the scenes ”  of technology development and is therefore usually invisible (Sachs  2020 ). For ex- ample, Gray and Suri ( 2019 ) described how  “ ghost workers ”  emerged because of the need to review the content and quality of the data that is used for training learning algorithms. As the current focus of curation is mainly on the input of technology, our case of algo- rithmic brokers who enact the role of curators shifts this perspective toward the output of learning algo- rithms, just like the output of art. This study therefore emphasizes the need to acknowledge that algorithmic brokers acting as curators can occupy a much more in- ﬂ uential role than what was previously assumed in the invisible  “ ghost work ”  of data curators and to un- pack the consequences of curation for how algorith- mic predictions are (re)presented to users. Practical Implications and Future Research This study offers practical implications for domain ex- perts, managers, and technology developers engaged in the development and implementation of emerging technologies in organizations. In various  ﬁ elds and parts of organizations, dealing with issues around ex- plainability of technology is becoming an important topic. As we have seen so far, on the side of technolo- gy developers and regulatory bodies these issues are mainly assumed to reside in the  “ translating from ” side and technical solutions are offered (e.g., Doran et al.  2017 , Kirsch  2017 , Lipton  2018 , Preece et al.  2018 , Miller  2019 , Mittelstadt et al.  2019 , Robbins  2019 , Bar- redo et al.  2020 ). On the other hand, organizations are generally interested in the  “ translating to ”  side when confronted with issues of algorithmic (in)transparency and push for more contextualization toward user community without recognizing the need for explain- ing how algorithmic predictions are generated (Henke et al.  2018 , Kellogg et al.  2020 ). Our study emphasizes, however, that one cannot exist without the other, which requires involving both the technology devel- opers and domain experts, for example, through mu- tual re ﬂ ection and adaptation already during the de- velopment and implementation process (Zhang et al. 2020 , Van den Broek et al.  2021 ). Involvement in terms of understanding each other ’ s thought worlds re- quires more long-term investments and new skills for developers, brokers, and domain experts or users (Waardenburg et al.  2021 ). For example, developers need social skills to understand the user needs, do- main experts need technical skills to understand the reasoning behind and limits of these technologies, and algorithmic brokers need skills that allow them to cope with the black-boxed machine learning with- out feeling the need to completely substitute predic- tions when they cannot understand how they are generated. Developing such skills will provide a  ﬁ rst step to overcome the knowledge boundary between the machine learning community and the user community. This study also shows that algorithmic brokerage work does not neutrally and objectively represent al- gorithmic predictions but likely includes the human interpretations of the brokers. Whereas brokerage work can be crucial for using learning algorithms in practice, it needs clear demarcations through, for ex- ample, regulation and close monitoring to prevent the work from going beyond translating into substituting. As Røvik ( 2016 , p. 300) emphasized,  “ The more the transfer process is regulated by authorities, the less transformable the transferred construct is for the translator. ”  Also, our case highlights data access as an important resource that enables brokers to translate algorithmic predictions to the user community. Yet, whereas data access can offer transparency, this study shows that unguided data access can also trigger brokers to trust their own interpretations more than algorithmic predictions and set aside the learning algorithm. In addition, it is worth noting several boundary conditions of our study, which also open up opportu- nities for further research. Our case shows that occu- pational values matter for how desirable access to ex- planations may be from the perspective of the user. In our study, the users (i.e., police managers) did not feel the need for explanations of algorithmic predictions and blindly left the responsibilities of translating with the intelligence of ﬁ cers. Although brevity and action orientation are virtues in the police community, this might be different in other communities, such as radi- ology, where the decision-making practices of the users might require as much evidence as possible (e.g., Kim et al.  2021 ). We encourage future studies to look at other communities to further understand the differences in explanations required and to provide insights into who or what is accountable in the age of learning algorithms. Also, we presented a case of the use of a learning algorithm within a highly hierarchi- cal and siloed organizational structure, which hin- dered the interaction between the different communi- ties. Due to this hierarchical setting, the knowledge brokerage work turned out to be largely one- directional. It would be interesting for advancing our knowledge on algorithmic brokering to also include more innovative or  ﬂ at research settings, in which dif- ferent relationships exist between developers and users (such as cocreation or agile technology develop- ment), which opens possibilities to study more unidi- rectional exchanges. Finally, our study focused on a relatively basic and simple version of a learning algo- rithm, which nevertheless had fundamental conse- quences for work and organizing. With the emergence of more advanced and even more opaque learning al- gorithms and computational techniques such as tools based on deep learning, these consequences can be further enlarged. We encourage future research to continue to unpack algorithmic brokerage work to provide deep insights into the organizational conse- quences of emerging technologies that are increasing- ly opaque."
Conclusion,"Conclusion Learning algorithms, because of the black-boxed machine learning, offer an extreme case for under- standing how knowledge brokers enact translation practices. In this study, we provided a case of knowl- edge brokers who aimed to translate algorithmic pre- dictions from a machine learning community to a user community. Translation has always been the core of knowledge brokerage work, yet so far has been main- ly taken for granted in organizational literature. It is now, in the age of learning algorithms, of signi ﬁ cant importance to question how knowledge brokers are able to translate from a machine learning community, since machine learning has become increasingly dif ﬁ - cult to understand. As this study shows, when the outputs of one community are opaque to all actors involved, brokers can become  “ kings in the land of the blind ”  and decide to substitute algorithmic pre- dictions with their own judgments. The case of learn- ing algorithms therefore highlights that knowledge brokers should not be considered as merely instru- mental in solving knowledge boundaries but even more so as highly in ﬂ uential curators of knowledge. Acknowledgments The authors thank the special issue senior editors, Diane Bailey, Samer Faraj, Pamela Hinds, Paul Leonardi, and Georg von Krogh, and the three anonymous reviewers for their valuable guidance during the revision process. The authors received helpful feedback and comments from Ella Hafermalz, Kate Kellogg, Michael Barrett, Ruthanne Huising, Bernard Forgues, Joao Vieira da Cunha, Ola Henfridsson, Ann Langley, Hans Berends, Wanda Orli- kowski, Arvind Karunakaran, Jochem Hummel, and Elmi- ra van den Broek, as well as from participants at seminars at the KIN Center for Digital Innovation, Cambridge Judge Business School, and EMLYON Business School, and at conferences such as the European Group for Orga- nization Studies 2018, the meeting of working group 8.2 of the International Federation for Information Processing 2018, and the Academy of Management Annual Meetings 2019 and 2020. The authors thank the participants of the Dutch police for their time and interest and for allowing us to participate in their everyday work."
Endnotes,"Endnotes 1     To simplify, we use the word  “ knowledge ”  in relation to the practice-based perspective in the remainder of the text. 2     All original names have been removed; the names mentioned are pseudonyms. 3     Further details can be retrieved in full from the corresponding author. 4     The four-hour time frames, seven days a week, meant clicking (24/4)  ×  7  �  42 times to get a weekly overview. 5     See  https://www.politieacademie.nl/kennisenonderzoek/kennis/ mediatheek/pdf/89539.pdf ."
References,"References Ajunwa I (2020) The  “ black box ”  at work.  Big Data Soc.  7(2):1 – 6. Ancona DG, Caldwell DF (1992) Bridging the boundary: External activity and performance in organizational teams.  Admin. Sci. Q.  37(4):634 – 665. Anthony C (2021) When knowledge work and analytical technolo- gies collide: The practices and consequences of black boxing al- gorithmic technologies.  Admin. Sci. Quart. , ePub ahead of print June 4,  https://doi.org/10.1177/00018392211016755 . Bader V, Kaiser S (2019) Algorithmic decision-making? The user in- terface and its role for human involvement in decisions sup- ported by arti ﬁ cial intelligence.  Organ.  26(5):655 – 672. Bailey DE, Barley SR (2020) Beyond design and use: How scholars should study intelligent technologies.  Inform. Organ.  30(2): 100286. Balzer D (2014)  Curationism: How Curating Took over the Art World and Everything Else  (Coach House Books, Toronto). Barley SR (1986) Technology as an occasion for structuring: Evi- dence from observations of CT scanners and the social order of radiology departments.  Admin. Sci. Quart.  31(1):78 – 108. Barley SR (1996) Technicians in the workplace: Ethnographic evi- dence for bringing work into organizational studies.  Admin. Sci. Quart.  41(3):404 – 441. Barley SR, Bechky BA (1994) In the backrooms of science: The work of technicians in science labs.  Work Occupations  21(1):85 – 126. Barredo AA, D ´ ı az-Rodr ´ ı guez N, Del Ser J, Bennetot A, Tabik S, Bar- bado A, Garcia S, et al. (2020) Explainable arti ﬁ cial intelligence (XAI): Concepts, taxonomies, opportunities and challenges to- ward responsible AI.  Inform. Fusion  58:82 – 115. Boari C, Riboldazzi F (2014) How knowledge brokers emerge and evolve: The role of actors ’  behaviour.  Res. Policy  43(4):683 – 695. Bolin G, Andersson Schwarz J (2015) Heuristics of the algorithm: Big Data, user interpretation and institutional translation.  Big Data Soc.  2(2):1 – 12. Brayne S (2020)  Predict and Surveil: Data, Discretion, and the Future of Policing  (Oxford University Press, Oxford, UK). Brown JS, Duguid P (1991) Organizational learning and communi- ties-of-practice: Toward a uni ﬁ ed view of working, learning, and innovation.  Organ. Sci.  2(1):40 – 57. Brown JS, Duguid P (1998) Organizing knowledge.  California Man- agement Rev.  40(3):90 – 111. Brown JS, Duguid P (2001) Knowledge and organization: A social practice perspective.  Organ. Sci.  12(2):198 – 213. Brynjolfsson E, McAfee A (2017) The business of arti ﬁ cial intelli- gence. Harvard Bus. Rev. (July 18),  https://hbr.org/2017/07/ the-business-of-arti ﬁ cial-intelligence . Burgess N, Currie G (2013) The knowledge brokering role of the hy- brid middle level manager: The case of healthcare.  British J. Management  24(S1):S132 – S142. Burrell J (2016) How the machine  ‘ thinks ’ : Understanding opacity in machine learning algorithms.  Big Data Soc.  3(1):1 – 12. Burt RS (1992)  Structural Holes: The Social Structure of Competition (Harvard University Press, Cambridge, MA). Callon M (1984) Some elements of a sociology of translation: Do- mestication of the scallops and the  ﬁ shermen of St Brieuc Bay. Sociol. Rev.  32:196 – 233. Carah N (2014) Curators of databases: Circulating images, manag- ing attention and making value on social media.  Media Internat. Australia  150(1):137 – 142. Carlile PR (2004) Transferring, translating, and transforming: An in- tegrative framework for managing knowledge across bound- aries.  Organ. Sci.  15(5):555 – 568. Chiambaretto P, Mass ´ e D, Mirc N (2019)  “ All for one and one for all? ”  - Knowledge broker roles in managing tensions of internal coopetition: The Ubisoft case.  Res. Policy  48(3):584 – 600. Christin A (2020) The ethnographer and the algorithm: Beyond the black box.  Theor. Soc.  49:897 – 918. Christin A, Brayne S (2020) Technologies of crime prediction: The reception of algorithms in policing and criminal courts.  Soc. Problems  68(3):608 – 624. Ciuk S, James P (2015) Interlingual translation and the transfer of value-infused practices: An in-depth qualitative exploration. Management Learning  46(5):565 – 581. Cook SDN, Brown JS (1999) Bridging epistemologies: The generative dance between organizational knowledge and organizational knowing.  Organ. Sci.  10(4):381 – 400. Czarniawska B, Joerges B (1996) Travels of ideas. Czarniawska B, Sev ´ on G, eds.  Translating Organizational Change  (De Gruyter, New York), 13 – 48. Czarniawska B, Sev ´ on G (2005) Translation is a vehicle, imitation its motor, and fashion sits at the wheel. Czarniawska B, Sev ´ on G, eds.  Global Ideas: How Ideas, Objects and Practices Travel in the Global Economy  (Liber and Copenhagen Business School Press, Malm ¨ o, Sweden), 7 – 12. Davenport T (2018)  The AI Advantage: How to Put the Arti ﬁ cial Intelli- gence Revolution to Work  (MIT Press, Cambridge, MA). DiMaggio P (1993) Nadel's paradox revisited: Relational and cultural aspects of organizational structures. Nohria N, Eccles R, eds.  Net- works and  Organization (Harvard Business School Press, Boston). Doorewaard H, van Bijsterveld M (2001) The osmosis of ideas: An analysis of the integrated approach to IT management from a translation theory perspective.  Organ.  8(1):55 – 76. Doran D, Schulz S, Besold TR (2017) What does explainable AI real- ly mean? A new conceptualization of perspectives. Preprint, submitted October 2,  https://arxiv.org/abs/1710.00794 . Dougherty D (1992) Interpretive barriers to successful product inno- vation in large  ﬁ rms.  Organ. Sci.  3(2):179 – 202. Dur ´ an JM, Jongsma KR (2021) Who is afraid of black box algo- rithms? On the epistemological and ethical basis of trust in medical AI.  J. Medical Ethics  47(5):329 – 335. Edacott CG, Leonardi PM (2020) Keep them apart or join them to- gether? How identi ﬁ cation processes shape orientations to net- work brokerage.  Comm. Res. , ePub ahead of print August 14, https://doi.org/10.1177/0093650220947316 . Evers HD, Menkhoff T (2004) Expert knowledge and the role of con- sultants in an emerging knowledge-based economy.  Human Systems Management  23(2):123 – 135. Faraj S, Pachidi S, Sayegh K (2018) Working and organizing in the age of the learning algorithm.  Inform. Organ.  28(1):62 – 70. Faraj S, von Krogh G, Monteiro E, Lakhani KR (2016) Online community as space for knowledge  ﬂ ows.  Inform. Systems. Res.  27(4):668 – 684. Fernandez-Mateo I (2007) Who pays the price of brokerage? Trans- ferring constraints through price setting in the staf ﬁ ng sector. Amer. Sociol. Rev.  72(2):291 – 317. Fernandez RM, Gould RV (1994) A dilemma of state power: Broker- age and in ﬂ uence in the National Health Policy domain.  Amer. J. Sociol.  99(6):1455 – 1491. Fisher G, Aguinis H (2017) Using theory elaboration to make theo- retical advancements.  Organ. Res. Methods  20(3):438 – 464. Fleming L, Waguespack DM (2007) Brokerage, boundary spanning, and leadership in open innovation communities.  Organ. Sci. 18(2):165 – 180. Forsythe DE (1993) The construction of work in arti ﬁ cial intelli- gence.  Sci. Tech. Human Values  18(4):460 – 479. Furusten S (1999)  Popular Management Books: How They Are Made and What They Mean for Organizations  (Routledge, London). Gal U, Jensen TB, Stein MK (2020) Breaking the vicious cycle of al- gorithmic management: A virtue ethics approach to people ana- lytics.  Inform. Organ.  30(2):100301. Glikson E, Woolley AW (2020) Human trust in arti ﬁ cial intelli- gence: Review of empirical research.  Acad. Management Ann. 14(2):627 – 660. Gould RV, Fernandez RM (1989) Structures of mediation: A formal approach to brokerage in transaction networks.  Sociol. Methodol- ogy  19:89 – 126. Grady R, Pratt J (2000) The UK technology transfer system: Calls for stronger links between higher education and industry.  J. Tech. Transfer  25(2):205 – 211. Gray ML, Suri S (2019)  Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass  (HMH Books, Boston). Haas A (2015) Crowding at the frontier: Boundary spanners, gate- keepers and knowledge brokers.  J. Knowledge Management  19(5): 1029 – 1047. Hargadon A, Sutton RI (1997) Technology brokering and innovation in a product development  ﬁ rm.  Admin. Sci. Quart.  42(4):716 – 749. Heaphy ED (2013) Repairing breaches with rules: Maintaining insti- tutions in the face of everyday disruptions.  Organ. Sci.  24(5): 1291 – 1315. Heimer CA, Stevens ML (1997) Caring for the organization: Social workers as frontline risk managers in neonatal intensive care units.  Work Occupations  24(2):133 – 163. Henke N, Levine K, McInerney P (2018) You don ’ t have to be a data scientist to  ﬁ ll this must-have analytics role. Harv ard  Bus. Rev. (February 5),  https://hbr.org/2018/02/you-dont-have-to- be-a-data-scientist-to- ﬁ ll-this-must-have-analytics-role . Heusinkveld S, Benders J (2005) Contested commodi ﬁ cation: Con- sultancies and their struggle with new concept development. Human Relations  58(3):283 – 310. Huising R, Silbey SS (2011) Governing the gap: Forging safe science through relational regulation.  Regulation Governance 5(1):14 – 42. Huysman M (2020) Information systems research on arti ﬁ cial intelli- gence and work: A commentary on  “ Robo-Apocalypse can- celled? Reframing the automation and future of work debate ” . J. Inform. Tech.  35(4):307 – 309. Introna LD (2016) Algorithms, governance, and governmentality: On governing academic writing.  Sci. Tech. Human Values  41(1):17 – 49. Johri A (2008) Boundary spanning knowledge broker: An emerging role in global engineering  ﬁ rms.  Proc . 38th Annual Frontiers Ed. Conf. (IEEE, Piscataway, NJ), 7 – 12. Karasti H, Baker KS, Halkola E (2006) Enriching the notion of data curation in e-science: Data managing and information infra- structuring in the long term ecological research (LTER) net- work.  Comput. Supported Cooperative Work  15(4):321 – 358. Kellogg KC (2014) Brokerage professions and implementing reform in an age of experts.  Amer. Sociol. Rev.  79(5):912 – 941. Kellogg KC, Valentine M, Christin A (2020) Algorithms at work: The new contested terrain of control.  Acad. Management Ann. 14(1):366 – 410. Kim B, Koopmanschap I, Mehrizi MHR, Huysman M, Ranschaert E (2021) How does the radiology community discuss the bene ﬁ ts and limitations of arti ﬁ cial intelligence for their work? A sys- tematic discourse analysis.  Eur. J. Radiology  136:109566. Kirsch A (2017) Explain to whom? Putting the user in the center of explainable AI.  Proc. First Internat. Workshop Comprehensibility Explanation AI ML, Bari, Italy,  November 16 – 17. Kissling-Naf I (2009) From a learned society to a 21st-century broker: The Swiss Academy of Sciences as a partner in the dialogue with society.  Internat. J. Tech. Management  46(1 – 2):120 – 131. Langley A (1999) Strategies for theorizing from process data.  Acad. Management Rev.  24(4):691 – 710. Langley A, Lindberg K, Mørk BE, Nicolini D, Raviola E, Walter L (2019) Boundary work among groups, occupations, and organ- izations: From cartography to process.  Acad. Management Ann. 13(2):704 – 736. Latour B (1986) The powers of associations. Law J, ed.  Power, Action and Belief: A New Sociology of Knowledge?  (Routledge, London), 264 – 280. Latour B (2005)  Reassembling the Social: An Introduction to Actor-Net- work-Theory  (Oxford University Press, Oxford, UK). Lave J (1988)  Cognition in Practice  (Cambridge University Press, Cambridge, UK). Lave J, Wenger E (1991)  Situated Learning: Legitimate Peripheral Partic- ipation  (Cambridge University Press, New York). Law J (2002)  Aircraft Stories: Decentering the Object in Technoscience (Duke University Press, Durham, NC). Lebovitz S, Levina N, Lifshitz-Assaf H (2019) Doubting the diagno- sis: How arti ﬁ cial intelligence increases ambiguity during pro- fessional decision making. Working paper, New York Universi- ty, New York. Lebovitz S, Levina N, Lifshitz-Assaf H (2021) Is AI ground truth re- ally  “ true ” ? The dangers of training and evaluating AI tools based on experts ’  know-what.  MIS Quart.  Forthcoming. Leonardi PM, Bailey DE (2017) Recognizing and selling good ideas: Network articulation and the making of an offshore innovation hub.  Acad. Management Discoveries  3(2):116 – 144. Levina N, Vaast E (2005) The emergency of boundary spanning competence in practice: Implications for implementation and use of information systems.  MIS Quart.  29(2):335 – 363. Lingo EL, O ’ Mahony S (2010) Nexus work: Brokerage on creative projects.  Admin. Sci. Quart.  55(1):47 – 81. Lipton ZC (2018) The mythos of model interpretability.  Queue  16(3): 31 – 57. Meyer M (2010) The rise of the knowledge broker.  Sci. Comm.  32(1): 118 – 127. Michalski RS, Carbonell JG, Mitchell TM (2013)  Machine Learning: An Arti ﬁ cial Intelligence Approach  (Springer, Cham, Switzerland). Miller T (2019) Explanation in arti ﬁ cial intelligence: Insights from the social sciences.  Arti ﬁ cial Intelligence  267:1 – 38. Mittelstadt B, Russell C, Wachter S (2019) Explaining explanations in AI.  Proc. Conf. Fairness Accountability Transparency  (ACM, New York), 279 – 288. Mueller F, Whittle A (2011) Translating management ideas: A dis- cursive devices analysis.  Organ. Stud.  32(2):187 – 210. Muller MJ, Milien DR, Feinberg J (2009) Information curators in an enterprise  ﬁ le-sharing service.  Proc. 11th Eur. Conf. Comput. Sup- ported Cooperative Work  (Springer, London), 403 – 410. Nelson R, Winter S (1982)  An Evolutionary Theory of Economic Change (Harvard University Press, Cambridge, MA). Nielsen JA, Mathiassen L, Newell S (2014) Theorization and transla- tion in information technology institutionalization: Evidence from Danish home care.  MIS Quart.  38(1):165 – 186. Nonaka I (1994) A dynamic theory of organizational knowledge cre- ation.  Organ. Sci.  5(1):14 – 37. Nonaka I, von Krogh G (2009) Perspective — Tacit knowledge and knowledge conversion: Controversy and advancement in or- ganizational knowledge creation theory.  Organ. Sci.  20(3):635 – 652. Obstfeld D (2005) Social networks, the  tertius iungens  and orientation involvement in innovation.  Admin. Sci. Quart.  50(1):100 – 130. Obstfeld DS, Borgatti P, Davis JP (2014) Brokerage as a process: Decou- pling third party action from social network structure. Brass DJ, Labianca G, Mehra A, Halgin DS, Borgatti SP, eds.  Research in the Sociology of Organizations  (Emerald Books, Bingley, UK), 135 – 159. O ’ Mahony S, Bechky BA (2008) Boundary organizations: Enabling collaboration among unexpected allies.  Admin. Sci. Quart.  53(3): 422 – 459. Orlikowski WJ (2002) Knowing in practice: Enacting a collec- tive capability in distributed organizing.  Organ. Sci.  13(3): 249 – 273. Orr J (1996)  Talking About Machines: An Ethnography of a Modern Job (ILP Press, Ithaca, NY). Østerlund C, Carlile PR (2005) Relations in practice: Sorting through practice theories on knowledge sharing in complex organiza- tions.  Inform. Soc.  21(2):91 – 107. Pachidi S, Berends H, Faraj S, Huysman M (2021) Make way for the algorithms: Symbolic actions and change in a regime of know- ing.  Organ. Sci.  32(1):18 – 41. Pasquale F (2015)  The Black Box Society: The Secret Algorithms That Control Money and Information  (Harvard University Press, Cam- bridge, MA). Paul S, Whittam G (2010) Business angel syndicates: An exploratory study of gatekeepers.  Venture Capital  12(3):241 – 256. Pawlowski SD, Robey D (2004) Bridging user organizations: Knowl- edge brokering and the work of information technology profes- sionals.  MIS Quart.  28(4):645 – 672. Preece A, Harborne D, Braines D, Tomsett R, Chakraborty S (2018) Stakeholders in explainable AI. Preprint, submitted September 29,  https://arxiv.org/abs/1810.00184 . Reagans R, McEvily B (2003) Network structure and knowledge transfer: The effects of cohesion and range.  Admin. Sci. Quart. 48(2):240 – 267. Rezazade Mehrizi MH, van Ooijen P, Homan M (2020) Applications of arti ﬁ cial intelligence (AI) in diagnostic radiology: A technog- raphy study.  Eur. Radiology  31:1805 – 1811. Robbins S (2019) A misdirected principle with a catch: Explicability for AI.  Minds Machines  29:495 – 514. Røvik KA (2016) Knowledge transfer as translation: Review and ele- ments of an instrumental theory.  Internat. J. Management Rev. 18(3):290 – 310. Sachs SE (2020) The algorithm at work? Explanation and repair in the enactment of similarity in art data.  Inform. Comm. Soc. 23(11):1689 – 1705. Safadi H, Johnson L, Faraj S (2021) Who contributes knowledge? Core-periphery tension in online innovation communities. Organ. Sci.  32(3):752 – 775. Saka A (2004) The cross-national diffusion of work systems: Translation of Japanese operations in the UK.  Organ. Stud.  25(2): 209 – 228. Shestakofsky B, Kelkar S (2020) Making platforms work: Relation- ship labor and the management of publics.  Theory Soc.  49(5): 863 – 896. Soundarajan V, Khan Z, Tarba SY (2018) Beyond brokering: Sourc- ing agents, boundary work and working conditions in global supply chains.  Human Relations  71(4):481 – 509. Stovel K, Shaw L (2012) Brokerage.  Annual Rev. Sociol.  38(1):139 – 158. Sturdy A, Wright C (2011) The active client: The boundary- spanning roles of internal consultants as gatekeepers, brokers and partners of their external counterparts.  Management Learn- ing  42(5):485 – 503. Strauss A, Corbin J (1990)  Basics of Qualitative Research  (Sage Publica- tions, Thousand Oaks, CA). Suddaby R, Greenwood R (2001) Colonizing knowledge: Commodi- ﬁ cation as a dynamic of jurisdictional expansion in professional service  ﬁ rms.  Human Relations  54(7):933 – 953. Teather JL (1990) The museum keepers: The Museums Association and the growth of museum professionalism.  Museum Manage- ment Curatorship  9(1):25 – 41. Teece DJ (1998) Capturing value from knowledge assets.  California Management Rev.  40(3):55 – 76. Tsoukas H (2003) Do we really understand tacit knowledge? Easter- by-Smith M, Lyles M, eds.  The Blackwell Handbook of Organiza- tional Learning and Knowledge Management  (Blackwell, Oxford, UK), 410 – 427. Tushman ML, Katz R (1980) External communication and project performance: An investigation into the role of gatekeepers. Management Sci.  26(11):1071 – 1085. Van den Broek E, Sergeeva A, Huysman M (2021) When the ma- chine meets the expert: An ethnography of developing AI for hiring.  MIS Quart.  45(3b):1557 – 1580. Van Maanen J (1973) Observations on the making of policemen.  Hu- man Organ.  32(4):407 – 418. Vogel A, Kaghan WN (2001) Bureaucrats, brokers, and the entrepre- neurial university.  Organ.  8(2):358 – 364. Von Hippel E (1994)  “ Sticky information ”  and the locus of problem solving: Implications for innovation.  Management Sci.  40(4): 429 – 439. Von Krogh G (2018) Arti ﬁ cial intelligence in organizations: New op- portunities for phenomenon-based theorizing.  Acad. Manage- ment Discoveries  4(4):404 – 409. Waardenburg L, Huysman M, Agterberg M (2021)  Managing AI Wise- ly: From Development to Organizational Change in Practice  (Edward Elgar, Cheltenham, UK). Wenger E (1999)  Communities of Practice: Learning, Meaning and Iden- tity  (Cambridge University Press, Cambridge, UK). Zarsky T (2016) The trouble with algorithmic decisions.  Sci. Tech. Human Values  41(1):118 – 132. Zhang Z, Nandhakumar J, Hummel JT, Waardenburg L (2020) Ad- dressing the key challenges of developing machine learning AI systems for knowledge-intensive work.  MIS Quart. Executive 19(4):221 – 238.    Lauren Waardenburg  is an assistant professor at IESEG School of Management in Lille, France. Her main research interests are related to the role of technology for occupation- al emergence and change, the reconfiguration of work and organizing due to intelligent technologies, and the duality of the physical and the digital. She has a specific interest in us- ing ethnography as a research method for studying technol- ogy in practice. Marleen Huysman  holds a chair in knowledge and orga- nization at the School of Business and Economics, Vrije Uni- versiteit Amsterdam, and heads the KIN Center for Digital Innovation and the Department of Knowledge, Innovation, and Networks at the same university. Her research focuses on the development and use of digital innovation, including new ways of working, technology in practice, and knowl- edge sharing. She is a frequent speaker at academic and pro- fessional meetings in the field. Anastasia V. Sergeeva  is an associate professor at the KIN Center for Digital Innovation at the Vrije Universiteit Amster- dam. Her research interests include technology-mediated orga- nizational change, the transformation of professional work, and the emergence of new forms of organizing due to digital tech- nologies. She has studied these topics across diverse occupa- tional contexts, following the introduction of technologies such as surgical robotics, predictive policing, and algorithmic hiring."
